{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "from pyhive import presto\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connection\n",
    "connection = presto.connect(\n",
    "        host='presto-gateway.serving.data.production.internal',\n",
    "        port=80,\n",
    "        protocol='http',\n",
    "        catalog='hive',\n",
    "        username='manoj.ravirajan@rapido.bike'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Chennai'\n",
    "service = 'Link'\n",
    "start_date = '20230710'\n",
    "end_date = '20230723'\n",
    "\n",
    "#PATH_TO_ROOT_DIR = '/Users/pallavichandra/commit_repo/latest_demand_repo/dse-demand-analysis/experiments/price_sensitivity/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datasets\n",
    "\n",
    "raw_dataset = f\"\"\"\n",
    "\n",
    "    WITH \n",
    "    fe_merged AS (\n",
    "        SELECT\n",
    "            city,\n",
    "            customer_id,\n",
    "            fe_tbl.fare_estimate_id AS fare_estimate_id,\n",
    "            pickup_cluster,\n",
    "            yyyymmdd,\n",
    "            orderdate,\n",
    "            time_period,\n",
    "            1 AS fe_count\n",
    "        FROM\n",
    "            (\n",
    "\n",
    "               SELECT\n",
    "                   city AS city,\n",
    "                   user_id as customer_id,\n",
    "                   fare_estimate_id,\n",
    "                   CASE \n",
    "                        WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n",
    "                        WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n",
    "                        WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n",
    "                        ELSE 'rest' \n",
    "                    END AS time_period,\n",
    "                    pickup_cluster,\n",
    "                   date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n",
    "                   yyyymmdd\n",
    "\n",
    "               FROM\n",
    "                   pricing.fare_estimates_enriched\n",
    "               WHERE\n",
    "                   coalesce(CAST( (static_surge + dynamic_surge + dynamic_fare) AS DOUBLE), 0 ) > 0\n",
    "                   AND service_name = '{service}'\n",
    "                   AND city = '{city}'\n",
    "                   AND yyyymmdd >= '{start_date}'\n",
    "                   AND yyyymmdd <= '{end_date}'  \n",
    "\n",
    "         ) fe_tbl\n",
    "    ),\n",
    "\n",
    "    fe_surged_non_surged_ord AS (\n",
    "        SELECT\n",
    "            city,\n",
    "            customer_id,\n",
    "            fe_tbl.fare_estimate_id AS fare_estimate_id,\n",
    "            pickup_cluster,\n",
    "            yyyymmdd,\n",
    "            orderdate,\n",
    "            time_period,\n",
    "            1 AS fe_count\n",
    "        FROM\n",
    "            (\n",
    "\n",
    "               SELECT\n",
    "                   city AS city,\n",
    "                   user_id as customer_id,\n",
    "                   fare_estimate_id,\n",
    "                   CASE \n",
    "                    WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n",
    "                    WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n",
    "                    WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n",
    "                    ELSE 'rest' \n",
    "                END AS time_period,\n",
    "                pickup_cluster,\n",
    "                   date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n",
    "                   yyyymmdd\n",
    "\n",
    "               FROM\n",
    "                   pricing.fare_estimates_enriched\n",
    "               WHERE\n",
    "                   -- coalesce(CAST( (static_surge + dynamic_surge + dynamic_fare) AS DOUBLE), 0 ) > 0\n",
    "                   service_name = '{service}'\n",
    "                   AND city = '{city}'\n",
    "                   AND yyyymmdd >= '{start_date}'\n",
    "                   AND yyyymmdd <= '{end_date}'  \n",
    "         ) fe_tbl\n",
    "    ),\n",
    "\n",
    "    gross_net_orders_tbl as (\n",
    "\n",
    "        SELECT * FROM\n",
    "        (   select\n",
    "                city_name AS city,\n",
    "                estimate_id as fare_estimate_id,\n",
    "                date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n",
    "                yyyymmdd,\n",
    "                CASE \n",
    "                    WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n",
    "                    WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n",
    "                    WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n",
    "                    ELSE 'rest' \n",
    "                END AS time_period,\n",
    "                pickup_cluster,\n",
    "                1 AS gross_order_count,\n",
    "                CASE WHEN order_status='dropped' and spd_fraud_flag = False THEN 1 ELSE 0 END AS net_orders_count_snapshot,\n",
    "                0 AS net_order_count\n",
    "\n",
    "            from\n",
    "                orders.order_logs_snapshot A\n",
    "\n",
    "            where\n",
    "               service_obj_service_name = '{service}'\n",
    "               AND city_name = '{city}'\n",
    "               AND coalesce(CAST( (surge) AS DOUBLE), 0 ) > 0\n",
    "               AND yyyymmdd >= '{start_date}'\n",
    "               AND yyyymmdd <= '{end_date}'\n",
    "            )\n",
    "    ),\n",
    "\n",
    "    gross_net_orders_tbl_all as (\n",
    "\n",
    "        SELECT * FROM\n",
    "        (   select\n",
    "                city_name AS city,\n",
    "                estimate_id as fare_estimate_id,\n",
    "                date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n",
    "                yyyymmdd,\n",
    "                CASE \n",
    "                    WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n",
    "                    WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n",
    "                    WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n",
    "                    ELSE 'rest' \n",
    "                END AS time_period,\n",
    "                pickup_cluster,\n",
    "                1 AS gross_order_count,\n",
    "                CASE WHEN order_status='dropped' and spd_fraud_flag = False THEN 1 ELSE 0 END AS net_orders_count_snapshot,\n",
    "                0 AS net_order_count\n",
    "\n",
    "            from\n",
    "                orders.order_logs_snapshot A\n",
    "            where\n",
    "               service_obj_service_name = '{service}'\n",
    "               AND city_name = '{city}' \n",
    "               AND yyyymmdd >= '{start_date}'\n",
    "               AND yyyymmdd <= '{end_date}'\n",
    "            )\n",
    "    ),\n",
    "\n",
    "    surged_orders_count as (\n",
    "    SELECT \n",
    "        pickup_cluster\n",
    "        ,orderdate\n",
    "        ,yyyymmdd\n",
    "        ,time_period\n",
    "        ,SUM(fe_count) AS fe_count\n",
    "        ,SUM(gross_order_count) AS gross_order_count\n",
    "        ,SUM(net_orders_count_snapshot) AS net_orders_count_snapshot\n",
    "        --,SUM(net_order_count) AS net_order_count\n",
    "        FROM\n",
    "        (\n",
    "\n",
    "            SELECT\n",
    "                fe_merged.city AS city,\n",
    "                fe_merged.customer_id AS customer_id,\n",
    "                fe_merged.fare_estimate_id AS fare_estimate_id,\n",
    "                fe_merged.orderdate AS orderdate,\n",
    "                fe_merged.yyyymmdd AS yyyymmdd,\n",
    "                fe_merged.time_period AS time_period,\n",
    "                fe_merged.pickup_cluster AS pickup_cluster,\n",
    "                fe_merged.fe_count AS fe_count,\n",
    "                coalesce(gross_net_orders_tbl.gross_order_count,0) AS gross_order_count,\n",
    "                coalesce(gross_net_orders_tbl.net_orders_count_snapshot ,0) AS net_orders_count_snapshot,\n",
    "                coalesce(gross_net_orders_tbl.net_order_count    ,0) AS net_order_count\n",
    "            FROM\n",
    "                fe_merged\n",
    "            LEFT JOIN \n",
    "                gross_net_orders_tbl \n",
    "            ON \n",
    "                gross_net_orders_tbl.fare_estimate_id=fe_merged.fare_estimate_id\n",
    "            AND \n",
    "                fe_merged.city = gross_net_orders_tbl.city\n",
    "            AND \n",
    "                fe_merged.orderdate = gross_net_orders_tbl.orderdate\n",
    "            AND \n",
    "                fe_merged.time_period = gross_net_orders_tbl.time_period\n",
    "            AND \n",
    "                fe_merged.pickup_cluster = gross_net_orders_tbl.pickup_cluster\n",
    "\n",
    "\n",
    "        ) A\n",
    "        GROUP BY 1,2,3,4\n",
    "        ORDER BY 1,2,3,4\n",
    "    ),\n",
    "\n",
    "    all_orders_count as (\n",
    "    SELECT \n",
    "          pickup_cluster\n",
    "         ,orderdate\n",
    "         ,yyyymmdd\n",
    "         ,time_period\n",
    "        ,SUM(fe_count) AS fe_count_all\n",
    "        ,SUM(gross_order_count) AS gross_order_count_all\n",
    "        ,SUM(net_orders_count_snapshot) AS net_orders_count_snapshot_all\n",
    "        --,SUM(net_order_count) AS net_order_count\n",
    "        FROM\n",
    "        (\n",
    "\n",
    "            SELECT\n",
    "\n",
    "                fe_surged_non_surged_ord.city AS city,\n",
    "                fe_surged_non_surged_ord.customer_id AS customer_id,\n",
    "                fe_surged_non_surged_ord.fare_estimate_id AS fare_estimate_id,\n",
    "                fe_surged_non_surged_ord.orderdate AS orderdate,\n",
    "                fe_surged_non_surged_ord.yyyymmdd AS yyyymmdd,\n",
    "                fe_surged_non_surged_ord.time_period AS time_period,\n",
    "                fe_surged_non_surged_ord.pickup_cluster AS pickup_cluster,\n",
    "                fe_surged_non_surged_ord.fe_count AS fe_count,\n",
    "                coalesce(gross_net_orders_tbl_all.gross_order_count,0) AS gross_order_count,\n",
    "                coalesce(gross_net_orders_tbl_all.net_orders_count_snapshot ,0) AS net_orders_count_snapshot,\n",
    "                coalesce(gross_net_orders_tbl_all.net_order_count    ,0) AS net_order_count\n",
    "            FROM\n",
    "                fe_surged_non_surged_ord\n",
    "            LEFT JOIN \n",
    "                gross_net_orders_tbl_all \n",
    "            ON \n",
    "                gross_net_orders_tbl_all.fare_estimate_id=fe_surged_non_surged_ord.fare_estimate_id\n",
    "            AND \n",
    "                fe_surged_non_surged_ord.city = gross_net_orders_tbl_all.city\n",
    "            AND \n",
    "                fe_surged_non_surged_ord.orderdate = gross_net_orders_tbl_all.orderdate\n",
    "            AND \n",
    "                fe_surged_non_surged_ord.time_period = gross_net_orders_tbl_all.time_period\n",
    "            AND \n",
    "                fe_surged_non_surged_ord.pickup_cluster = gross_net_orders_tbl_all.pickup_cluster\n",
    "        ) A\n",
    "        GROUP BY 1,2,3,4\n",
    "        ORDER BY 1,2,3,4\n",
    "    )\n",
    "\n",
    "    SELECT \n",
    "        surged_ord_all.pickup_cluster,\n",
    "        surged_ord_all.orderdate,\n",
    "        surged_ord_all.yyyymmdd,\n",
    "        surged_ord_all.time_period,\n",
    "        fe_count,\n",
    "        gross_order_count,\n",
    "        net_orders_count_snapshot,\n",
    "        fe_count_all,\n",
    "        gross_order_count_all,\n",
    "        net_orders_count_snapshot_all,\n",
    "        ROUND((100 * CAST(surged_ord.fe_count AS DOUBLE)) / NULLIF(surged_ord_all.fe_count_all,0),4) as fe_contri_percent,\n",
    "        ROUND((100 * CAST(surged_ord.gross_order_count AS DOUBLE)) / NULLIF(surged_ord_all.gross_order_count_all,0),4) as gross_contri_percent,\n",
    "        ROUND((100 * CAST(surged_ord.net_orders_count_snapshot AS DOUBLE)) / NULLIF(surged_ord_all.net_orders_count_snapshot_all,0),4) as net_contri_percent\n",
    "    FROM \n",
    "        surged_orders_count surged_ord\n",
    "    JOIN \n",
    "        all_orders_count surged_ord_all\n",
    "        ON \n",
    "            surged_ord.orderdate = surged_ord_all.orderdate\n",
    "        AND \n",
    "            surged_ord.time_period = surged_ord_all.time_period\n",
    "        AND \n",
    "            surged_ord.pickup_cluster = surged_ord_all.pickup_cluster\n",
    "    ORDER BY \n",
    "        1,2,3,4\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j7/5rtfb17j30s9g9q790v9nr0h0000gn/T/ipykernel_31543/847345064.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_raw_dataset = pd.read_sql(raw_dataset, connection)\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql: \n\n    WITH \n    fe_merged AS (\n        SELECT\n            city,\n            customer_id,\n            fe_tbl.fare_estimate_id AS fare_estimate_id,\n            pickup_cluster,\n            yyyymmdd,\n            orderdate,\n            time_period,\n            1 AS fe_count\n        FROM\n            (\n\n               SELECT\n                   city AS city,\n                   user_id as customer_id,\n                   fare_estimate_id,\n                   CASE \n                        WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n                        WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n                        WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n                        ELSE 'rest' \n                    END AS time_period,\n                    pickup_cluster,\n                   date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n                   yyyymmdd\n\n               FROM\n                   pricing.fare_estimates_enriched\n               WHERE\n                   coalesce(CAST( (static_surge + dynamic_surge + dynamic_fare) AS DOUBLE), 0 ) > 0\n                   AND service_name = 'Link'\n                   AND city = 'Chennai'\n                   AND yyyymmdd >= '20230710'\n                   AND yyyymmdd <= '20230723'  \n\n         ) fe_tbl\n    ),\n\n    fe_surged_non_surged_ord AS (\n        SELECT\n            city,\n            customer_id,\n            fe_tbl.fare_estimate_id AS fare_estimate_id,\n            pickup_cluster,\n            yyyymmdd,\n            orderdate,\n            time_period,\n            1 AS fe_count\n        FROM\n            (\n\n               SELECT\n                   city AS city,\n                   user_id as customer_id,\n                   fare_estimate_id,\n                   CASE \n                    WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n                    ELSE 'rest' \n                END AS time_period,\n                pickup_cluster,\n                   date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n                   yyyymmdd\n\n               FROM\n                   pricing.fare_estimates_enriched\n               WHERE\n                   -- coalesce(CAST( (static_surge + dynamic_surge + dynamic_fare) AS DOUBLE), 0 ) > 0\n                   service_name = 'Link'\n                   AND city = 'Chennai'\n                   AND yyyymmdd >= '20230710'\n                   AND yyyymmdd <= '20230723'  \n         ) fe_tbl\n    ),\n\n    gross_net_orders_tbl as (\n\n        SELECT * FROM\n        (   select\n                city_name AS city,\n                estimate_id as fare_estimate_id,\n                date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n                yyyymmdd,\n                CASE \n                    WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n                    ELSE 'rest' \n                END AS time_period,\n                pickup_cluster,\n                1 AS gross_order_count,\n                CASE WHEN order_status='dropped' and spd_fraud_flag = False THEN 1 ELSE 0 END AS net_orders_count_snapshot,\n                0 AS net_order_count\n\n            from\n                orders.order_logs_snapshot A\n\n            where\n               service_obj_service_name = 'Link'\n               AND city_name = 'Chennai'\n               AND coalesce(CAST( (surge) AS DOUBLE), 0 ) > 0\n               AND yyyymmdd >= '20230710'\n               AND yyyymmdd <= '20230723'\n            )\n    ),\n\n    gross_net_orders_tbl_all as (\n\n        SELECT * FROM\n        (   select\n                city_name AS city,\n                estimate_id as fare_estimate_id,\n                date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n                yyyymmdd,\n                CASE \n                    WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n                    ELSE 'rest' \n                END AS time_period,\n                pickup_cluster,\n                1 AS gross_order_count,\n                CASE WHEN order_status='dropped' and spd_fraud_flag = False THEN 1 ELSE 0 END AS net_orders_count_snapshot,\n                0 AS net_order_count\n\n            from\n                orders.order_logs_snapshot A\n            where\n               service_obj_service_name = 'Link'\n               AND city_name = 'Chennai' \n               AND yyyymmdd >= '20230710'\n               AND yyyymmdd <= '20230723'\n            )\n    ),\n\n    surged_orders_count as (\n    SELECT \n        pickup_cluster\n        ,orderdate\n        ,yyyymmdd\n        ,time_period\n        ,SUM(fe_count) AS fe_count\n        ,SUM(gross_order_count) AS gross_order_count\n        ,SUM(net_orders_count_snapshot) AS net_orders_count_snapshot\n        --,SUM(net_order_count) AS net_order_count\n        FROM\n        (\n\n            SELECT\n                fe_merged.city AS city,\n                fe_merged.customer_id AS customer_id,\n                fe_merged.fare_estimate_id AS fare_estimate_id,\n                fe_merged.orderdate AS orderdate,\n                fe_merged.yyyymmdd AS yyyymmdd,\n                fe_merged.time_period AS time_period,\n                fe_merged.pickup_cluster AS pickup_cluster,\n                fe_merged.fe_count AS fe_count,\n                coalesce(gross_net_orders_tbl.gross_order_count,0) AS gross_order_count,\n                coalesce(gross_net_orders_tbl.net_orders_count_snapshot ,0) AS net_orders_count_snapshot,\n                coalesce(gross_net_orders_tbl.net_order_count    ,0) AS net_order_count\n            FROM\n                fe_merged\n            LEFT JOIN \n                gross_net_orders_tbl \n            ON \n                gross_net_orders_tbl.fare_estimate_id=fe_merged.fare_estimate_id\n            AND \n                fe_merged.city = gross_net_orders_tbl.city\n            AND \n                fe_merged.orderdate = gross_net_orders_tbl.orderdate\n            AND \n                fe_merged.time_period = gross_net_orders_tbl.time_period\n            AND \n                fe_merged.pickup_cluster = gross_net_orders_tbl.pickup_cluster\n\n\n        ) A\n        GROUP BY 1,2,3,4\n        ORDER BY 1,2,3,4\n    ),\n\n    all_orders_count as (\n    SELECT \n          pickup_cluster\n         ,orderdate\n         ,yyyymmdd\n         ,time_period\n        ,SUM(fe_count) AS fe_count_all\n        ,SUM(gross_order_count) AS gross_order_count_all\n        ,SUM(net_orders_count_snapshot) AS net_orders_count_snapshot_all\n        --,SUM(net_order_count) AS net_order_count\n        FROM\n        (\n\n            SELECT\n\n                fe_surged_non_surged_ord.city AS city,\n                fe_surged_non_surged_ord.customer_id AS customer_id,\n                fe_surged_non_surged_ord.fare_estimate_id AS fare_estimate_id,\n                fe_surged_non_surged_ord.orderdate AS orderdate,\n                fe_surged_non_surged_ord.yyyymmdd AS yyyymmdd,\n                fe_surged_non_surged_ord.time_period AS time_period,\n                fe_surged_non_surged_ord.pickup_cluster AS pickup_cluster,\n                fe_surged_non_surged_ord.fe_count AS fe_count,\n                coalesce(gross_net_orders_tbl_all.gross_order_count,0) AS gross_order_count,\n                coalesce(gross_net_orders_tbl_all.net_orders_count_snapshot ,0) AS net_orders_count_snapshot,\n                coalesce(gross_net_orders_tbl_all.net_order_count    ,0) AS net_order_count\n            FROM\n                fe_surged_non_surged_ord\n            LEFT JOIN \n                gross_net_orders_tbl_all \n            ON \n                gross_net_orders_tbl_all.fare_estimate_id=fe_surged_non_surged_ord.fare_estimate_id\n            AND \n                fe_surged_non_surged_ord.city = gross_net_orders_tbl_all.city\n            AND \n                fe_surged_non_surged_ord.orderdate = gross_net_orders_tbl_all.orderdate\n            AND \n                fe_surged_non_surged_ord.time_period = gross_net_orders_tbl_all.time_period\n            AND \n                fe_surged_non_surged_ord.pickup_cluster = gross_net_orders_tbl_all.pickup_cluster\n        ) A\n        GROUP BY 1,2,3,4\n        ORDER BY 1,2,3,4\n    )\n\n    SELECT \n        surged_ord_all.pickup_cluster,\n        surged_ord_all.orderdate,\n        surged_ord_all.yyyymmdd,\n        surged_ord_all.time_period,\n        fe_count,\n        gross_order_count,\n        net_orders_count_snapshot,\n        fe_count_all,\n        gross_order_count_all,\n        net_orders_count_snapshot_all,\n        ROUND((100 * CAST(surged_ord.fe_count AS DOUBLE)) / NULLIF(surged_ord_all.fe_count_all,0),4) as fe_contri_percent,\n        ROUND((100 * CAST(surged_ord.gross_order_count AS DOUBLE)) / NULLIF(surged_ord_all.gross_order_count_all,0),4) as gross_contri_percent,\n        ROUND((100 * CAST(surged_ord.net_orders_count_snapshot AS DOUBLE)) / NULLIF(surged_ord_all.net_orders_count_snapshot_all,0),4) as net_contri_percent\n    FROM \n        surged_orders_count surged_ord\n    JOIN \n        all_orders_count surged_ord_all\n        ON \n            surged_ord.orderdate = surged_ord_all.orderdate\n        AND \n            surged_ord.time_period = surged_ord_all.time_period\n        AND \n            surged_ord.pickup_cluster = surged_ord_all.pickup_cluster\n    ORDER BY \n        1,2,3,4\n\n\nHTTPConnectionPool(host='presto-gateway.serving.data.production.internal', port=80): Max retries exceeded with url: /v1/statement (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f87cac3bf10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\nunable to rollback",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhttplib_request_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/urllib3/connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f87cac3bf10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='presto-gateway.serving.data.production.internal', port=80): Max retries exceeded with url: /v1/statement (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f87cac3bf10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/sql.py:2018\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2018\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pyhive/presto.py:276\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, operation, parameters)\u001b[0m\n\u001b[1;32m    275\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeaders: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, headers)\n\u001b[0;32m--> 276\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(response)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/requests/adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='presto-gateway.serving.data.production.internal', port=80): Max retries exceeded with url: /v1/statement (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f87cac3bf10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotSupportedError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/sql.py:2022\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2022\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pyhive/presto.py:88\u001b[0m, in \u001b[0;36mConnection.rollback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrollback\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotSupportedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPresto does not have transactions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotSupportedError\u001b[0m: Presto does not have transactions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_raw_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_raw_dataset\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/sql.py:564\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    561\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    574\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/sql.py:2078\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2067\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2068\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2074\u001b[0m     dtype: DtypeArg \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2075\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m   2077\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> 2078\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2079\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/sql.py:2027\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m     ex \u001b[38;5;241m=\u001b[39m DatabaseError(\n\u001b[1;32m   2025\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124munable to rollback\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2026\u001b[0m     )\n\u001b[0;32m-> 2027\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2029\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql: \n\n    WITH \n    fe_merged AS (\n        SELECT\n            city,\n            customer_id,\n            fe_tbl.fare_estimate_id AS fare_estimate_id,\n            pickup_cluster,\n            yyyymmdd,\n            orderdate,\n            time_period,\n            1 AS fe_count\n        FROM\n            (\n\n               SELECT\n                   city AS city,\n                   user_id as customer_id,\n                   fare_estimate_id,\n                   CASE \n                        WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n                        WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n                        WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n                        ELSE 'rest' \n                    END AS time_period,\n                    pickup_cluster,\n                   date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n                   yyyymmdd\n\n               FROM\n                   pricing.fare_estimates_enriched\n               WHERE\n                   coalesce(CAST( (static_surge + dynamic_surge + dynamic_fare) AS DOUBLE), 0 ) > 0\n                   AND service_name = 'Link'\n                   AND city = 'Chennai'\n                   AND yyyymmdd >= '20230710'\n                   AND yyyymmdd <= '20230723'  \n\n         ) fe_tbl\n    ),\n\n    fe_surged_non_surged_ord AS (\n        SELECT\n            city,\n            customer_id,\n            fe_tbl.fare_estimate_id AS fare_estimate_id,\n            pickup_cluster,\n            yyyymmdd,\n            orderdate,\n            time_period,\n            1 AS fe_count\n        FROM\n            (\n\n               SELECT\n                   city AS city,\n                   user_id as customer_id,\n                   fare_estimate_id,\n                   CASE \n                    WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n                    ELSE 'rest' \n                END AS time_period,\n                pickup_cluster,\n                   date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n                   yyyymmdd\n\n               FROM\n                   pricing.fare_estimates_enriched\n               WHERE\n                   -- coalesce(CAST( (static_surge + dynamic_surge + dynamic_fare) AS DOUBLE), 0 ) > 0\n                   service_name = 'Link'\n                   AND city = 'Chennai'\n                   AND yyyymmdd >= '20230710'\n                   AND yyyymmdd <= '20230723'  \n         ) fe_tbl\n    ),\n\n    gross_net_orders_tbl as (\n\n        SELECT * FROM\n        (   select\n                city_name AS city,\n                estimate_id as fare_estimate_id,\n                date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n                yyyymmdd,\n                CASE \n                    WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n                    ELSE 'rest' \n                END AS time_period,\n                pickup_cluster,\n                1 AS gross_order_count,\n                CASE WHEN order_status='dropped' and spd_fraud_flag = False THEN 1 ELSE 0 END AS net_orders_count_snapshot,\n                0 AS net_order_count\n\n            from\n                orders.order_logs_snapshot A\n\n            where\n               service_obj_service_name = 'Link'\n               AND city_name = 'Chennai'\n               AND coalesce(CAST( (surge) AS DOUBLE), 0 ) > 0\n               AND yyyymmdd >= '20230710'\n               AND yyyymmdd <= '20230723'\n            )\n    ),\n\n    gross_net_orders_tbl_all as (\n\n        SELECT * FROM\n        (   select\n                city_name AS city,\n                estimate_id as fare_estimate_id,\n                date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,\n                yyyymmdd,\n                CASE \n                    WHEN substr(quarter_hour,1,2) IN ('08','09','10') THEN 'morning_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('11','12','13','14','15','16') THEN 'afternoon_peak'\n                    WHEN substr(quarter_hour,1,2) IN ('17','18','19','20') THEN 'evening_peak'\n                    ELSE 'rest' \n                END AS time_period,\n                pickup_cluster,\n                1 AS gross_order_count,\n                CASE WHEN order_status='dropped' and spd_fraud_flag = False THEN 1 ELSE 0 END AS net_orders_count_snapshot,\n                0 AS net_order_count\n\n            from\n                orders.order_logs_snapshot A\n            where\n               service_obj_service_name = 'Link'\n               AND city_name = 'Chennai' \n               AND yyyymmdd >= '20230710'\n               AND yyyymmdd <= '20230723'\n            )\n    ),\n\n    surged_orders_count as (\n    SELECT \n        pickup_cluster\n        ,orderdate\n        ,yyyymmdd\n        ,time_period\n        ,SUM(fe_count) AS fe_count\n        ,SUM(gross_order_count) AS gross_order_count\n        ,SUM(net_orders_count_snapshot) AS net_orders_count_snapshot\n        --,SUM(net_order_count) AS net_order_count\n        FROM\n        (\n\n            SELECT\n                fe_merged.city AS city,\n                fe_merged.customer_id AS customer_id,\n                fe_merged.fare_estimate_id AS fare_estimate_id,\n                fe_merged.orderdate AS orderdate,\n                fe_merged.yyyymmdd AS yyyymmdd,\n                fe_merged.time_period AS time_period,\n                fe_merged.pickup_cluster AS pickup_cluster,\n                fe_merged.fe_count AS fe_count,\n                coalesce(gross_net_orders_tbl.gross_order_count,0) AS gross_order_count,\n                coalesce(gross_net_orders_tbl.net_orders_count_snapshot ,0) AS net_orders_count_snapshot,\n                coalesce(gross_net_orders_tbl.net_order_count    ,0) AS net_order_count\n            FROM\n                fe_merged\n            LEFT JOIN \n                gross_net_orders_tbl \n            ON \n                gross_net_orders_tbl.fare_estimate_id=fe_merged.fare_estimate_id\n            AND \n                fe_merged.city = gross_net_orders_tbl.city\n            AND \n                fe_merged.orderdate = gross_net_orders_tbl.orderdate\n            AND \n                fe_merged.time_period = gross_net_orders_tbl.time_period\n            AND \n                fe_merged.pickup_cluster = gross_net_orders_tbl.pickup_cluster\n\n\n        ) A\n        GROUP BY 1,2,3,4\n        ORDER BY 1,2,3,4\n    ),\n\n    all_orders_count as (\n    SELECT \n          pickup_cluster\n         ,orderdate\n         ,yyyymmdd\n         ,time_period\n        ,SUM(fe_count) AS fe_count_all\n        ,SUM(gross_order_count) AS gross_order_count_all\n        ,SUM(net_orders_count_snapshot) AS net_orders_count_snapshot_all\n        --,SUM(net_order_count) AS net_order_count\n        FROM\n        (\n\n            SELECT\n\n                fe_surged_non_surged_ord.city AS city,\n                fe_surged_non_surged_ord.customer_id AS customer_id,\n                fe_surged_non_surged_ord.fare_estimate_id AS fare_estimate_id,\n                fe_surged_non_surged_ord.orderdate AS orderdate,\n                fe_surged_non_surged_ord.yyyymmdd AS yyyymmdd,\n                fe_surged_non_surged_ord.time_period AS time_period,\n                fe_surged_non_surged_ord.pickup_cluster AS pickup_cluster,\n                fe_surged_non_surged_ord.fe_count AS fe_count,\n                coalesce(gross_net_orders_tbl_all.gross_order_count,0) AS gross_order_count,\n                coalesce(gross_net_orders_tbl_all.net_orders_count_snapshot ,0) AS net_orders_count_snapshot,\n                coalesce(gross_net_orders_tbl_all.net_order_count    ,0) AS net_order_count\n            FROM\n                fe_surged_non_surged_ord\n            LEFT JOIN \n                gross_net_orders_tbl_all \n            ON \n                gross_net_orders_tbl_all.fare_estimate_id=fe_surged_non_surged_ord.fare_estimate_id\n            AND \n                fe_surged_non_surged_ord.city = gross_net_orders_tbl_all.city\n            AND \n                fe_surged_non_surged_ord.orderdate = gross_net_orders_tbl_all.orderdate\n            AND \n                fe_surged_non_surged_ord.time_period = gross_net_orders_tbl_all.time_period\n            AND \n                fe_surged_non_surged_ord.pickup_cluster = gross_net_orders_tbl_all.pickup_cluster\n        ) A\n        GROUP BY 1,2,3,4\n        ORDER BY 1,2,3,4\n    )\n\n    SELECT \n        surged_ord_all.pickup_cluster,\n        surged_ord_all.orderdate,\n        surged_ord_all.yyyymmdd,\n        surged_ord_all.time_period,\n        fe_count,\n        gross_order_count,\n        net_orders_count_snapshot,\n        fe_count_all,\n        gross_order_count_all,\n        net_orders_count_snapshot_all,\n        ROUND((100 * CAST(surged_ord.fe_count AS DOUBLE)) / NULLIF(surged_ord_all.fe_count_all,0),4) as fe_contri_percent,\n        ROUND((100 * CAST(surged_ord.gross_order_count AS DOUBLE)) / NULLIF(surged_ord_all.gross_order_count_all,0),4) as gross_contri_percent,\n        ROUND((100 * CAST(surged_ord.net_orders_count_snapshot AS DOUBLE)) / NULLIF(surged_ord_all.net_orders_count_snapshot_all,0),4) as net_contri_percent\n    FROM \n        surged_orders_count surged_ord\n    JOIN \n        all_orders_count surged_ord_all\n        ON \n            surged_ord.orderdate = surged_ord_all.orderdate\n        AND \n            surged_ord.time_period = surged_ord_all.time_period\n        AND \n            surged_ord.pickup_cluster = surged_ord_all.pickup_cluster\n    ORDER BY \n        1,2,3,4\n\n\nHTTPConnectionPool(host='presto-gateway.serving.data.production.internal', port=80): Max retries exceeded with url: /v1/statement (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f87cac3bf10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\nunable to rollback"
     ]
    }
   ],
   "source": [
    "df_raw_dataset = pd.read_sql(raw_dataset, connection)\n",
    "df_raw_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_dataset.to_csv('/Users/rapido/local-datasets/non-peak-demand/raw/raw_data_surged_orders_contri_analysis_{}_{}_{}_to_{}.csv' \\\n",
    "                                .format(city, service,start_date,end_date)\n",
    "                               , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Adambakkam', 'Adyar', 'Alamathi', 'Alandur', 'Allapakkam',\n",
       "       'Alwarpet', 'Alwarthirunagar', 'Ambattur',\n",
       "       'Ambattur Industrial Estate', 'Ambattur OT', 'Anakaputhur',\n",
       "       'Anna Nagar', 'Anna Nagar East', 'Annanur', 'Arasankalani',\n",
       "       'Arumbakkam 2', 'Ashok Nagar Chennai', 'Avadi', 'Ayanambakkam',\n",
       "       'Ayappakkam', 'Baby Nagar Velachery', 'Balaji Nagar',\n",
       "       'Basin Bridge', 'Beasant Avenue', 'Beasant Nagar',\n",
       "       'CHN CHETTINAD HEALTH CITY', 'CHN GUDUVANCHERY', 'CHN KANDIGAI',\n",
       "       'CHN KELAMBAKKAM', 'CHN MAMBAKKAM', 'CHN MURUGAMANGALAM',\n",
       "       'CHN SRM UNIVERSITY', 'CHN URAPAKKAM', 'CHN VANDALUR', 'CMBT',\n",
       "       'Chembarambakkam', 'Chennai Beach', 'Chennai Central',\n",
       "       'Chennai International Airport', 'Chennai One IT park ', 'Chepauk',\n",
       "       'Choolai', 'Chromepet', 'ECR Beach', 'East Tambaram', 'Egmore',\n",
       "       'Egmore Metro', 'Ekkatutthangal Metro', 'Ennore', 'Guindy',\n",
       "       'Guindy 3', 'Guindy Madras Race Club', 'Guindy National Park',\n",
       "       'Guru Nanak College', 'IIT Madras Velachery', 'Kadanchavadi',\n",
       "       'Kamarajapuram  Ambattur', 'Kannadapalayam', 'Kathipara',\n",
       "       'Kattupakkam', 'Keelkattalai', 'Keelkattalai 2', 'Keelkattalai 3',\n",
       "       'Kolathur', 'Korattur', 'Kotturpuram', 'Koyambedu', 'Kundrathur',\n",
       "       'Little Mount Metro', 'Madhanandapuram', 'Madhavaram',\n",
       "       'Madipakkam', 'Maduravoyal', 'Manali', 'Manapakkam', 'Mangadu',\n",
       "       'Mangadu 2', 'Maraimalai Nagar', 'Medavakkam Central',\n",
       "       'Meenambakkam', 'Mogappair East', 'Mogappair West', 'Mugalivakkam',\n",
       "       'Mylapore', 'N.I.W.E', 'Nandambakkam', 'Nanganallur',\n",
       "       'New Vellanur', 'Nolambur', 'Nungambakkam', 'Padianallur',\n",
       "       'Palavakkam', 'Palavanthangal', 'Pallavaram', 'Pallikaranai',\n",
       "       'Panaiyur', 'Park Town', 'Parrys', 'Pattabiram', 'Pennagaram',\n",
       "       'Perambur', 'Perumbakkam', 'Perungalattur', 'Perungudi ',\n",
       "       'Perungudi 2', 'Poonamallee', 'Porur', 'Porur Lake',\n",
       "       'Purasaiwalkam', 'Ramapuram', 'Red Hills', 'Retteri Lake',\n",
       "       'Royapettah', 'Royapuram', 'SRM Dental College',\n",
       "       'SRM Institute of Science Ramapuram', 'Saidapet',\n",
       "       'Saidapet Metro ', 'Saligragam', 'Santoshpuram', 'Semmancheri',\n",
       "       'Shenoy Nagar', 'Sholinganallur', 'Sholinganallur ELCOT',\n",
       "       'Siruseri', 'Sithalapakkam', 'Surya Nagar', 'T Nagar', 'Tambaram',\n",
       "       'Taramani', 'Teynampet', 'Thanikachalam Nagar', 'Thirumallaivoyal',\n",
       "       'Thiruvanmiyur', 'Thiruverkadu', 'Thoraipakkam',\n",
       "       'Thousand Lights Metro', 'Tiruvanmiyur Beach', 'Tiruvottiyur',\n",
       "       'Tondiarpet', 'Triplicane', 'VIrugambakkam', 'Vadapalani',\n",
       "       'Vadapalani East', 'Vadapalani Fortis Hospital ',\n",
       "       'Vadapalani Thirunagar', 'Vanagaram', 'Vel Tech College',\n",
       "       'Velachery', 'Velachery Lake', 'Vengaivasal', 'Villivakkam',\n",
       "       'Vyasarpadi', 'Washermanpet', 'West Koyambedu', 'West Tambaram',\n",
       "       'kilpauk', 'puzhal'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surged_orders_contri_cluster_level = pd.read_csv('/Users/rapido/local-datasets/non-peak-demand/raw/raw_data_surged_orders_contri_analysis_{}_{}_{}_to_{}.csv' \\\n",
    "                                                 .format(city, service,start_date,end_date))\n",
    "\n",
    "surged_orders_contri_cluster_level.pickup_cluster.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>time_period</th>\n",
       "      <th>fe_count</th>\n",
       "      <th>gross_order_count</th>\n",
       "      <th>net_orders_count_snapshot</th>\n",
       "      <th>fe_count_all</th>\n",
       "      <th>gross_order_count_all</th>\n",
       "      <th>net_orders_count_snapshot_all</th>\n",
       "      <th>fe_contri_percent</th>\n",
       "      <th>gross_contri_percent</th>\n",
       "      <th>net_contri_percent</th>\n",
       "      <th>week_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>20230710</td>\n",
       "      <td>afternoon_peak</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>263</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>16.7300</td>\n",
       "      <td>20.5128</td>\n",
       "      <td>33.3333</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>20230710</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7.6923</td>\n",
       "      <td>6.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>20230710</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>37.5000</td>\n",
       "      <td>16.1290</td>\n",
       "      <td>6.6667</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>20230711</td>\n",
       "      <td>afternoon_peak</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>7.6923</td>\n",
       "      <td>2.8571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>20230711</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>5.5276</td>\n",
       "      <td>10.5263</td>\n",
       "      <td>12.5000</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pickup_cluster   orderdate  yyyymmdd     time_period  fe_count  \\\n",
       "0            NaN  2023-07-10  20230710  afternoon_peak        44   \n",
       "1            NaN  2023-07-10  20230710    evening_peak        13   \n",
       "2            NaN  2023-07-10  20230710    morning_peak        57   \n",
       "3            NaN  2023-07-11  20230711  afternoon_peak        16   \n",
       "4            NaN  2023-07-11  20230711    evening_peak        11   \n",
       "\n",
       "   gross_order_count  net_orders_count_snapshot  fe_count_all  \\\n",
       "0                  8                          5           263   \n",
       "1                  1                          0           169   \n",
       "2                  5                          1           152   \n",
       "3                  1                          0           208   \n",
       "4                  2                          1           199   \n",
       "\n",
       "   gross_order_count_all  net_orders_count_snapshot_all  fe_contri_percent  \\\n",
       "0                     39                             15            16.7300   \n",
       "1                     16                              7             7.6923   \n",
       "2                     31                             15            37.5000   \n",
       "3                     35                             17             7.6923   \n",
       "4                     19                              8             5.5276   \n",
       "\n",
       "   gross_contri_percent  net_contri_percent week_period  \n",
       "0               20.5128             33.3333      Monday  \n",
       "1                6.2500              0.0000      Monday  \n",
       "2               16.1290              6.6667      Monday  \n",
       "3                2.8571              0.0000     Tuesday  \n",
       "4               10.5263             12.5000     Tuesday  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surged_orders_contri_cluster_level['week_period'] = surged_orders_contri_cluster_level['yyyymmdd'].map(\n",
    "    lambda x: datetime.strptime(str(x), '%Y%m%d').strftime('%A')\n",
    ")\n",
    "\n",
    "surged_orders_contri_cluster_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "surged_orders_contri_cluster_level.loc[\n",
    "    (surged_orders_contri_cluster_level['time_period'] == 'afternoon_peak'), 'time_period' ] = 'afternoon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>time_period</th>\n",
       "      <th>fe_count</th>\n",
       "      <th>gross_order_count</th>\n",
       "      <th>net_orders_count_snapshot</th>\n",
       "      <th>fe_count_all</th>\n",
       "      <th>gross_order_count_all</th>\n",
       "      <th>net_orders_count_snapshot_all</th>\n",
       "      <th>fe_contri_percent</th>\n",
       "      <th>gross_contri_percent</th>\n",
       "      <th>net_contri_percent</th>\n",
       "      <th>week_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>20230710</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>263</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>16.7300</td>\n",
       "      <td>20.5128</td>\n",
       "      <td>33.3333</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>20230710</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7.6923</td>\n",
       "      <td>6.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>20230710</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>37.5000</td>\n",
       "      <td>16.1290</td>\n",
       "      <td>6.6667</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>20230711</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>7.6923</td>\n",
       "      <td>2.8571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>20230711</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>5.5276</td>\n",
       "      <td>10.5263</td>\n",
       "      <td>12.5000</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pickup_cluster   orderdate  yyyymmdd   time_period  fe_count  \\\n",
       "0            NaN  2023-07-10  20230710     afternoon        44   \n",
       "1            NaN  2023-07-10  20230710  evening_peak        13   \n",
       "2            NaN  2023-07-10  20230710  morning_peak        57   \n",
       "3            NaN  2023-07-11  20230711     afternoon        16   \n",
       "4            NaN  2023-07-11  20230711  evening_peak        11   \n",
       "\n",
       "   gross_order_count  net_orders_count_snapshot  fe_count_all  \\\n",
       "0                  8                          5           263   \n",
       "1                  1                          0           169   \n",
       "2                  5                          1           152   \n",
       "3                  1                          0           208   \n",
       "4                  2                          1           199   \n",
       "\n",
       "   gross_order_count_all  net_orders_count_snapshot_all  fe_contri_percent  \\\n",
       "0                     39                             15            16.7300   \n",
       "1                     16                              7             7.6923   \n",
       "2                     31                             15            37.5000   \n",
       "3                     35                             17             7.6923   \n",
       "4                     19                              8             5.5276   \n",
       "\n",
       "   gross_contri_percent  net_contri_percent week_period  \n",
       "0               20.5128             33.3333      Monday  \n",
       "1                6.2500              0.0000      Monday  \n",
       "2               16.1290              6.6667      Monday  \n",
       "3                2.8571              0.0000     Tuesday  \n",
       "4               10.5263             12.5000     Tuesday  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surged_orders_contri_cluster_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>city</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>service_detail_id</th>\n",
       "      <th>week_period</th>\n",
       "      <th>time_period</th>\n",
       "      <th>demand</th>\n",
       "      <th>supply</th>\n",
       "      <th>mismatch_qr_level</th>\n",
       "      <th>fe_count</th>\n",
       "      <th>rr_count</th>\n",
       "      <th>net_count</th>\n",
       "      <th>fe_count_med</th>\n",
       "      <th>rr_count_med</th>\n",
       "      <th>net_count_med</th>\n",
       "      <th>mismtach_pred_tp</th>\n",
       "      <th>excess_supply_ratio</th>\n",
       "      <th>is_excess_supply</th>\n",
       "      <th>unique_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Adambakkam</td>\n",
       "      <td>5bed473f1278885df4ea9d57</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>71.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1485</td>\n",
       "      <td>363</td>\n",
       "      <td>270</td>\n",
       "      <td>303.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>1.802817</td>\n",
       "      <td>yes</td>\n",
       "      <td>Adambakkam_Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Ambattur</td>\n",
       "      <td>5bed473f1278885df4ea9d57</td>\n",
       "      <td>Friday</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>53.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>1214</td>\n",
       "      <td>291</td>\n",
       "      <td>201</td>\n",
       "      <td>246.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>1.471698</td>\n",
       "      <td>yes</td>\n",
       "      <td>Ambattur_Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Ambattur</td>\n",
       "      <td>5bed473f1278885df4ea9d57</td>\n",
       "      <td>Friday</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>88.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1577</td>\n",
       "      <td>449</td>\n",
       "      <td>353</td>\n",
       "      <td>311.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>1.318182</td>\n",
       "      <td>yes</td>\n",
       "      <td>Ambattur_Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Ambattur</td>\n",
       "      <td>5bed473f1278885df4ea9d57</td>\n",
       "      <td>Monday</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>79.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1602</td>\n",
       "      <td>414</td>\n",
       "      <td>328</td>\n",
       "      <td>351.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1.215190</td>\n",
       "      <td>yes</td>\n",
       "      <td>Ambattur_Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Ambattur</td>\n",
       "      <td>5bed473f1278885df4ea9d57</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1637</td>\n",
       "      <td>301</td>\n",
       "      <td>224</td>\n",
       "      <td>342.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>1.228070</td>\n",
       "      <td>yes</td>\n",
       "      <td>Ambattur_Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     city pickup_cluster         service_detail_id week_period  \\\n",
       "0          19  Chennai     Adambakkam  5bed473f1278885df4ea9d57   Wednesday   \n",
       "1         145  Chennai       Ambattur  5bed473f1278885df4ea9d57      Friday   \n",
       "2         146  Chennai       Ambattur  5bed473f1278885df4ea9d57      Friday   \n",
       "3         149  Chennai       Ambattur  5bed473f1278885df4ea9d57      Monday   \n",
       "4         151  Chennai       Ambattur  5bed473f1278885df4ea9d57    Saturday   \n",
       "\n",
       "    time_period  demand  supply  mismatch_qr_level  fe_count  rr_count  \\\n",
       "0  evening_peak    71.0   128.0               -6.0      1485       363   \n",
       "1     afternoon    53.0    78.0               -3.5      1214       291   \n",
       "2  evening_peak    88.0   116.0               -2.0      1577       449   \n",
       "3  evening_peak    79.0    96.0               -3.0      1602       414   \n",
       "4     afternoon    57.0    70.0               -2.0      1637       301   \n",
       "\n",
       "   net_count  fe_count_med  rr_count_med  net_count_med  mismtach_pred_tp  \\\n",
       "0        270         303.0          74.0           56.0             -57.0   \n",
       "1        201         246.0          58.0           41.0             -25.0   \n",
       "2        353         311.0          89.0           67.0             -28.0   \n",
       "3        328         351.0          81.0           66.0             -17.0   \n",
       "4        224         342.0          61.0           44.0             -13.0   \n",
       "\n",
       "   excess_supply_ratio is_excess_supply           unique_name  \n",
       "0             1.802817              yes  Adambakkam_Wednesday  \n",
       "1             1.471698              yes       Ambattur_Friday  \n",
       "2             1.318182              yes       Ambattur_Friday  \n",
       "3             1.215190              yes       Ambattur_Monday  \n",
       "4             1.228070              yes     Ambattur_Saturday  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excess_supply_all_sessions = pd.read_csv('/Users/rapido/local-datasets/non-peak-demand/raw/excess_supply_all_sessions_{}_{}_{}_{}.csv' \\\n",
    "                                        .format(city, service,start_date,end_date))\n",
    "excess_supply_all_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "surged_orders_contri_cluster_level['cluster_week_time'] = surged_orders_contri_cluster_level[\n",
    "    'pickup_cluster'] + '-' + surged_orders_contri_cluster_level[\n",
    "    'week_period'] + '-' + surged_orders_contri_cluster_level['time_period']\n",
    "\n",
    "excess_supply_all_sessions['cluster_week_time'] = excess_supply_all_sessions[\n",
    "    'pickup_cluster'] + '-' + excess_supply_all_sessions['week_period'] + '-' + excess_supply_all_sessions[\n",
    "    'time_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>time_period</th>\n",
       "      <th>fe_count</th>\n",
       "      <th>gross_order_count</th>\n",
       "      <th>net_orders_count_snapshot</th>\n",
       "      <th>fe_count_all</th>\n",
       "      <th>gross_order_count_all</th>\n",
       "      <th>net_orders_count_snapshot_all</th>\n",
       "      <th>fe_contri_percent</th>\n",
       "      <th>gross_contri_percent</th>\n",
       "      <th>net_contri_percent</th>\n",
       "      <th>week_period</th>\n",
       "      <th>cluster_week_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Adambakkam</td>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>20230712</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>147</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>724</td>\n",
       "      <td>160</td>\n",
       "      <td>116</td>\n",
       "      <td>20.3039</td>\n",
       "      <td>16.8750</td>\n",
       "      <td>16.3793</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adambakkam-Wednesday-evening_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Adambakkam</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>20230719</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>633</td>\n",
       "      <td>126</td>\n",
       "      <td>94</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adambakkam-Wednesday-evening_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Ambattur</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>20230710</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>863</td>\n",
       "      <td>187</td>\n",
       "      <td>147</td>\n",
       "      <td>4.0556</td>\n",
       "      <td>4.8128</td>\n",
       "      <td>6.1224</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Ambattur-Monday-evening_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Ambattur</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>20230711</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>244</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>991</td>\n",
       "      <td>203</td>\n",
       "      <td>136</td>\n",
       "      <td>24.6216</td>\n",
       "      <td>20.6897</td>\n",
       "      <td>18.3824</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Ambattur-Tuesday-afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Ambattur</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>20230711</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>81</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>720</td>\n",
       "      <td>186</td>\n",
       "      <td>140</td>\n",
       "      <td>11.2500</td>\n",
       "      <td>13.9785</td>\n",
       "      <td>12.1429</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Ambattur-Tuesday-evening_peak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pickup_cluster   orderdate  yyyymmdd   time_period  fe_count  \\\n",
       "59      Adambakkam  2023-07-12  20230712  evening_peak       147   \n",
       "81      Adambakkam  2023-07-19  20230719  evening_peak         4   \n",
       "356       Ambattur  2023-07-10  20230710  evening_peak        35   \n",
       "358       Ambattur  2023-07-11  20230711     afternoon       244   \n",
       "359       Ambattur  2023-07-11  20230711  evening_peak        81   \n",
       "\n",
       "     gross_order_count  net_orders_count_snapshot  fe_count_all  \\\n",
       "59                  27                         19           724   \n",
       "81                   0                          0           633   \n",
       "356                  9                          9           863   \n",
       "358                 42                         25           991   \n",
       "359                 26                         17           720   \n",
       "\n",
       "     gross_order_count_all  net_orders_count_snapshot_all  fe_contri_percent  \\\n",
       "59                     160                            116            20.3039   \n",
       "81                     126                             94             0.6319   \n",
       "356                    187                            147             4.0556   \n",
       "358                    203                            136            24.6216   \n",
       "359                    186                            140            11.2500   \n",
       "\n",
       "     gross_contri_percent  net_contri_percent week_period  \\\n",
       "59                16.8750             16.3793   Wednesday   \n",
       "81                 0.0000              0.0000   Wednesday   \n",
       "356                4.8128              6.1224      Monday   \n",
       "358               20.6897             18.3824     Tuesday   \n",
       "359               13.9785             12.1429     Tuesday   \n",
       "\n",
       "                     cluster_week_time  \n",
       "59   Adambakkam-Wednesday-evening_peak  \n",
       "81   Adambakkam-Wednesday-evening_peak  \n",
       "356       Ambattur-Monday-evening_peak  \n",
       "358         Ambattur-Tuesday-afternoon  \n",
       "359      Ambattur-Tuesday-evening_peak  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh_clusters_filtered = surged_orders_contri_cluster_level[\n",
    "    surged_orders_contri_cluster_level['cluster_week_time'].isin(\n",
    "        excess_supply_all_sessions['cluster_week_time'].unique().tolist())]\n",
    "\n",
    "lh_clusters_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusing Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surged orders % contribution by these clusters, week period and time peirod combinations during all sessions\n",
      "-------------------------------------------------\n",
      "FE Contribution % 17.33565240640157\n",
      "RR Contribution % 14.251653997747749\n",
      "Net Contribution % 14.475685481057699\n"
     ]
    }
   ],
   "source": [
    "funnel_coverage_calc_data_all_sessions = lh_clusters_filtered[\n",
    "    lh_clusters_filtered['time_period'] != 'rest']\n",
    "\n",
    "fe_countribution = 100*funnel_coverage_calc_data_all_sessions['fe_count'].sum()/funnel_coverage_calc_data_all_sessions[\n",
    "    'fe_count_all'].sum()\n",
    "rr_countribution = 100*funnel_coverage_calc_data_all_sessions['gross_order_count'].sum()/funnel_coverage_calc_data_all_sessions[\n",
    "    'gross_order_count_all'].sum()\n",
    "net_countribution = 100*funnel_coverage_calc_data_all_sessions['net_orders_count_snapshot'].sum()/funnel_coverage_calc_data_all_sessions[\n",
    "    'net_orders_count_snapshot_all'].sum()\n",
    "\n",
    "\n",
    "print(\"surged orders % contribution by these clusters, week period and time peirod combinations during all sessions\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"FE Contribution %\",fe_countribution)\n",
    "print(\"RR Contribution %\",rr_countribution)\n",
    "print(\"Net Contribution %\",net_countribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evening Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% contribution by these clusters during evening peak\n",
      "-------------------------------------------------\n",
      "FE Contribution % 15.517395641065576\n",
      "RR Contribution % 12.849117809953318\n",
      "Net Contribution % 12.700936741066267\n"
     ]
    }
   ],
   "source": [
    "funnel_coverage_calc_data_ep = lh_clusters_filtered[lh_clusters_filtered['time_period'] == 'evening_peak']\n",
    "\n",
    "fe_countribution = 100*funnel_coverage_calc_data_ep['fe_count'].sum()/funnel_coverage_calc_data_ep[\n",
    "    'fe_count_all'].sum()\n",
    "rr_countribution = 100*funnel_coverage_calc_data_ep['gross_order_count'].sum()/funnel_coverage_calc_data_ep[\n",
    "    'gross_order_count_all'].sum()\n",
    "net_countribution = 100*funnel_coverage_calc_data_ep['net_orders_count_snapshot'].sum()/funnel_coverage_calc_data_ep[\n",
    "    'net_orders_count_snapshot_all'].sum()\n",
    "\n",
    "\n",
    "print(\"% contribution by these clusters during evening peak\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"FE Contribution %\",fe_countribution)\n",
    "print(\"RR Contribution %\",rr_countribution)\n",
    "print(\"Net Contribution %\",net_countribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afternoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% contribution by these clusters during afternoon\n",
      "-------------------------------------------------\n",
      "FE Contribution % 19.11816807596013\n",
      "RR Contribution % 15.542613584170786\n",
      "Net Contribution % 16.38359110605054\n"
     ]
    }
   ],
   "source": [
    "funnel_coverage_calc_data_after = lh_clusters_filtered[lh_clusters_filtered['time_period'] == 'afternoon']\n",
    "\n",
    "fe_countribution = 100*funnel_coverage_calc_data_after['fe_count'].sum()/funnel_coverage_calc_data_after[\n",
    "    'fe_count_all'].sum()\n",
    "rr_countribution = 100*funnel_coverage_calc_data_after['gross_order_count'].sum()/funnel_coverage_calc_data_after[\n",
    "    'gross_order_count_all'].sum()\n",
    "net_countribution = 100*funnel_coverage_calc_data_after['net_orders_count_snapshot'].sum()/funnel_coverage_calc_data_after[\n",
    "    'net_orders_count_snapshot_all'].sum()\n",
    "\n",
    "\n",
    "print(\"% contribution by these clusters during afternoon\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"FE Contribution %\",fe_countribution)\n",
    "print(\"RR Contribution %\",rr_countribution)\n",
    "print(\"Net Contribution %\",net_countribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morning Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% contribution by these clusters during morning peak\n",
      "-------------------------------------------------\n",
      "FE Contribution % 16.182355282730303\n",
      "RR Contribution % 14.325227613230378\n",
      "Net Contribution % 14.67032967032967\n"
     ]
    }
   ],
   "source": [
    "funnel_coverage_calc_data_mp = lh_clusters_filtered[lh_clusters_filtered['time_period'] == 'morning_peak']\n",
    "\n",
    "fe_countribution = 100*funnel_coverage_calc_data_mp['fe_count'].sum()/funnel_coverage_calc_data_mp[\n",
    "    'fe_count_all'].sum()\n",
    "rr_countribution = 100*funnel_coverage_calc_data_mp['gross_order_count'].sum()/funnel_coverage_calc_data_mp[\n",
    "    'gross_order_count_all'].sum()\n",
    "net_countribution = 100*funnel_coverage_calc_data_mp['net_orders_count_snapshot'].sum()/funnel_coverage_calc_data_mp[\n",
    "    'net_orders_count_snapshot_all'].sum()\n",
    "\n",
    "\n",
    "print(\"% contribution by these clusters during morning peak\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"FE Contribution %\",fe_countribution)\n",
    "print(\"RR Contribution %\",rr_countribution)\n",
    "print(\"Net Contribution %\",net_countribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared sheet #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>orderdate</th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>time_period</th>\n",
       "      <th>fe_count</th>\n",
       "      <th>gross_order_count</th>\n",
       "      <th>net_orders_count_snapshot</th>\n",
       "      <th>fe_count_all</th>\n",
       "      <th>gross_order_count_all</th>\n",
       "      <th>net_orders_count_snapshot_all</th>\n",
       "      <th>fe_contri_percent</th>\n",
       "      <th>gross_contri_percent</th>\n",
       "      <th>net_contri_percent</th>\n",
       "      <th>week_period</th>\n",
       "      <th>cluster_week_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Adambakkam</td>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>20230712</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>147</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>724</td>\n",
       "      <td>160</td>\n",
       "      <td>116</td>\n",
       "      <td>20.3039</td>\n",
       "      <td>16.8750</td>\n",
       "      <td>16.3793</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adambakkam-Wednesday-evening_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Adambakkam</td>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>20230719</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>633</td>\n",
       "      <td>126</td>\n",
       "      <td>94</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adambakkam-Wednesday-evening_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Ambattur</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>20230710</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>863</td>\n",
       "      <td>187</td>\n",
       "      <td>147</td>\n",
       "      <td>4.0556</td>\n",
       "      <td>4.8128</td>\n",
       "      <td>6.1224</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Ambattur-Monday-evening_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Ambattur</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>20230711</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>244</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>991</td>\n",
       "      <td>203</td>\n",
       "      <td>136</td>\n",
       "      <td>24.6216</td>\n",
       "      <td>20.6897</td>\n",
       "      <td>18.3824</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Ambattur-Tuesday-afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Ambattur</td>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>20230711</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>81</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>720</td>\n",
       "      <td>186</td>\n",
       "      <td>140</td>\n",
       "      <td>11.2500</td>\n",
       "      <td>13.9785</td>\n",
       "      <td>12.1429</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Ambattur-Tuesday-evening_peak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pickup_cluster   orderdate  yyyymmdd   time_period  fe_count  \\\n",
       "59      Adambakkam  2023-07-12  20230712  evening_peak       147   \n",
       "81      Adambakkam  2023-07-19  20230719  evening_peak         4   \n",
       "356       Ambattur  2023-07-10  20230710  evening_peak        35   \n",
       "358       Ambattur  2023-07-11  20230711     afternoon       244   \n",
       "359       Ambattur  2023-07-11  20230711  evening_peak        81   \n",
       "\n",
       "     gross_order_count  net_orders_count_snapshot  fe_count_all  \\\n",
       "59                  27                         19           724   \n",
       "81                   0                          0           633   \n",
       "356                  9                          9           863   \n",
       "358                 42                         25           991   \n",
       "359                 26                         17           720   \n",
       "\n",
       "     gross_order_count_all  net_orders_count_snapshot_all  fe_contri_percent  \\\n",
       "59                     160                            116            20.3039   \n",
       "81                     126                             94             0.6319   \n",
       "356                    187                            147             4.0556   \n",
       "358                    203                            136            24.6216   \n",
       "359                    186                            140            11.2500   \n",
       "\n",
       "     gross_contri_percent  net_contri_percent week_period  \\\n",
       "59                16.8750             16.3793   Wednesday   \n",
       "81                 0.0000              0.0000   Wednesday   \n",
       "356                4.8128              6.1224      Monday   \n",
       "358               20.6897             18.3824     Tuesday   \n",
       "359               13.9785             12.1429     Tuesday   \n",
       "\n",
       "                     cluster_week_time  \n",
       "59   Adambakkam-Wednesday-evening_peak  \n",
       "81   Adambakkam-Wednesday-evening_peak  \n",
       "356       Ambattur-Monday-evening_peak  \n",
       "358         Ambattur-Tuesday-afternoon  \n",
       "359      Ambattur-Tuesday-evening_peak  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh_clusters_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderdate</th>\n",
       "      <th>time_period</th>\n",
       "      <th>fe_count</th>\n",
       "      <th>gross_order_count</th>\n",
       "      <th>net_orders_count_snapshot</th>\n",
       "      <th>fe_count_all</th>\n",
       "      <th>gross_order_count_all</th>\n",
       "      <th>net_orders_count_snapshot_all</th>\n",
       "      <th>fe_contri_percent</th>\n",
       "      <th>gross_contri_percent</th>\n",
       "      <th>net_contri_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>2167</td>\n",
       "      <td>281</td>\n",
       "      <td>148</td>\n",
       "      <td>17999</td>\n",
       "      <td>3023</td>\n",
       "      <td>1546</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>1464</td>\n",
       "      <td>197</td>\n",
       "      <td>130</td>\n",
       "      <td>17355</td>\n",
       "      <td>3128</td>\n",
       "      <td>2078</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>213</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>2058</td>\n",
       "      <td>413</td>\n",
       "      <td>193</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>3008</td>\n",
       "      <td>521</td>\n",
       "      <td>340</td>\n",
       "      <td>17963</td>\n",
       "      <td>3443</td>\n",
       "      <td>1964</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>1799</td>\n",
       "      <td>292</td>\n",
       "      <td>195</td>\n",
       "      <td>17784</td>\n",
       "      <td>3532</td>\n",
       "      <td>2416</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-11</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>632</td>\n",
       "      <td>101</td>\n",
       "      <td>66</td>\n",
       "      <td>1853</td>\n",
       "      <td>368</td>\n",
       "      <td>259</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>2020</td>\n",
       "      <td>314</td>\n",
       "      <td>199</td>\n",
       "      <td>15214</td>\n",
       "      <td>2738</td>\n",
       "      <td>1544</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>4255</td>\n",
       "      <td>704</td>\n",
       "      <td>506</td>\n",
       "      <td>25719</td>\n",
       "      <td>5004</td>\n",
       "      <td>3559</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-07-12</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>421</td>\n",
       "      <td>74</td>\n",
       "      <td>52</td>\n",
       "      <td>3044</td>\n",
       "      <td>605</td>\n",
       "      <td>395</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-07-13</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>8464</td>\n",
       "      <td>1241</td>\n",
       "      <td>738</td>\n",
       "      <td>21363</td>\n",
       "      <td>3777</td>\n",
       "      <td>2148</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-07-13</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>3762</td>\n",
       "      <td>652</td>\n",
       "      <td>468</td>\n",
       "      <td>22186</td>\n",
       "      <td>4347</td>\n",
       "      <td>3010</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-07-13</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>1136</td>\n",
       "      <td>182</td>\n",
       "      <td>111</td>\n",
       "      <td>4146</td>\n",
       "      <td>832</td>\n",
       "      <td>459</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-07-14</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>3027</td>\n",
       "      <td>443</td>\n",
       "      <td>287</td>\n",
       "      <td>20314</td>\n",
       "      <td>3700</td>\n",
       "      <td>2133</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-07-14</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>3465</td>\n",
       "      <td>561</td>\n",
       "      <td>392</td>\n",
       "      <td>24171</td>\n",
       "      <td>4531</td>\n",
       "      <td>3168</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-07-14</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>745</td>\n",
       "      <td>124</td>\n",
       "      <td>74</td>\n",
       "      <td>3361</td>\n",
       "      <td>667</td>\n",
       "      <td>412</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>7481</td>\n",
       "      <td>976</td>\n",
       "      <td>588</td>\n",
       "      <td>33799</td>\n",
       "      <td>4959</td>\n",
       "      <td>2821</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>5227</td>\n",
       "      <td>671</td>\n",
       "      <td>465</td>\n",
       "      <td>27734</td>\n",
       "      <td>4029</td>\n",
       "      <td>2585</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>1261</td>\n",
       "      <td>197</td>\n",
       "      <td>140</td>\n",
       "      <td>4843</td>\n",
       "      <td>824</td>\n",
       "      <td>560</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-07-16</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>3708</td>\n",
       "      <td>448</td>\n",
       "      <td>299</td>\n",
       "      <td>40970</td>\n",
       "      <td>5842</td>\n",
       "      <td>3712</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-07-16</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>1373</td>\n",
       "      <td>140</td>\n",
       "      <td>88</td>\n",
       "      <td>21927</td>\n",
       "      <td>2723</td>\n",
       "      <td>1777</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023-07-16</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>832</td>\n",
       "      <td>106</td>\n",
       "      <td>80</td>\n",
       "      <td>5153</td>\n",
       "      <td>756</td>\n",
       "      <td>504</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>6769</td>\n",
       "      <td>980</td>\n",
       "      <td>579</td>\n",
       "      <td>17992</td>\n",
       "      <td>2960</td>\n",
       "      <td>1612</td>\n",
       "      <td>38.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>6876</td>\n",
       "      <td>1019</td>\n",
       "      <td>686</td>\n",
       "      <td>21471</td>\n",
       "      <td>3815</td>\n",
       "      <td>2612</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023-07-17</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>225</td>\n",
       "      <td>42</td>\n",
       "      <td>28</td>\n",
       "      <td>2009</td>\n",
       "      <td>388</td>\n",
       "      <td>207</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023-07-18</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>3726</td>\n",
       "      <td>631</td>\n",
       "      <td>386</td>\n",
       "      <td>17027</td>\n",
       "      <td>3294</td>\n",
       "      <td>1895</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-07-18</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>3824</td>\n",
       "      <td>600</td>\n",
       "      <td>420</td>\n",
       "      <td>22771</td>\n",
       "      <td>4324</td>\n",
       "      <td>3066</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023-07-18</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>512</td>\n",
       "      <td>77</td>\n",
       "      <td>48</td>\n",
       "      <td>1900</td>\n",
       "      <td>377</td>\n",
       "      <td>226</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>1353</td>\n",
       "      <td>221</td>\n",
       "      <td>143</td>\n",
       "      <td>15929</td>\n",
       "      <td>3021</td>\n",
       "      <td>1717</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>2659</td>\n",
       "      <td>348</td>\n",
       "      <td>247</td>\n",
       "      <td>22518</td>\n",
       "      <td>4241</td>\n",
       "      <td>2970</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023-07-19</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>638</td>\n",
       "      <td>120</td>\n",
       "      <td>77</td>\n",
       "      <td>3153</td>\n",
       "      <td>645</td>\n",
       "      <td>419</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>984</td>\n",
       "      <td>148</td>\n",
       "      <td>95</td>\n",
       "      <td>19861</td>\n",
       "      <td>3822</td>\n",
       "      <td>2220</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1539</td>\n",
       "      <td>311</td>\n",
       "      <td>229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023-07-20</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>224</td>\n",
       "      <td>59</td>\n",
       "      <td>30</td>\n",
       "      <td>2818</td>\n",
       "      <td>625</td>\n",
       "      <td>412</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2023-07-21</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>683</td>\n",
       "      <td>104</td>\n",
       "      <td>68</td>\n",
       "      <td>20978</td>\n",
       "      <td>3930</td>\n",
       "      <td>2203</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2023-07-21</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>3229</td>\n",
       "      <td>463</td>\n",
       "      <td>295</td>\n",
       "      <td>22710</td>\n",
       "      <td>4123</td>\n",
       "      <td>2943</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-07-21</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>122</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>2142</td>\n",
       "      <td>442</td>\n",
       "      <td>275</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023-07-22</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>1554</td>\n",
       "      <td>205</td>\n",
       "      <td>136</td>\n",
       "      <td>29538</td>\n",
       "      <td>4637</td>\n",
       "      <td>2965</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-07-22</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>5483</td>\n",
       "      <td>511</td>\n",
       "      <td>268</td>\n",
       "      <td>28337</td>\n",
       "      <td>3583</td>\n",
       "      <td>2334</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-07-22</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>279</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>4417</td>\n",
       "      <td>795</td>\n",
       "      <td>544</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>19810</td>\n",
       "      <td>1947</td>\n",
       "      <td>1174</td>\n",
       "      <td>49757</td>\n",
       "      <td>5285</td>\n",
       "      <td>3137</td>\n",
       "      <td>40.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>evening_peak</td>\n",
       "      <td>3409</td>\n",
       "      <td>338</td>\n",
       "      <td>233</td>\n",
       "      <td>25549</td>\n",
       "      <td>2865</td>\n",
       "      <td>1841</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2023-07-23</td>\n",
       "      <td>morning_peak</td>\n",
       "      <td>484</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>6834</td>\n",
       "      <td>940</td>\n",
       "      <td>595</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     orderdate   time_period  fe_count  gross_order_count  \\\n",
       "0   2023-07-10     afternoon      2167                281   \n",
       "1   2023-07-10  evening_peak      1464                197   \n",
       "2   2023-07-10  morning_peak       213                 46   \n",
       "3   2023-07-11     afternoon      3008                521   \n",
       "4   2023-07-11  evening_peak      1799                292   \n",
       "5   2023-07-11  morning_peak       632                101   \n",
       "6   2023-07-12     afternoon      2020                314   \n",
       "7   2023-07-12  evening_peak      4255                704   \n",
       "8   2023-07-12  morning_peak       421                 74   \n",
       "9   2023-07-13     afternoon      8464               1241   \n",
       "10  2023-07-13  evening_peak      3762                652   \n",
       "11  2023-07-13  morning_peak      1136                182   \n",
       "12  2023-07-14     afternoon      3027                443   \n",
       "13  2023-07-14  evening_peak      3465                561   \n",
       "14  2023-07-14  morning_peak       745                124   \n",
       "15  2023-07-15     afternoon      7481                976   \n",
       "16  2023-07-15  evening_peak      5227                671   \n",
       "17  2023-07-15  morning_peak      1261                197   \n",
       "18  2023-07-16     afternoon      3708                448   \n",
       "19  2023-07-16  evening_peak      1373                140   \n",
       "20  2023-07-16  morning_peak       832                106   \n",
       "21  2023-07-17     afternoon      6769                980   \n",
       "22  2023-07-17  evening_peak      6876               1019   \n",
       "23  2023-07-17  morning_peak       225                 42   \n",
       "24  2023-07-18     afternoon      3726                631   \n",
       "25  2023-07-18  evening_peak      3824                600   \n",
       "26  2023-07-18  morning_peak       512                 77   \n",
       "27  2023-07-19     afternoon      1353                221   \n",
       "28  2023-07-19  evening_peak      2659                348   \n",
       "29  2023-07-19  morning_peak       638                120   \n",
       "30  2023-07-20     afternoon       984                148   \n",
       "31  2023-07-20  evening_peak         2                  0   \n",
       "32  2023-07-20  morning_peak       224                 59   \n",
       "33  2023-07-21     afternoon       683                104   \n",
       "34  2023-07-21  evening_peak      3229                463   \n",
       "35  2023-07-21  morning_peak       122                 26   \n",
       "36  2023-07-22     afternoon      1554                205   \n",
       "37  2023-07-22  evening_peak      5483                511   \n",
       "38  2023-07-22  morning_peak       279                 36   \n",
       "39  2023-07-23     afternoon     19810               1947   \n",
       "40  2023-07-23  evening_peak      3409                338   \n",
       "41  2023-07-23  morning_peak       484                 53   \n",
       "\n",
       "    net_orders_count_snapshot  fe_count_all  gross_order_count_all  \\\n",
       "0                         148         17999                   3023   \n",
       "1                         130         17355                   3128   \n",
       "2                          19          2058                    413   \n",
       "3                         340         17963                   3443   \n",
       "4                         195         17784                   3532   \n",
       "5                          66          1853                    368   \n",
       "6                         199         15214                   2738   \n",
       "7                         506         25719                   5004   \n",
       "8                          52          3044                    605   \n",
       "9                         738         21363                   3777   \n",
       "10                        468         22186                   4347   \n",
       "11                        111          4146                    832   \n",
       "12                        287         20314                   3700   \n",
       "13                        392         24171                   4531   \n",
       "14                         74          3361                    667   \n",
       "15                        588         33799                   4959   \n",
       "16                        465         27734                   4029   \n",
       "17                        140          4843                    824   \n",
       "18                        299         40970                   5842   \n",
       "19                         88         21927                   2723   \n",
       "20                         80          5153                    756   \n",
       "21                        579         17992                   2960   \n",
       "22                        686         21471                   3815   \n",
       "23                         28          2009                    388   \n",
       "24                        386         17027                   3294   \n",
       "25                        420         22771                   4324   \n",
       "26                         48          1900                    377   \n",
       "27                        143         15929                   3021   \n",
       "28                        247         22518                   4241   \n",
       "29                         77          3153                    645   \n",
       "30                         95         19861                   3822   \n",
       "31                          0          1539                    311   \n",
       "32                         30          2818                    625   \n",
       "33                         68         20978                   3930   \n",
       "34                        295         22710                   4123   \n",
       "35                         13          2142                    442   \n",
       "36                        136         29538                   4637   \n",
       "37                        268         28337                   3583   \n",
       "38                         28          4417                    795   \n",
       "39                       1174         49757                   5285   \n",
       "40                        233         25549                   2865   \n",
       "41                         35          6834                    940   \n",
       "\n",
       "    net_orders_count_snapshot_all  fe_contri_percent  gross_contri_percent  \\\n",
       "0                            1546               12.0                   9.0   \n",
       "1                            2078                8.0                   6.0   \n",
       "2                             193               10.0                  11.0   \n",
       "3                            1964               17.0                  15.0   \n",
       "4                            2416               10.0                   8.0   \n",
       "5                             259               34.0                  27.0   \n",
       "6                            1544               13.0                  11.0   \n",
       "7                            3559               17.0                  14.0   \n",
       "8                             395               14.0                  12.0   \n",
       "9                            2148               40.0                  33.0   \n",
       "10                           3010               17.0                  15.0   \n",
       "11                            459               27.0                  22.0   \n",
       "12                           2133               15.0                  12.0   \n",
       "13                           3168               14.0                  12.0   \n",
       "14                            412               22.0                  19.0   \n",
       "15                           2821               22.0                  20.0   \n",
       "16                           2585               19.0                  17.0   \n",
       "17                            560               26.0                  24.0   \n",
       "18                           3712                9.0                   8.0   \n",
       "19                           1777                6.0                   5.0   \n",
       "20                            504               16.0                  14.0   \n",
       "21                           1612               38.0                  33.0   \n",
       "22                           2612               32.0                  27.0   \n",
       "23                            207               11.0                  11.0   \n",
       "24                           1895               22.0                  19.0   \n",
       "25                           3066               17.0                  14.0   \n",
       "26                            226               27.0                  20.0   \n",
       "27                           1717                8.0                   7.0   \n",
       "28                           2970               12.0                   8.0   \n",
       "29                            419               20.0                  19.0   \n",
       "30                           2220                5.0                   4.0   \n",
       "31                            229                0.0                   0.0   \n",
       "32                            412                8.0                   9.0   \n",
       "33                           2203                3.0                   3.0   \n",
       "34                           2943               14.0                  11.0   \n",
       "35                            275                6.0                   6.0   \n",
       "36                           2965                5.0                   4.0   \n",
       "37                           2334               19.0                  14.0   \n",
       "38                            544                6.0                   5.0   \n",
       "39                           3137               40.0                  37.0   \n",
       "40                           1841               13.0                  12.0   \n",
       "41                            595                7.0                   6.0   \n",
       "\n",
       "    net_contri_percent  \n",
       "0                 10.0  \n",
       "1                  6.0  \n",
       "2                 10.0  \n",
       "3                 17.0  \n",
       "4                  8.0  \n",
       "5                 25.0  \n",
       "6                 13.0  \n",
       "7                 14.0  \n",
       "8                 13.0  \n",
       "9                 34.0  \n",
       "10                16.0  \n",
       "11                24.0  \n",
       "12                13.0  \n",
       "13                12.0  \n",
       "14                18.0  \n",
       "15                21.0  \n",
       "16                18.0  \n",
       "17                25.0  \n",
       "18                 8.0  \n",
       "19                 5.0  \n",
       "20                16.0  \n",
       "21                36.0  \n",
       "22                26.0  \n",
       "23                14.0  \n",
       "24                20.0  \n",
       "25                14.0  \n",
       "26                21.0  \n",
       "27                 8.0  \n",
       "28                 8.0  \n",
       "29                18.0  \n",
       "30                 4.0  \n",
       "31                 0.0  \n",
       "32                 7.0  \n",
       "33                 3.0  \n",
       "34                10.0  \n",
       "35                 5.0  \n",
       "36                 5.0  \n",
       "37                11.0  \n",
       "38                 5.0  \n",
       "39                37.0  \n",
       "40                13.0  \n",
       "41                 6.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numbers_filtered = lh_clusters_filtered \\\n",
    "                        .groupby(['orderdate','time_period'])\\\n",
    "                        .agg({'fe_count' : 'sum',\n",
    "                               'gross_order_count' : 'sum',\n",
    "                               'net_orders_count_snapshot' : 'sum',\n",
    "                               'fe_count_all' : 'sum',\n",
    "                               'gross_order_count_all' : 'sum',\n",
    "                               'net_orders_count_snapshot_all' : 'sum'\n",
    "                              }).reset_index()\n",
    "\n",
    "df_numbers_filtered['fe_contri_percent'] = (df_numbers_filtered['fe_count']*100/df_numbers_filtered['fe_count_all']).round()\n",
    "df_numbers_filtered['gross_contri_percent'] = (df_numbers_filtered['gross_order_count']*100/df_numbers_filtered['gross_order_count_all']).round()\n",
    "df_numbers_filtered['net_contri_percent'] = (df_numbers_filtered['net_orders_count_snapshot']*100/df_numbers_filtered['net_orders_count_snapshot_all']).round()\n",
    "df_numbers_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers_filtered.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
