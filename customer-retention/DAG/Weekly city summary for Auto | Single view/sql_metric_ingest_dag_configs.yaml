owner: data-platform
tags: [ fluidity, sql_ingest, metrics ]
domain: RAPIDO_SQL_INGEST

cluster_config:
  name: rapido-sql-ingest-all
  worker_machine_type: "n1-standard-8"
  master_machine_type: "e2-standard-8"
  image: "1.4-debian10"
  worker_count: 6
  idle_ttl: 3600
  preembtible_worker_percent: 0.8
  properties:
    "dataproc:dataproc.conscrypt.provider.enable": "false"
    "spark:spark.executor.cores": "8"

framework_sql_ingest_job_configs:

  - run_config:
      name: REFERRAL_VIEW_CUSTOMER_V2
      start_date: '2021-12-18T18:30:00' 
      schedule_interval: "0 2 * * *"
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-refrl-view-cus2
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"


    flow_config:
      sql:
        SELECT yyyymmdd as date, City as "City", Referrers AS
       Total_Referrers,
       Referrals AS
       Referral_Registrations_Referred_Users,
       Net AS
       Total_Net_Referrals_Net_referred,
       Total_Orders AS Total_Orders_Final,
       (CAST(Total_Orders as double) / CAST(Net as double)) AS
       RPC,
       referred_Incentive AS
       Incentive_to_referred,
       referrer_Incentive AS
       Incetive_to_referrer,
       ((CAST(referred_Incentive as double) + CAST(referrer_Incentive as double)) / CAST(Net as double)) AS
       CAC_Cost_of_Acquisition
       FROM
       (
         select * from
         (
           (select yyyymmdd, City,
             COUNT(DISTINCT (referrerUserId)) AS
             "Referrers",
             COUNT(DISTINCT (referredUserId)) AS
             "Referrals",
             COUNT(DISTINCT (ride1)) AS
             "Net",
             SUM(CASE WHEN Tag = 1 THEN CAST(incentiveamountforreferred as double) ELSE 0 END) AS
             "referred_Incentive",
             SUM(CASE WHEN Tag = 1 THEN CAST(incentiveamountforreferrer as double) ELSE 0 END) AS
             "referrer_Incentive" from
             (select *,
             (CASE WHEN (Days <= expiryindays) THEN 1 ELSE 0 END) AS
                   "Tag",
                   (CASE WHEN rideNum = 1 THEN referredUserId END) AS
                   "ride1"
                   from
                   (Select ref_net_tb.*,
                            datediff(ref_net_tb.orderdate , ref_net_tb.RegDate) AS
                         "Days",
                         rule_tb.expiryindays,
                         rule_tb.maxvalue,
                         rule_tb.incentiveamountforreferrer,
                         rule_tb.incentiveamountforreferred
                         from
                         (
                           (SELECT * from 
                           ((SELECT 
                               a.yyyymmdd, 
                               a.City,
                               a.referrerUserId,
                               a.referredUserId,
                               a.campaignid,
                               a.RegDate,
                               b.orderdate,
                               CAST(b.rn as double) AS rideNum
                               from ((select * from (SELECT _id, yyyymmdd, referrerusercity AS "City",
                                        referrerUserId, referredUserId, campaignid, DATE (datebucket) AS "RegDate", ROW_NUMBER() OVER (PARTITION BY _id ORDER BY updated_epoch DESC) latest_raw
                                    FROM raw.mongodb_rapidoreferralcampaigns_referral_usage_immutable
                                    WHERE yyyymmdd BETWEEN DATE_format({{startDate}}
                                                          , '%Y%m%d')
                                                        and DATE_format({{endDate}}
                                                          , '%Y%m%d')
                                      and referreruserrole = 'CUSTOMER'
                                      and referreduserrole = 'CUSTOMER')
                              where latest_raw = 1) a
                              LEFT JOIN
                             (SELECT *
                              FROM (SELECT customer,
                                           DATE(orderdate) as                                               orderdate,
                                           createdon,
                                           row_number() over (partition by customer order by createdon asc) rn
                                    FROM legacy.orders
                                    WHERE serviceobj_service = 'Link'
                                      and status = 'dropped'
                                      and spdfraud_flag != 1
                                      and DATE(orderdate) >= {{startDate}})
                              WHERE rn in (1, 2, 3, 4)) b ON a.referredUserId = b.customer))
                              )) ref_net_tb
                              LEFT JOIN 
                              (SELECT *
                                    FROM (SELECT campaignid,
                                     CAST(maxvalue as double)     AS
                                     "maxvalue",
                                     CAST(expiryindays as double) AS
                                     "expiryindays",
                                     incentiveamountforreferrer,
                                     incentiveamountforreferred,
                                     ROW_NUMBER()
                                             OVER (PARTITION BY campaignid, maxvalue ORDER BY updated_epoch DESC) latest_raw
                              FROM raw.mongodb_rapidoreferralcampaigns_referral_rules_immutable
                              WHERE role = 'CUSTOMER'
                                and ruletype = 'ORDERS'
                                and yyyymmdd >= '20200101')
                        WHERE latest_raw = 1) rule_tb on ref_net_tb.campaignid = rule_tb.campaignid and
                                                         ref_net_tb.rideNum = rule_tb.maxvalue)))
                    GROUP BY 1,2 ) finalrefTb     
                    LEFT JOIN 
                    (SELECT yyyymmdd as day, referrerusercity, Total_Orders
                            FROM 
                            (SELECT reftbl.yyyymmdd, reftbl.referrerusercity, sum(ordtbl.Orders) AS "Total_Orders"
                            FROM 
                            (
                            (SELECT DISTINCT yyyymmdd,referrerusercity, referredUserId
                              FROM raw.mongodb_rapidoreferralcampaigns_referral_usage_immutable
                              WHERE yyyymmdd BETWEEN DATE_format({{startDate}}, '%Y%m%d') and DATE_format({{endDate}}, '%Y%m%d')
                                 and referreruserrole = 'CUSTOMER' and referreduserrole = 'CUSTOMER') reftbl
                                 LEFT JOIN
                             (SELECT customer, COUNT(_id) AS "Orders"
                              FROM legacy.orders
                              WHERE serviceobj_service = 'Link'
                                and status = 'dropped'
                                and spdfraud_flag != 1
                                and DATE(orderdate) >= {{startDate}}
                              GROUP BY 1) ordtbl ON reftbl.referredUserId = ordtbl.customer
                                                   )
                             group by 1,2
                            )) TotOrdTb
                                ON finalrefTb.yyyymmdd = TotOrdTb.day
                                and finalrefTb.city = TotOrdTb.referrerusercity
                                ))
      args:
        - var_name: startDate
          var_type: DATE
          value: "DATE('2021-04-01')"
        - var_name: endDate
          var_type: DATE
          expression: 'current_date()'


    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_referral_view_customer_v2"
      partition_columns: [ "date" ]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_referral_view_customer_v2"
      table_schema_name: "reports_internal"
      view_name: "sql_ingest_referral_view_customer"
      base_path: "metrics/sql_ingest_referral_view_customer_v2"
      view_schema_name: "reports"

  - run_config:
      name: INCENTIVE_SUMMARY_V2
      start_date: '2021-12-27T08:30:00' # 26th Night 00:00 # Make sure this runs after dependent data.
      schedule_interval: "30 2 * * *"
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-incentive-summary
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 8
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"


    flow_config:
      overwrite: true
      sql:
        with incentive_imm as(
          select
            incentiveId,
            startdate,
            enddate,
            type,
            incentivetype,
            incentivename,
            cities,
            servicenames,
            servicetype,
            rulename,
            ruleid,
            priority,
            active,
            selectedvariable,
            updated_epoch,
            updated_yyyymmdd,
            goals,
            try(
              cast(
                json_extract(time_periods, '$.timeSlot[0].fromTime') as varchar
              )
            ) as timeslot_fromtime,
            try(
              cast(
                json_extract(time_periods, '$.timeSlot[0].toTime') as varchar
              )
            ) as timeslot_totime,
            dayslot,
            try(
              cardinality(
                cast(
                  json_extract(time_periods, '$.rules') as ARRAY(JSON)
                )
              )
            ) as max_index,
            try(
              transform(
                cast(
                  json_extract(time_periods, '$.rules') as ARRAY < MAP < varchar,
                  varchar > >
                ),
                x -> cast(x ['order'] as double)
              )
            ) as rules_orders,
            try(
              transform(
                cast(
                  json_extract(time_periods, '$.rules') as ARRAY < MAP < varchar,
                  varchar > >
                ),
                x -> cast(x ['distance'] as double)
              )
            ) as rules_distance,
            try(
              transform(
                cast(
                  json_extract(time_periods, '$.rules') as ARRAY < MAP < varchar,
                  varchar > >
                ),
                x -> cast(x ['amount'] as double)
              )
            ) as rules_amount,
            try(
              cast(json_extract(time_periods, '$.uuid') as varchar)
            ) as uuid
          from
            (
              select
                *,
                cast(goals_processed as array(json)) as goals_array
              from
                (
                  select
                    *
                  from
                    (
                      select
                        *,
                        _id as incentiveId,
                        row_number() over(
                          partition by _id
                          order by
                            ts_ms desc
                        ) as row
                      from
                        raw.mongodb_rapidopayroll_incentives_immutable
                      where
                        startdate <= {{ date_ }}
                        and enddate >= {{ date_ }}
                        and (
                          (
                            updated_yyyymmdd = {{ ymd }}
                            and yyyymmdd = {{ ymd }}
                          )
                          or (updated_yyyymmdd < {{ ymd }})
                        )
                    )
                  where
                    row = 1
                ) t1
                cross join unnest(cast(goals as map < varchar, json >)) as d(dayslot, goals_processed)
            )
            cross join unnest(goals_array) as t(time_periods)
        ),
        incRiders as (
          select
            _id as incentive_riders_id,
            yyyymmdd,
            dayslot,
            riderid,
            orderDate,
            incentivetype,
            incentiveid,
            rulename,
            cast(json_extract(field_status, '$.uuid') as varchar) as uuid,
            cast(
              json_extract(field_status, '$.isSetCompleted') as varchar
            ) as is_set_completed,
            cast(
              json_extract(field_status, '$.isSetStarted') as varchar
            ) as is_set_started,
            try(
              transform(
                cast(
                  json_extract(field_status, '$.rulesStatus') as ARRAY < MAP < varchar,
                  varchar > >
                ),
                x -> x ['isRuleCompleted']
              )
            ) as rule_completed,
            transform(
              transform(
                cast(
                  json_extract(field_status, '$.rulesStatus') as ARRAY < json >
                ),
                x -> json_extract_scalar(x, '$.orders')
              ),
              x -> length(x) - length(replace(x, '{', ''))
            ) as orders_done
          from
            (
              select
                _id,
                yyyymmdd,
                riderid,
                orderDate,
                incentivetype,
                raw.mongodb_rapidopayroll_incentive_riders_snapshot.incentiveid,
                imm.rulename,
                cast(json_extract(progress, '$.field') as varchar) as dayslot,
                cast(
                  json_extract(progress, '$.fieldStatus') as ARRAY(JSON)
                ) as fieldstatus
              from
                raw.mongodb_rapidopayroll_incentive_riders_snapshot
                inner join (
                  select
                    distinct incentiveId,
                    rulename
                  from
                    incentive_imm
                ) imm on imm.incentiveId = raw.mongodb_rapidopayroll_incentive_riders_snapshot.incentiveId
                cross join unnest(cast(incentiveprogress_json as ARRAY(JSON))) as t(progress)
              where
                (
                  (
                    incentivetype not like 'Weekly%'
                    and yyyymmdd = {{ ymd }}
                    and orderDate = {{ date_ }}
                  )
                  or (incentivetype like 'Weekly%')
                )
            )
            cross join unnest (fieldstatus) as t(field_status)
        ),
        incentive_base_table as (
          select
            incentive_riders_id,
            yyyymmdd,
            orderDate,
            startdate,
            enddate,
            incentivetype,
            incentiveid,
            incentivename,
            riderid,
            uuid,
            timeslot_fromtime,
            timeslot_totime,
            dayslot,
            goals,
            rules_orders,
            rules_distance,
            servicetype,
            servicenames,
            cities,
            rules_amount,
            is_set_started,
            is_set_completed,
            rule_completed,
            number_rules_completed,
            orders_done,
            reduce(orders_done, 0,(s, x) -> s + x, s -> s) as total_orders_done,
            total_rules_amount_mod,
            dense_rank() over(
              partition by riderid,
              incentivetype,
              yyyymmdd
              order by
                priority desc,
                updated_epoch desc
            ) as priority_rank
          from
            (
              select
                incentive_riders_id,
                yyyymmdd,
                orderDate,
                imm.startdate,
                imm.enddate,
                ir.incentivetype,
                ir.incentiveid,
                incentivename,
                riderid,
                ir.uuid,
                imm.cities,
                imm.servicetype,
                imm.servicenames,
                timeslot_fromtime,
                timeslot_totime,
                imm.dayslot,
                imm.goals,
                rules_orders,
                rules_distance,
                rules_amount,
                is_set_started,
                is_set_completed,
                rule_completed,
                reduce(
                  transform(
                    zip(
                      cast(
                        cast(rule_completed as array(boolean)) as array(double)
                      ),
                      rules_amount
                    ),
                    k -> k [1] * k [2]
                  ),
                  0,
                  (s, x) -> s + x,
                  s -> s
                ) as total_rules_amount_mod,
                reduce(
                  rule_completed,
                  0,
                  (s, x) -> case
                    when x = 'true' then s + 1
                    else s + 0
                  end,
                  s -> s
                ) as number_rules_completed,
                imm.priority,
                imm.updated_epoch,
                orders_done
              from
                incRiders ir
                inner join incentive_imm imm on ir.incentiveid = imm.incentiveId
                and ir.uuid = imm.uuid
            )
        ),
        rules_index as (
          select
            incentiveid,
            uuid as subincentiveid,
            rules_orders,
            rules_amount,
            rules_distance,
            number_rules_completed
          from
            (
              select
                incentiveid,
                uuid,
                rules_orders,
                rules_amount,
                rules_distance,
                sequence(0, max_index, 1) as slab_indices
              from
                (
                  select
                    incentiveid,
                    uuid,
                    rules_orders,
                    rules_amount,
                    rules_distance,
                    max_index
                  from
                    incentive_imm
                ) as max_index
            )
            cross join unnest (slab_indices) as t(number_rules_completed)
        ),
        achvmt_tbl as (
          select
            incentiveid,
            subincentiveid,
            slab_distance_target,
            slab_order_target,
            slab_amount,
            number_rules_completed,
            num_achieved_slab,
            sum(num_achieved_slab) over (
              partition by incentiveid,
              subincentiveid
              order by
                number_rules_completed desc rows between unbounded preceding
                and current row
            ) as num_achieved_cumulative,
            lead(num_participated_next_slab_incomplete) over(
              partition by incentiveid,
              subincentiveid
              order by
                number_rules_completed desc
            ) as num_participated_next_slab_incomplete,
            mean_orders_participants,
            narrow_miss_by1,
            narrow_miss_by2
          from
            (
              select
                ind.incentiveid,
                ind.subincentiveid,
                ind.number_rules_completed,
                case
                  when ind.number_rules_completed = 0
                  or ind.rules_distance is null then 0
                  else element_at(ind.rules_distance, ind.number_rules_completed)
                end as slab_distance_target,
                case
                  when ind.number_rules_completed = 0
                  or ind.rules_orders is null then 0
                  else element_at(ind.rules_orders, ind.number_rules_completed)
                end as slab_order_target,
                case
                  when ind.number_rules_completed = 0
                  or ind.rules_amount is null then 0
                  else element_at(ind.rules_amount, ind.number_rules_completed)
                end as slab_amount,
                coalesce(base.num_achieved_slab, 0) as num_achieved_slab,
                coalesce(base.num_participated_next_slab_incomplete, 0) as num_participated_next_slab_incomplete,
                coalesce(base.mean_orders_participants, 0) as mean_orders_participants,
                coalesce(base.narrow_miss_by1, 0) as narrow_miss_by1,
                coalesce(base.narrow_miss_by2, 0) as narrow_miss_by2
              from
                rules_index ind
                left join (
                  select
                    incentiveid,
                    uuid as subincentiveid,
                    number_rules_completed,
                    count(distinct riderid) as num_achieved_slab,
                    count(
                      distinct case
                        when total_orders_done > if(
                          number_rules_completed > 0,
                          element_at(rules_orders, number_rules_completed),
                          0
                        ) then riderid
                      end
                    ) as num_participated_next_slab_incomplete,
                    avg(
                      case
                        when total_orders_done > 0 then total_orders_done
                      end
                    ) as mean_orders_participants,
                    count(
                      distinct case
                        when cast(
                          if(
                            number_rules_completed > 0,
                            element_at(
                              rules_orders,
                              number_rules_completed
                            ),
                            0
                          ) as integer
                        ) - cast(total_orders_done as integer) = 1 then riderid
                      end
                    ) as narrow_miss_by1,
                    count(
                      distinct case
                        when cast(
                          if(
                            number_rules_completed > 0,
                            element_at(
                              rules_orders,
                              number_rules_completed
                            ),
                            0
                          ) as integer
                        ) - cast(total_orders_done as integer) = 2 then riderid
                      end
                    ) as narrow_miss_by2
                  from
                    incentive_base_table
                  group by
                    1,
                    2,
                    3
                ) base on base.incentiveid = ind.incentiveid
                and base.subincentiveid = ind.subincentiveid
                and base.number_rules_completed = ind.number_rules_completed
            )
        )
        select
          base.*,
          assign.num_assigned,
          assign.num_participated_overall,
          assign.num_achieved_atleast_oneslab,
          sum(achieved.incentive_burn_slab) over (
            partition by achieved.incentiveid,
            achieved.subincentiveid
          ) as total_burn_incentive,
          achieved.number_rules_completed,
          achieved.slab_distance_target,
          achieved.slab_order_target,
          achieved.slab_amount,
          achieved.num_achieved_slab as num_achieved_slab_exact,
          achieved.num_participated_slab,
          achieved.num_achieved_cumulative,
          num_achieved_cumulative / (1.00 * num_assigned) as achievement_pct,
          achieved.mean_orders_participants,
          achieved.incentive_burn_slab,
          achieved.narrow_miss_by1,
          achieved.narrow_miss_by2,
          to_unixtime(now()) as job_epoch
        from
          (
            select
              distinct incentiveid,
              uuid as subincentiveid,
              incentivename,
              incentivetype,
              array_join(cast(servicetype as ARRAY < varchar >), ', ') as servicetype,
              array_join(cast(servicenames as ARRAY < varchar >), ', ') as servicenames,
              timeslot_fromtime,
              timeslot_totime,
              dayslot,
              startdate,
              enddate,
              array_join(rules_orders, ', ') as rules_orders,
              array_join(rules_distance, ', ') as rules_distance,
              array_join(rules_amount, ', ') as rules_amount,
              yyyymmdd as incrider_ymd,
              {{ ymd }} as yyyymmdd,
              orderdate,
              array_join(cast(cities as ARRAY < varchar >), ', ') as cities
            from
              incentive_base_table
          ) base
          inner join (
            select
              incentiveid,
              uuid as subincentiveid,
              count(distinct riderid) num_assigned,
              count(
                distinct case
                  when total_orders_done > 0 then riderid
                end
              ) num_participated_overall,
              count(
                distinct case
                  when number_rules_completed > 0 then riderid
                end
              ) num_achieved_atleast_oneslab
            from
              incentive_base_table
            group by
              1,
              2
          ) assign on assign.incentiveid = base.incentiveid
          and assign.subincentiveid = base.subincentiveid
          inner join (
            select
              incentiveid,
              subincentiveid,
              number_rules_completed,
              slab_distance_target,
              slab_order_target,
              slab_amount,
              num_achieved_slab,
              num_achieved_cumulative,
              num_participated_next_slab_incomplete + num_achieved_cumulative as num_participated_slab,
              mean_orders_participants,
              narrow_miss_by1,
              narrow_miss_by2,
              slab_amount * num_achieved_cumulative as incentive_burn_slab
            from
              achvmt_tbl
          ) achieved on achieved.incentiveid = base.incentiveid
          and achieved.subincentiveid = base.subincentiveid
        order by
          incentivename,
          subincentiveid,
          number_rules_completed

      args:
        - var_name: date_
          var_type: DATE
          expression: 'current_date()'
          format: "'%Y-%m-%d'"
        - var_name: ymd
          var_type: DATE
          expression: 'current_date()'
          format: "'%Y%m%d'"


    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_incentive_summary_v2"
      partition_columns: [ "yyyymmdd", "cities", "incentivetype" ]


    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_incentive_summary_v2"
      table_schema_name: "reports_internal"
      view_name: "sql_ingest_incentive_summary"
      base_path: "metrics/sql_ingest_incentive_summary_v2"
      view_schema_name: "reports"
  
  - run_config:
      name: 'CAPTAIN_SUPPLY_DATA'
      start_date: '2022-02-01T08:30:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-captain-supply-data
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 3
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"



    flow_config:
      sql:
        with citys as (
        select
          *
        from
          (
          select
            _id as city_id,
            displayname as cityName,
            row_number() OVER(PARTITION BY _id ORDER BY updated_epoch DESC) as latest_info
          from
            hive.raw.mongodb_rapidoprod_cities_immutable
          )
        where
          latest_info = 1
        ),
        
        riders as (
        select
          user_id,
          yyyymmdd as registereddate,
          Services_Interested as servicesinterested,
          mobile,
          mobile_verified,
          status_updates_mobile_number_verified_on,
          referral_code as referralcode,
          status_updates_activated_by as statusupdates_activatedby,
          city,
          cityName as registeredcity,
          shift_name,
          current_vehicle_number as currentvehicle_number,
          license_number,
          from_unixtime((created_On + (330*60*1000))/1000) as registrationtime,
          active,
          substr(birth_date,1,10) as Birth_Date,
          case
          when status_updates_activated_on is not null then from_unixtime((status_updates_activated_on + (330*60*1000))/1000)
          end as activationtime,
          status_updates_training_completed_on,
          status_updates_lms_started,
          status_updates_lms_completed,
          created_On,
          status_updates_activated_on,
          status_updates_video_seen,
          application_version,
          device_device_id,
          first_name,
          last_name
        from
          entity.riders_snapshot rs
          left join citys cs on rs.city = cs.city_id
        where
          yyyymmdd >= date_format({{startdate}}, '%Y%m%d')
          and yyyymmdd <= date_format({{enddate}}, '%Y%m%d')
        ),

        docs as (
        select
          captain_id,
          max(case when document_type = 'profilePicture' then event_time end) as profilePicture,
          max(case when document_type = 'profilePicture' then document_status end) as profilePicture_Status,
          
          max(case when document_type = 'license' then event_time end) as license,
          max(case when document_type = 'license' then document_status end) as license_status,
          
          max(case when document_type = 'rc' then event_time end) as rc,
          max(case when document_type = 'rc' then document_status end) as rc_status,
          
          max(case when document_type = 'pan' then event_time end) as pan,
          max(case when document_type = 'pan' then document_status end) as pan_status,
          
          max(case when document_type = 'aadhar' then event_time end) as aadhar,
          max(case when document_type = 'aadhar' then document_status end) as aadhar_status
        from
          (
          select
            captain_id,
            document_type,
            event_time,
            json_extract_scalar(data, '$.status') as document_status,
            row_number() OVER(PARTITION BY captain_id, document_type ORDER BY event_time DESC) as latest_info
          from
            raw.kafka_captain_document_meta_immutable
          where
            yyyymmdd >= date_format({{startdate}}, '%Y%m%d')
          )
          where
            latest_info = 1
          group by
            1
          ),

        rides as (
        select
          rider,
          min(ride_day_1) as first_ridedate,
          min(ride_day_5) as fifth_ridedate,
          min(ride_day_10) as tenth_ridedate,
          min(ride_day_15) as fifteenth_ridedate,
          min(ride_day_20) as twentyth_ridedate,
          min(ride_day_25) as twentyfifth_ridedate,
          min(ride_day_30) as thirtyth_ridedate,
          min(ride_day_50) as fiftyth_ridedate,
          min(ride_day_75) as seventyfifth_ridedate,
          min(ride_day_100) as hundredth_ridedate,
          min(ride_day_150) as onefiftyth_ridedate,
          max(rn) as LTR,
          max(orderdate) as last_ridedate
        from
          (
          select
            captain_id as rider,
            captain_obj_mobile as mobile,
            orderdate,
            rn,
            (case when rn=1 then orderdate end) as ride_day_1,
            (case when rn=5 then orderdate end) as ride_day_5,
            (case when rn=10 then orderdate end) as ride_day_10,
            (case when rn=15 then orderdate end) as ride_day_15,
            (case when rn=20 then orderdate end) as ride_day_20,
            (case when rn=25 then orderdate end) as ride_day_25,
            (case when rn=30 then orderdate end) as ride_day_30,
            (case when rn=50 then orderdate end) as ride_day_50,
            (case when rn=75 then orderdate end) as ride_day_75,
            (case when rn=100 then orderdate end) as ride_day_100,
            (case when rn=150 then orderdate end) as ride_day_150
          from
            (
            select
              captain_id,
              captain_obj_mobile,
              date_parse(yyyymmdd,'%Y%m%d') as orderdate,
              row_number() over (partition by captain_id order by yyyymmdd asc) rn
            from
              orders.order_logs_snapshot
            where
              order_status = 'dropped'
              and (spd_fraud_flag = false or spd_fraud_flag is null)
              and yyyymmdd >= date_format({{startdate}}, '%Y%m%d')
              and yyyymmdd <= date_format({{enddate}}, '%Y%m%d')
            )
          )
        group by 1
        )

        select
          *,
          case
            when onefiftyth_ride is not null then '150th_ride'
            when hundredth_ride is not null then '100th_ride'
            when seventyfifth_ride is not null then '75th_ride'
            when fiftyth_ride is not null then '50th_ride'
            when thirtyth_ride is not null then '30th_ride'
            when twentyfifth_ride is not null then '25th_ride'
            when twentyth_ride is not null then '20th_ride'
            when fifteenth_ride is not null then '15th_ride'
            when tenth_ride is not null then 'tenth_ride'
            when fifth_ride is not null then '5th_ride'
            when first_ride is not null then '1st_ride'
            else '0_Ride'
          end as max_ride_tag
        from
          (
          select
            riders.user_id as captain_id,
            Mobile as mobile_number,
            riders.referralcode as referral_code,
            final_source as source,
            case when riders.ServicesInterested like '%auto%' then 'Auto'
            when riders.ServicesInterested not like '%auto%' and riders.ServicesInterested <> '[]' then 'Link' end as  services_interested,
            Service_Name as servicename,
            date(RegistrationTime) as registration_date,
            RegistrationTime as registration_time,
            Created_On as createdon,
            registeredcity as registration_city,
            profilePicture as profile_picture_uploaded,
            profilePicture_Status,
            license as license_uploaded,
            license_status,
            rc as rc_uploaded,
            rc_status,
            pan as pancard_uploaded,
            pan_status,
            aadhar as aadhar_uploaded,
            aadhar_status,
            status_updates_lms_started as lms_started,
            status_updates_lms_completed as lms_completed,
            status_updates_training_completed_on as training_completed,
            date(ActivationTime) as activation_date,
            ActivationTime as activation_time,
            Status_Updates_Activated_On as statusupdates_activatedon,
            status_updates_video_seen as statusupdates_videoseen,
            mobile_verified,
            status_updates_mobile_number_verified_on,
            application_version,
            Birth_Date,
            exp_ref.status,
            device_device_id,
            first_name,
            last_name,
            cluster as registered_cluster,
            Active as active,
            currentvehicle_number,
            license_number,
            shift_name as shift,
            LTR as lifetimerides,
            first_ridedate as first_ride,
            fifth_ridedate as fifth_ride,
            tenth_ridedate as tenth_ride,
            fifteenth_ridedate as fifteenth_ride,
            twentyth_ridedate as twentyth_ride,
            twentyfifth_ridedate as twentyfifth_ride,
            thirtyth_ridedate as thirtyth_ride,
            fiftyth_ridedate as fiftyth_ride,
            seventyfifth_ridedate as seventyfifth_ride,
            hundredth_ridedate as hundredth_ride,
            onefiftyth_ridedate as onefiftyth_ride,
            last_ridedate
          from
            riders
            left join docs on riders.user_id = docs.captain_id
            left join (select distinct captainid, service_name, final_source from datasets_internal.captain_acquisition) ca on riders.user_id = ca.captainid
            left join experiments.pm_referral_codes exp_ref on riders.referralcode = exp_ref.hub_code
            left join rides on riders.user_id = rides.rider
            left join (select _id, cluster from entity.users_snapshot) uss on riders.user_id = uss._id
          )
      args:
        - var_name: startdate
          var_type: DATE
          value: "DATE('2018-01-01')"
        - var_name: enddate
          var_type: DATE
          expression: 'current_date()'


    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_captain_supply_data_v1"
      partition_columns: [ "registration_date" ]


    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_captain_supply_data_v1"
      table_schema_name: "reports_internal"
      view_name: "sql_ingest_captain_supply_data"
      base_path: "metrics/sql_ingest_captain_supply_data_v1"
      view_schema_name: "reports"

  - run_config:
      name: GROSS_CAPTAIN_OVERVIEW_V1
      start_date: '2021-12-20T00:00:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-gross-capt
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"


    flow_config:
      sql:
        select
        top1.yyyymmdd, top1.city_name as city, top1.service, top1.pickup_cluster,
        csv.mobilenumber as rider_mobile, top1.gross_rides, top1.net_rides,
        top1.total_pings, top1.accepted_pings, csv.shift as current_shift,
        date_format(csv.activationdate,'%Y-%m-%d') as activation_date,
        acq.service_name as current_services, app_availability, last_app_uninstalled_date
        from
        (
        select
        yyyymmdd, city_name, captain_id, service_obj_service_name as service, pickup_cluster,
        count(distinct order_id) as gross_rides,
        count(distinct case when event_type = 'dropped' and (spd_fraud_flag = false or spd_fraud_flag is null) then order_id end) as net_rides,
        count(case when event_type in ('rider_reject', 'rider_busy', 'accepted') then order_id end) as total_pings,
        count(case when event_type = 'accepted' then order_id end) as accepted_pings
        from
        orders.order_logs_immutable
        where
        1=1
        and yyyymmdd >= date_format({{start_date}}, '%Y%m%d')
        and yyyymmdd <= date_format({{end_date}}, '%Y%m%d')
        and event_type in ('rider_reject', 'rider_busy', 'accepted','dropped')
        group by
        1, 2, 3, 4, 5
        ) as top1
        join
        datasets.captain_single_view csv
        on
        top1.captain_id = csv.captainid
        left join
        datasets_internal.captain_acquisition acq
        on
        top1.captain_id = acq.captainid
        left join
        (
        select
        captain,
        (case
        when uninstall_time is null and install_time is not null then 'Only Installed Info'
        when (install_time -  uninstall_time) < 0 then 'Uninstalled'
        when (install_time - uninstall_time) > 0 then 'Re-Installed'
        else 'Unknown' end
        ) as app_availability,
        date_format(from_unixtime(uninstall_time / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS last_app_uninstalled_date
        from
        (
        select
        substr(app_install_tbl.profile_phone,-10,10) as captain,
        max(app_install_tbl.epoch) as install_time,
        max(app_uninstall_tbl.epoch) as uninstall_time
        from
        raw.clevertap_captain_app_installed as app_install_tbl
        left join raw.clevertap_captain_app_uninstalled as app_uninstall_tbl
        on substr(app_install_tbl.profile_phone,-10,10) = substr(app_uninstall_tbl.profile_phone,-10,10)
        group by
        1
        )
        ) as app_tbl
        on
        csv.mobilenumber = app_tbl.captain
      args:
        - var_name: start_date
          var_type: DATE
          expression: 'current_month_start()'
        - var_name: end_date
          var_type: DATE
          expression: 'current_date()'


    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_gross_captain_overview_v1"

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_gross_captain_overview_v1"
      table_name: "sql_gross_captain_overview_v1"
      table_schema_name: "reports_internal"
      view_name: "sql_ingest_gross_captain_overview"
      view_schema_name: "reports"

  - run_config:
      name: CUSTOMER_RETENTION_SGPE_v1
      start_date: '2022-05-18T00:00:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-customer-retention-sgpe-v1
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"


    flow_config:
      sql:
        with v00 as
        (
        select
        customerid as customers,
        date_trunc('week', cast(day as date)) as week,
        DATE_FORMAT(DATE_TRUNC('week', DATE(substr(cast(day as varchar),1,10))), '%Y-%m-%d') AS Start,
        min(day) as startdate,
        max(day) as enddate,
        sum(case when service_name = 'Link' then gross_rides_daily end) as gross_rides,
        sum(case when service_name = 'Link' and net_rides_daily > 0 then net_rides_daily end) as net_rides,
        sum(case when service_name = 'Link' and net_rides_daily > 0 then subscription_rides_daily end) as sub_rides,
        sum(case when service_name = 'Link' and net_rides_daily > 0 then discount_daily end) as burn,
        sum(case when service_name = 'Link' and subscription_rides_daily > 0 then discount_daily end) as subs_discount,
        sum(case when service_name = 'Link' and net_rides_daily > 0 then subtotal_daily end) as subtotal,
        sum(case when service_name = 'Link' then rr_sessions_unique_daily end) as rr
        from
        datasets.customer_rf_daily_kpi
        where
        cast(day as date) >= ({{startdate}})
        and cast(day as date) <= {{enddate}}
        and service_name = 'Link'
        group by
        1, 2, 3
        ),
        max_daily_ao as
        (
        select
        customerid,
        day,
        sum(ao) as ao,
        sum(fe) as fe
        from
        (
        select
        customerid,
        day,
        max(ao_sessions_unique_daily) as ao,
        max(fe_sessions_unique_daily) as fe
        from datasets.customer_rf_daily_kpi
        where
        cast(day as date) >= {{startdate}}
        and cast(day as date) <= {{enddate}}
        group by 1,2
        order by 1,2
        )
        group by 1,2
        order by 1,2
        ),
        weekly_ao as
        (
        select
        date_trunc('week', cast(day as date)) as week,
        DATE_FORMAT(DATE_TRUNC('week', DATE(substr(cast(day as varchar),1,10))), '%Y-%m-%d') AS Start,
        customerid,
        sum(ao) ao,
        sum(fe) fe
        from max_daily_ao
        group by 1,2,3
        ),
        v0 as
        (
        select
        a.*,
        b.week as ao_week,
        b.Start as ao_start,
        b.customerid,
        b.ao,
        b.fe
        from v00 a right join weekly_ao b on a.customers = b.customerid and a.Start = b.Start
        ),
        v1 as
        (
        select *
        from
        (
        select day,
        customer_rf_segment,
        case
        when customer_rf_segment like '%HH%' then '02. HH'
        when customer_rf_segment like '%NEW%' then '02. HH'
        when customer_rf_segment like '%GOLD%' then '05. Gold'
        when customer_rf_segment like '%SILVER%' then '04. Silver'
        when customer_rf_segment like '%PLATINUM%' then '06. Platinum'
        when customer_rf_segment like '%PRIME%' then '03. Prime'
        when customer_rf_segment like '%ELITE%' then '07. Elite'
        when customer_rf_segment like '%INACTIVE%' then '09. Inactive'
        when customer_rf_segment like '%DORMANT%' then '08. Dormant'
        end as finalSegment,
        customerid,
        row_number() over(partition by customerid, day order by recency asc) as row
        from
        datasets.customer_retention_immutable
        where
        day >= {{startdate}} - interval '1' day
        and day <= {{enddate}}
        and day_of_week(cast(day as date)) = 7
        and service_name = 'Link'
        )
        where
        row = 1
        ),
        link_net_custs as
        (
        select
        customerid,
        date_trunc('week', cast(day as date)) as week,
        sum(net_rides_daily) link_rides
        
        from
        datasets.customer_rf_daily_kpi
        where
        cast(day as date) >= ({{startdate}})
        and cast(day as date) <= {{enddate}}
        and service_name = 'Link'
        and net_rides_daily > 0
        group by 1,2
        ),
        auto_ride_info as (
        select
        customerid,
        date_trunc('week', cast(day as date)) as week,
        sum( net_rides_daily) as net_rides_auto
        from datasets.customer_rf_daily_kpi
        where
        cast(day as date) >= ({{startdate}})
        and cast(day as date) <= {{enddate}}
        and service_name = 'Auto'
        and net_rides_daily > 0
        group by 1,2
        ),
        link_auto_net as
        (
        select
        a.week,
        a.customerid link_net_customers,
        b.customerid auto_net_customers,
        a.link_rides,
        b.net_rides_auto
        from link_net_custs a left join auto_ride_info b on a.customerid = b.customerid and a.week = b.week
        ),
        link_auto_segment as
        (
        select
        a.*,
        b.finalSegment
        from link_auto_net a left join v1 b on a.link_net_customers = b.customerid and a.week = (b.day + interval '1' day)
        ),
        link_auto_segment_agg as
        (
        select
        extract(week from cast(week as date)) Week,
        coalesce(finalSegment,'01. New') finalSegment,
        sum(net_rides_auto) auto_rides,
        sum(link_rides) link_rides,
        sum(link_rides) + sum(net_rides_auto) Taxi_rides
        from link_auto_segment
        group by 1,2
        order by 1,2
        ),
        v2 as
        (
        select
        extract(week from cast(coalesce(date(day) + interval '1' day, ao_week) as date)) as Week,
        case
        when finalSegment is null then '01. New'
        when finalSegment is not null then finalSegment
        end as finalSegment,
        min(startdate) startdate,
        max(enddate) enddate,
        count(distinct v1.customerid) as Base,
        count(distinct case when net_rides > 0 then v0.customerid end) as Net_Customers,
        sum(gross_rides) as GrossRides,
        sum(net_rides) as NetRides,
        sum(sub_rides) as Subs_Rides,
        1.00*sum(net_rides)/count(distinct case when net_rides > 0 then v0.customerid end) as RPC,
        count(distinct case when sub_rides > 0 then v0.customerid end) as subs_Customers,
        1.00*sum(sub_rides)/count(distinct case when sub_rides > 0 then v0.customerid end) as Subs_RPC_subsCust,
        1.00*sum(sub_rides)/sum(net_rides) as "subs_rides_percentage",
        sum(burn) as Discount,
        sum(subs_discount) as Subs_Discount,
        sum(subtotal) as Subtotal,
        1.00*sum(burn)/sum(net_rides) as DPR,
        1.00*sum(burn)/sum(subtotal) as "discount_percentage",
        1.00*sum(Subs_Discount)/sum(burn) as "subs_discount_percentage",
        sum(ao) as AO,
        sum(fe) as FE,
        sum(rr) as RR,
        count(distinct case when ao > 0 then v0.customerid end) as AO_Cust,
        count(distinct case when fe > 0 then v0.customerid end) as FE_Cust,
        count(distinct case when rr > 0 then v0.customerid end) as RR_Cust,
        1.00*sum(rr)/sum(fe) as "fe_rr_percentage",
        1.00*sum(net_rides)/sum(gross_rides) as "G2N"
        from
        v0
        full outer join
        v1
        on v0.customerid = v1.customerid and date(v0.ao_week) = (v1.day + interval '1' day)
        group by 1, 2
        order by 1,2
        ),
        final_with_cr as
        (
        select
        a.*,
        b.auto_rides as NetRidesAuto,
        b.Taxi_rides,
        b.auto_rides*100.00/b.Taxi_rides as "auto_rides_contribution_percentage"
        from v2 a left join link_auto_segment_agg b on a.Week = b.Week and a.finalSegment = b.finalSegment
        order by 1,2,3
        ),
        base as
        (
        select
        extract(week from cast(coalesce(date(day) + interval '1' day, week) as date)) as Week,
        case
        when finalSegment is null then '01. New'
        when finalSegment is not null then finalSegment
        end as finalSegment,
        v0.Start,
        v0.customerid as customerid,
        v1.customerid as base_custs
        from
        v0
        full outer join
        v1
        on v0.customerid = v1.customerid and v0.week = (v1.day + interval '1' day)
        ),
        orders as
        (
        select *,
        substr(cast(date_trunc('week',date_parse(yyyymmdd,'%Y%m%d')) as varchar),1,10) Start
        from orders.order_logs_snapshot
        where service_obj_service_name in ('Link')
        and customer_id in (select distinct customerid from base)
        and order_id is not null
        and service_obj_city_display_name is not null
        and yyyymmdd between date_format({{startdate}},'%Y%m%d') and date_format({{enddate}},'%Y%m%d')
        ),
        order_coin as
        (
        select
        Concat('WK-',cast(week(date_parse(yyyymmdd,'%Y%m%d')) as varchar)) week_number,
        substr(cast(date_trunc('week',date_parse(yyyymmdd,'%Y%m%d')) as varchar),1,10) StartDate,
        owner_id customerid,
        entity_id,
        cast(json_extract(coin_wallet_changes, '$[0].offerType') as varchar) offerType,
        coalesce(round(sum(case when transaction_type = 'credit' then cast(amount as double) end)),0) as coin_credited,
        coalesce(round(sum(case when transaction_type = 'debit' and subtype != 'coinExpired' then cast(amount as double) end)),0) as coin_utilized,
        coalesce(round(sum(case when transaction_type = 'debit' and subtype = 'coinExpired' then cast(amount as double) end)),0) as coin_expired
        from payments.transactions_snapshot
        where yyyymmdd between date_format({{startdate}},'%Y%m%d') and date_format({{enddate}},'%Y%m%d')
        and owner_type ='customer'
        and transaction_status = 'done'
        and json_extract(coin_wallet_changes, '$[0].id') is not null
        group by 1,2,3,4,5
        ),
        service_total_coins as
        (
        select
        StartDate,
        week_number,
        customerid,
        sum(case when offerType = 'locationOffer' then coin_credited end) - sum(case when offerType = 'locationOffer' then coin_expired end) locationOffer_burn,
        sum(case when offerType = 'rideOffer' then coin_credited end) - sum(case when offerType = 'rideOffer' then coin_expired end) rideOffer_burn,
        sum(case when offerType = 'scratchCardOffer' then coin_credited end) - sum(case when offerType = 'scratchCardOffer' then coin_expired end) scratchCardOffer_burn,
        sum(case when offerType = 'giftOffer' and service_obj_service_name = 'Link' then coin_utilized end) giftOffer_utilized,
        sum(case when offerType = 'walletRechargeOffer' and service_obj_service_name = 'Link' then coin_utilized end) walletOffer_utilized
        from
        (
        select
        a.*,
        b.*
        from order_coin a right join orders b on a.customerid = b.customer_id and a.entity_id = b.order_id and a.StartDate = b.Start
        order by customerid
        )
        where StartDate is not null
        group by 1,2,3
        ),
        coins as
        (
        select
        Start,
        Week,
        coalesce(finalSegment,'0.NEW') finalSegment,
        sum(locationOffer_burn) locationOffer_burn,
        sum(scratchCardOffer_burn) scratchCardOffer_burn,
        sum(rideOffer_burn) rideOffer_burn,
        sum(walletOffer_utilized) walletOffer_utilized,
        sum(giftOffer_utilized) giftOffer_utilized
        from
        (
        select a.*,
        b.locationOffer_burn,
        b.scratchCardOffer_burn,
        b.rideOffer_burn,
        b.walletOffer_utilized,
        b.giftOffer_utilized
        from base a right join service_total_coins b on a.Start = b.StartDate and a.customerid = b.customerid
        )
        where Start is not null
        group by 1,2,3
        ),
        final_with_coins as
        (
        select
        a.*,
        coalesce(b.locationOffer_burn,0) + coalesce(b.scratchCardOffer_burn,0) + coalesce(b.rideOffer_burn,0)
        + coalesce(b.giftOffer_utilized,0) + coalesce(b.walletOffer_utilized,0) Total_coin_burn
        from final_with_cr a join coins b on a.Week = cast(b.Week as real) and a.finalSegment = b.finalSegment
        ),
        discounted_rides0 as
        (
        select
        DATE_FORMAT(DATE_TRUNC('week', DATE(substr(cast(order_date as varchar),1,10))), '%Y-%m-%d') AS StartDate,
        extract(week from date(order_date)) week,
        city_name,
        customer_id,
        order_id,
        discount,
        amount,
        sub_total
        from orders.order_logs_snapshot
        where service_obj_service_name in ('Link')
        and order_id is not null
        and order_status = 'dropped'
        and yyyymmdd between date_format({{startdate}},'%Y%m%d') and date_format({{enddate}},'%Y%m%d')
        ),
        discounted_rides AS
        (
        select
        b.StartDate,
        b.week,
        coalesce(a.finalSegment,'01. New') finalSegment,
        count (distinct b.customer_id) Net_customers,
        count(distinct b.order_id) Net_rides,
        count(distinct case when b.discount > 0 then b.order_id end) Discounted_Rides,
        count(distinct case when b.discount > 0 then b.order_id end)*100.00/count(distinct b.order_id) Discounted_Rides_perc,
        sum(b.sub_total) sub_total,
        sum(b.discount) discount
        from v1 a right join discounted_rides0 b on a.customerid = b.customer_id and (a.day + interval '1' day) = date(b.StartDate)
        group by 1,2,3
        ),
        final_with_discounted as
        (
        select
        final_with_coins.*,
        discounted_rides.Discounted_Rides_perc as "discounted_rides_percentage",
        discounted_rides.Discounted_Rides
        from final_with_coins join discounted_rides on final_with_coins.Week = discounted_rides.week and final_with_coins.finalSegment = discounted_rides.finalSegment
        )
        select
        extract(year from cast(startdate as date)) year,
        Week as week,
        finalSegment finalsegment,
        startdate,
        enddate,
        Base as base,
        Net_Customers as net_customers,
        subs_Customers subs_customers,
        Try(Net_Customers*100.00/Base) "retention",
        GrossRides as gross_rides,
        NetRides as netrides,
        auto_rides_contribution_percentage,
        Subs_Rides as subs_rides,
        RPC as rides_per_customer,
        subs_rides_percentage,
        Discount as discount,
        Discount + Total_coin_burn discount_with_coins,
        discounted_rides_percentage,
        Subs_Discount as subs_discount,
        Subtotal as subtotal,
        DPR discount_per_ride,
        discount_percentage,
        (Discount + Total_coin_burn)*100.0/Subtotal discount_with_coins_percentage,
        subs_discount_percentage,
        AO as app_open_sessions,
        FE fare_estimate_sessions,
        RR request_rapido_sessions,
        AO_Cust as app_open_customers,
        FE_Cust as fare_estimate_customers,
        RR_Cust as request_rapido_customers,
        fe_rr_percentage,
        "G2N"  gross_to_net_percentage
        from final_with_discounted
        order by 1,2
      args:
        - var_name: startdate
          var_type: DATE
          expression: 'current_week_monday() - timedelta(days=7)'
          format: "DATE('%Y-%m-%d')"
        - var_name: enddate
          var_type: DATE
          expression: 'current_date()'
          format: "DATE('%Y-%m-%d')"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_customer_retention_sgpe_v1"
      partition_columns: ["year","week"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_customer_retention_sgpe_v1"
      table_schema_name: "reports_internal"
      view_name: "customer_retention_sgpe_v1"
      base_path: "metrics/sql_ingest_customer_retention_sgpe_v1"
      view_schema_name: "reports"

  - run_config:
      name: RAPIDO_PASS_PURCHASE_FUNNEL_V1
      start_date: '2022-04-04T00:00:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-purchase-funnel ## changed 
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"

    flow_config:
      sql:
        with base_ret_segment as (
        select *
        from(
        (
        select distinct customer_id as base_customer,subs_segment as subs_segment_week_start, week, date_trunc('week', date(run_date)) as base_week, last_ride_city as base_city
        from
        hive.datasets_internal.subscription_segments_v0
        where cast(run_date as date) >= date(date_trunc('week', date({{start_date}})))
        and cast(run_date as date)    <=  date(date_trunc('week', date({{end_date}})))
        and service_name = 'Link'
        and subs_segment != 'HH'
        and format_datetime(date_trunc('week', date(run_date)), 'E') = 'Mon'
        ) as base_Cus
        left join
        (
        select distinct customerId as user_seg,customer_segment_value as retention_segment_week_start,date_trunc('week', date(day)) as ret_week, geo_city as seg_city
        from datasets.customer_retention_immutable
        where cast(day as date) >= date(date_trunc('week', date({{start_date}})))
        and cast(day as date)    <=  date(date_trunc('week', date({{end_date}})))
        and customer_segment_value != 'HH'
        and format_datetime(date_trunc('week', date(day)), 'E') = 'Mon'
        ) as segment_data
        on user_seg = base_customer and date(ret_week) = date(base_week) and base_city=seg_city
        )
        ),

        page_visit as (
        select *
        FROM base_ret_segment
        left join
        (
        select distinct date_trunc('week',date(date_format(date_parse(yyyymmdd, '%Y%m%d'),'%Y-%m-%d'))) as pv_week,profile_identity as pv_user
        from raw.clevertap_customer_events_master
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d')
        and  yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        and eventname = 'rapidopass'
        )
        on pv_user = base_customer
        ),

        continuetobuypass as (
        select *
        from page_visit
        left join
        (
        select distinct date_trunc('week',date(date_format(date_parse(yyyymmdd, '%Y%m%d'),'%Y-%m-%d'))) as cbp_week,profile_identity as continuetobuypass_user
        from raw.clevertap_customer_events_master
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d')
        and  yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        and eventname in ('continuetobuypass','passrenewclicked','rapidopassbuyclicked')
        )
        on base_customer = continuetobuypass_user
        ),

        passbuyclicked as (
        select *
        from continuetobuypass
        left join
        (
        select distinct date_trunc('week',date(date_format(date_parse(yyyymmdd, '%Y%m%d'),'%Y-%m-%d'))) as pbc_week,profile_identity as passbuyclicked_user
        from raw.clevertap_customer_events_master
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d')
        and  yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        and eventname in ('passbuyclicked','rapidorenewpassbuyclicked','powerpassproceedclicked')
        )
        on base_customer = passbuyclicked_user
        ),

        purchase as (
        select *
        from passbuyclicked
        left join
        (
        select distinct userid as pass_purchaser,
        date_trunc('week', DATE(date))as passBought_week_start
        from (select offerid, userid,date, updated_yyyymmdd2
        from (select * from (select _id as offerid, userId, date, date_format(date_parse(updated_yyyymmdd, '%Y%m%d'),'%Y-%m-%d') as updated_yyyymmdd2,
        rule_data_start_date,
        ROW_NUMBER() OVER(PARTITION BY _id, userid, renewalCount ORDER BY updated_epoch DESC) as latest_raw
        from  raw.mongodb_rapidopass_subscriptions_immutable
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d')
        and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        order by userId, updated_epoch desc)
        where latest_raw = 1))
        )
        on base_customer = pass_purchaser
        ),

        final as (
        (select distinct *,
        subsStartDate as first_pass_purchase_date
        from
        (select *
        from purchase
        left join
        (select distinct userId,subsStartDate
        From
        (
        select distinct userId,subsStartDate,ROW_NUMBER() OVER(PARTITION BY userId ORDER BY subsStartDate ASC) as FirstRow
        From raw.mongodb_rapidopass_subscriptions_immutable
        where yyyymmdd >= date_format(date '2021-01-01','%Y%m%d')
        )
        where FirstRow = 1
        )
        on base_customer = userId
        )
        )
        )

        select
        date_format({{start_date}}, '%Y%m%d') as yyyymmdd,
        week_no,
        week_start_date,
        (date(week_start_date) + interval '6' day) as week_end_date,
        city,
        customer_id,
        subs_segment_week_start,
        retention_segment_week_start,
        pagevisit_flag,
        continuetobuypass_flag,
        buypass_flag,
        purchased_flag,
        first_pass_purchase_date
        from
        (select  week as week_no,
        base_week as week_start_date,
        base_city as city,
        base_customer as customer_id,
        subs_segment_week_start,
        retention_segment_week_start,
        case when pv_user = base_customer then 1 else 0 end as pagevisit_flag,
        case when continuetobuypass_user = base_customer then 1 else 0  end as continuetobuypass_flag,
        case when passbuyclicked_user = base_customer then 1 else 0  end as buypass_flag,
        case when pass_purchaser= base_customer then 1 else 0 end as purchased_flag,
        first_pass_purchase_date,
        count(base_customer) over (partition by base_customer) as cnt
        from final)
        where cnt = 1
        
      args:
        - var_name: start_date
          var_type: DATE
          expression: 'current_date()'               # week start date
        - var_name: end_date
          var_type: DATE
          expression: 'current_date()'

          
    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"       
      base_path: "metrics/sql_ingest_rapido_pass_purchase_funnel_v1"     
      partition_columns: ['yyyymmdd']

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports" 
      table_name: "sql_ingest_rapido_pass_purchase_funnel_v1"
      table_schema_name: "reports_internal"
      view_name: "sql_ingest_rapido_pass_purchase_funnel_v1"
      base_path: "metrics/sql_ingest_rapido_pass_purchase_funnel_v1"
      view_schema_name: "reports"

  - run_config:
      name: CITY_FE2RR_DIAGNOSIS_V1
      start_date: '2020-12-28T00:00:00'
      schedule_interval: 0 0 * * MON
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-city-fe2rr-diagnosis-v0
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"


    flow_config:
      sql:
        with
        fe_tbl as (
        select * from (
        select *, 1.0 as fe_count,
        row_number() over (partition by cast(cast(eventprops_ctsessionid as decimal) as varchar) || ' - ' || profile_phone || ' - ' || servicename order by eventprops_epoch desc) as updated_seq
        from
        (
        SELECT
        eventprops_currentcity AS city, week(DATE_PARSE(yyyymmdd, '%Y%m%d')) as wk,
        DATE_TRUNC('week',DATE_PARSE(yyyymmdd, '%Y%m%d')) AS week_start_date,
        DATE_PARSE(yyyymmdd, '%Y%m%d') as dd,
        eventprops_userid as customer_id,
        eventprops_fareestimateid as fareestimateid,
        eventprops_servicename as servicename,
        cast(eventprops_finalamount AS double) AS finalamount,
        eventprops_ctsessionid, profile_phone, eventprops_epoch,
        cast(eventprops_hfdistance AS double) AS distance,
        cast(eventprops_eta AS double) AS eta,
        case when cast(substr(hhmmss,1,2) as double) between 8 and 11 then 'morning_peak'
        when cast(substr(hhmmss,1,2) as double) between 12 and 16 then 'afternoon'
        when cast(substr(hhmmss,1,2) as double) between 17 and 21 then 'evening_peak'
        else 'rest' end as temporal,
        cast(cast(eventprops_ctsessionid as decimal) as varchar) || ' - ' || profile_phone || ' - ' || eventProps_serviceName AS unique_id,
        date_format(from_unixtime(cast(eventprops_epoch as double) / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate,
        cast(eventprops_discountamount AS double) AS discount,
        cast(eventprops_subtotal AS double) AS subtotal
        FROM
        raw.clevertap_customer_fareestimate
        WHERE
        (yyyymmdd >= date_format({{start_date}}, '%Y%m%d') AND yyyymmdd <= date_format({{end_date}}, '%Y%m%d'))
        AND eventProps_serviceName in ('Link', 'Auto')
        )
        ) where updated_seq=1
        ),

        rr_tbl as (
        select * from (
        select *, 1.0 as rr_count,
        row_number() over (partition by cast(cast(eventprops_ctsessionid as decimal) as varchar) || ' - ' || profile_phone || ' - ' || servicename order by eventprops_epoch desc) as updated_seq
        from
        (
        SELECT
        eventprops_currentcity AS city, week(DATE_PARSE(yyyymmdd, '%Y%m%d')) as wk,
        DATE_PARSE(yyyymmdd, '%Y%m%d') as dd,
        eventprops_userid as customer_id,
        eventprops_fareestimateid as fareestimateid,
        eventprops_servicename as servicename,
        eventprops_ctsessionid, profile_phone, eventprops_epoch,
        cast(cast(eventprops_ctsessionid as decimal) as varchar) || ' - ' || profile_phone || ' - ' || eventprops_servicename AS unique_id,
        date_format(from_unixtime(cast(eventprops_epoch as double) / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS orderdate
        FROM
        raw.clevertap_customer_request_rapido
        WHERE
        (yyyymmdd >= date_format({{start_date}}, '%Y%m%d') AND yyyymmdd <= date_format({{end_date}}, '%Y%m%d'))
        AND eventProps_serviceName in ('Link', 'Auto')
        )
        ) where updated_seq=1
        ),

        response_tbl AS (
        SELECT city,
        fare_estimate_id, week(DATE_PARSE(yyyymmdd, '%Y%m%d')) as wk,
        DATE_PARSE(yyyymmdd, '%Y%m%d') as dd,
        service_level,
        CAST(dynamic_surge_amount AS DOUBLE) AS dynamic_surge,
        CAST(dynamic_fare_amount AS DOUBLE) AS dynamic_fare,
        CAST(rate_card_amount AS DOUBLE) AS rate_card
        FROM
        experiments.iprice_cleaned_responses_v2
        WHERE
        (yyyymmdd >= date_format({{start_date}}, '%Y%m%d') AND yyyymmdd <= date_format({{end_date}}, '%Y%m%d'))
        AND service_level in ('Link', 'Auto')
        ),

        rr_merged AS (
        SELECT
        rr_tbl.city, rr_tbl.wk,
        customer_id,
        rr_tbl.dd,
        rr_tbl.fareestimateid AS fareestimateid,
        unique_id,
        servicename,
        orderdate,
        rr_count
        FROM
        rr_tbl
        LEFT JOIN
        response_tbl
        ON rr_tbl.fareestimateid = response_tbl.fare_estimate_id and rr_tbl.servicename = response_tbl.service_level and rr_tbl.dd = response_tbl.dd and rr_tbl.city = response_tbl.city
        ),

        fe_merged AS (
        SELECT
        fe_tbl.city, fe_tbl.wk,
        customer_id,
        fe_tbl.fareestimateid AS fareestimateid,
        fe_tbl.dd,
        unique_id,
        servicename,
        discount,
        subtotal,
        orderdate,
        week_start_date,
        distance,
        eta,
        temporal,
        finalamount,
        rate_card,
        (dynamic_fare+dynamic_surge) as total_surge,
        fe_count
        FROM
        fe_tbl
        LEFT JOIN
        response_tbl
        ON fe_tbl.fareestimateid = response_tbl.fare_estimate_id and fe_tbl.servicename = response_tbl.service_level and fe_tbl.dd = response_tbl.dd and fe_tbl.city = response_tbl.city
        ),

        fe_rr AS (
        SELECT
        fe_merged.city AS city, fe_merged.wk,
        fe_merged.customer_id AS customer_id,
        fe_merged.week_start_date,
        fe_merged.fareestimateid AS fareestimateid,
        fe_merged.unique_id AS unique_id,
        fe_merged.orderdate AS orderdate,
        fe_merged.servicename as servicename,
        fe_merged.rate_card,
        fe_merged.finalamount,
        fe_merged.distance,
        fe_merged.eta,
        fe_merged.temporal,
        fe_merged.total_surge,
        fe_merged.discount,
        fe_merged.subtotal,
        fe_count,
        coalesce(rr_merged.rr_count,0) AS rr_count
        FROM
        fe_merged
        LEFT JOIN
        rr_merged
        ON fe_merged.city = rr_merged.city
        AND fe_merged.unique_id = rr_merged.unique_id
        AND fe_merged.orderdate = rr_merged.orderdate
        and fe_merged.servicename = rr_merged.servicename
        and fe_merged.dd = rr_merged.dd
        order by city, wk, unique_id
        ),

        final_v0 as
        (
        select week_start_date, city, wk, servicename, discount, subtotal, total_surge, temporal, fe_count, rr_count,
        case when servicename='Link' then fe_count else 0 end as link_fe,
        case when servicename='Auto' then fe_count else 0 end as auto_fe,
        case when servicename='Link' then rr_count else 0 end as link_rr,
        case when servicename='Auto' then rr_count else 0 end as auto_rr,
        case when cast(rate_card as double) is null then '4. Rate_card_not_available'
        when 100*((cast(rate_card as double)-cast(finalamount as double))/cast(rate_card as double))<=-5 then '1. Above_Rate_Card'
        when 100*((cast(rate_card as double)-cast(finalamount as double))/cast(rate_card as double))<=5 then '2. At_Rate_Card'
        else '3. Below_Rate_Card' end as pct_delta_from_rc_bucket,
        case when 100*(cast(discount as double)/cast(subtotal as double))>00 then '1. Discounted_FE'
        when 100*(cast(discount as double)/cast(subtotal as double))=00 then '2. Zero_Discount_FE'
        else '3. NA' end as discount_bucket,
        case when 100*(cast(total_surge as double)/cast(subtotal as double))>00 then '1. Surged FE'
        when 100*(cast(total_surge as double)/cast(subtotal as double))=00 then '2. Zero Surged FE'
        else '3. NA' end as surge_bucket,
        case when cast(distance as double)<=2000 then '00 - 02 km'
        when cast(distance as double)<=4000 then '02 - 04 km'
        when cast(distance as double)<=6000 then '04 - 06 km'
        when cast(distance as double)<=8000 then '06 - 08 km'
        when cast(distance as double)<=10000 then '08 - 10 km'
        else '10+ km' end as distance_bucket,
        case when cast(eta as double)<=5 then '00 - 05'
        when cast(eta as double)<=10 then '05 - 10'
        when cast(eta as double)<=20 then '10 - 20'
        when cast(eta as double)<=30 then '20 - 30'
        else '30+' end as eta_bucket
        from fe_rr
        ),

        v0 as
        (
        select city, week_start_date,
        sum(link_fe) as link_fe, sum(link_rr) as link_rr, sum(auto_fe) as auto_fe, sum(auto_rr) as auto_rr,
        sum(case when pct_delta_from_rc_bucket='1. Above_Rate_Card' then link_fe end) as above_rc_link_fe,
        sum(case when pct_delta_from_rc_bucket='2. At_Rate_Card' then link_fe end) as at_rc_link_fe,
        sum(case when pct_delta_from_rc_bucket='3. Below_Rate_Card' then link_fe end) as below_rc_link_fe,
        sum(case when pct_delta_from_rc_bucket='1. Above_Rate_Card' then auto_fe end) as above_rc_auto_fe,
        sum(case when pct_delta_from_rc_bucket='2. At_Rate_Card' then auto_fe end) as at_rc_auto_fe,
        sum(case when pct_delta_from_rc_bucket='3. Below_Rate_Card' then auto_fe end) as below_rc_auto_fe,
        sum(case when pct_delta_from_rc_bucket='1. Above_Rate_Card' then auto_rr end) as above_rc_auto_rr,
        sum(case when pct_delta_from_rc_bucket='2. At_Rate_Card' then auto_rr end) as at_rc_auto_rr,
        sum(case when pct_delta_from_rc_bucket='3. Below_Rate_Card' then auto_rr end) as below_rc_auto_rr,
        sum(case when discount_bucket='1. Discounted_FE' then link_fe end) as discounted_link_fe,
        sum(case when discount_bucket='1. Discounted_FE' then auto_fe end) as discounted_auto_fe,
        sum(case when servicename='Link' then discount end) as link_discount,
        sum(case when servicename='Link' then subtotal end) as link_subtotal,
        sum(case when servicename='Auto' then discount end) as auto_discount,
        sum(case when servicename='Auto' then subtotal end) as auto_subtotal,
        sum(case when servicename='Link' then total_surge end) as link_surge,
        sum(case when servicename='Auto' then total_surge end) as auto_surge,
        sum(case when surge_bucket='1. Surged FE' then link_fe end) as surged_link_fe,
        sum(case when surge_bucket='1. Surged FE' then auto_fe end) as surged_auto_fe,
        sum(case when distance_bucket='00 - 02 km' then link_fe end) as zero_two_link_fe,
        sum(case when distance_bucket='02 - 04 km' then link_fe end) as two_four_link_fe,
        sum(case when distance_bucket='04 - 06 km' then link_fe end) as four_six_link_fe,
        sum(case when distance_bucket='06 - 08 km' then link_fe end) as six_eight_link_fe,
        sum(case when distance_bucket='08 - 10 km' then link_fe end) as eight_ten_link_fe,
        sum(case when distance_bucket='10+ km' then link_fe end) as ten_plus_link_fe,
        sum(case when distance_bucket='00 - 02 km' then link_rr end) as zero_two_link_rr,
        sum(case when distance_bucket='02 - 04 km' then link_rr end) as two_four_link_rr,
        sum(case when distance_bucket='04 - 06 km' then link_rr end) as four_six_link_rr,
        sum(case when distance_bucket='06 - 08 km' then link_rr end) as six_eight_link_rr,
        sum(case when distance_bucket='08 - 10 km' then link_rr end) as eight_ten_link_rr,
        sum(case when distance_bucket='10+ km' then link_rr end) as ten_plus_link_rr,
        sum(case when distance_bucket='00 - 02 km' then auto_fe end) as zero_two_auto_fe,
        sum(case when distance_bucket='02 - 04 km' then auto_fe end) as two_four_auto_fe,
        sum(case when distance_bucket='04 - 06 km' then auto_fe end) as four_six_auto_fe,
        sum(case when distance_bucket='06 - 08 km' then auto_fe end) as six_eight_auto_fe,
        sum(case when distance_bucket='08 - 10 km' then auto_fe end) as eight_ten_auto_fe,
        sum(case when distance_bucket='10+ km' then auto_fe end) as ten_plus_auto_fe,
        sum(case when distance_bucket='00 - 02 km' then auto_rr end) as zero_two_auto_rr,
        sum(case when distance_bucket='02 - 04 km' then auto_rr end) as two_four_auto_rr,
        sum(case when distance_bucket='04 - 06 km' then auto_rr end) as four_six_auto_rr,
        sum(case when distance_bucket='06 - 08 km' then auto_rr end) as six_eight_auto_rr,
        sum(case when distance_bucket='08 - 10 km' then auto_rr end) as eight_ten_auto_rr,
        sum(case when distance_bucket='10+ km' then auto_rr end) as ten_plus_auto_rr,
        sum(case when eta_bucket='00 - 05' then link_fe end) as zero_five_link_fe,
        sum(case when eta_bucket='05 - 10' then link_fe end) as five_ten_link_fe,
        sum(case when eta_bucket='10 - 20' then link_fe end) as ten_twenty_link_fe,
        sum(case when eta_bucket='20 - 30' then link_fe end) as twenty_thirty_link_fe,
        sum(case when eta_bucket='30+' then link_fe end) as thirty_plus_link_fe,
        sum(case when eta_bucket='00 - 05' then link_rr end) as zero_five_link_rr,
        sum(case when eta_bucket='05 - 10' then link_rr end) as five_ten_link_rr,
        sum(case when eta_bucket='10 - 20' then link_rr end) as ten_twenty_link_rr,
        sum(case when eta_bucket='20 - 30' then link_rr end) as twenty_thirty_link_rr,
        sum(case when eta_bucket='30+' then link_rr end) as thirty_plus_link_rr,
        sum(case when eta_bucket='00 - 05' then auto_fe end) as zero_five_auto_fe,
        sum(case when eta_bucket='05 - 10' then auto_fe end) as five_ten_auto_fe,
        sum(case when eta_bucket='10 - 20' then auto_fe end) as ten_twenty_auto_fe,
        sum(case when eta_bucket='20 - 30' then auto_fe end) as twenty_thirty_auto_fe,
        sum(case when eta_bucket='30+' then auto_fe end) as thirty_plus_auto_fe,
        sum(case when eta_bucket='00 - 05' then auto_rr end) as zero_five_auto_rr,
        sum(case when eta_bucket='05 - 10' then auto_rr end) as five_ten_auto_rr,
        sum(case when eta_bucket='10 - 20' then auto_rr end) as ten_twenty_auto_rr,
        sum(case when eta_bucket='20 - 30' then auto_rr end) as twenty_thirty_auto_rr,
        sum(case when eta_bucket='30+' then auto_rr end) as thirty_plus_auto_rr,
        sum(case when temporal='morning_peak' then link_fe end) as morning_link_fe,
        sum(case when temporal='afternoon' then link_fe end) as afternoon_link_fe,
        sum(case when temporal='evening_peak' then link_fe end) as evening_link_fe,
        sum(case when temporal='rest' then link_fe end) as rest_link_fe,
        sum(case when temporal='morning_peak' then link_rr end) as morning_link_rr,
        sum(case when temporal='afternoon' then link_rr end) as afternoon_link_rr,
        sum(case when temporal='evening_peak' then link_rr end) as evening_link_rr,
        sum(case when temporal='rest' then link_rr end) as rest_link_rr,
        sum(case when temporal='morning_peak' then auto_fe end) as morning_auto_fe,
        sum(case when temporal='afternoon' then auto_fe end) as afternoon_auto_fe,
        sum(case when temporal='evening_peak' then auto_fe end) as evening_auto_fe,
        sum(case when temporal='rest' then auto_fe end) as rest_auto_fe,
        sum(case when temporal='morning_peak' then auto_rr end) as morning_auto_rr,
        sum(case when temporal='afternoon' then auto_rr end) as afternoon_auto_rr,
        sum(case when temporal='evening_peak' then auto_rr end) as evening_auto_rr,
        sum(case when temporal='rest' then auto_rr end) as rest_auto_rr
        from final_v0
        group by city, week_start_date
        order by city, week_start_date
        )

        select * from v0
      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()"
          format: "DATE('%Y-%m-%d')"
        - var_name: end_date
          var_type: DATE
          expression: "next_execution_date()-timedelta(days=1)"
          format: "DATE('%Y-%m-%d')"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_city_fe2rr_diagnosis_v0"
      partition_columns: [ "city","week_start_date" ]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_city_fe2rr_diagnosis_v0"
      table_schema_name: "reports_internal"
      view_name: "city_fe2rr_diagnosis_v0"
      base_path: "metrics/sql_ingest_city_fe2rr_diagnosis_v0"
      view_schema_name: "reports"

  - run_config:
      name: CANCEL_CHARGED_ORDERS_WRT_ETA_SHOWN_V2
      start_date: '2022-04-11T00:00:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-charged-orders-v2
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"

    flow_config:
      sql:
        with x as (  select yyyymmdd, city_name, order_type, order_id, ETA_Shown, ("c_time" - "a_time")/cast(60000 as real) as cancel_time, 
                     (case when "ar_time" is null then 0 else (("ar_time" - "a_time")/cast(60000 as real)) end) as arrived_time 
        from ( 
        select yyyymmdd, city_name, order_type, order_id, avg(case when Rank_1 = 1 then eta end) as ETA_Shown, 
        avg(case when event_type = 'customer_cancelled' then updated_epoch end) as "c_time", 
        avg(case when lag_event_type = 'accepted' then lag_updated_epoch end) as "a_time", 
        avg(case when event_type = 'arrived' then updated_epoch end) as "ar_time" 
        from ( 
        select city_name, order_type, captain_id, customer_feedback_rating, eta, yyyymmdd, event_type,  
        spd_fraud_flag, order_id, updated_epoch, 
        lag(event_type) over (partition by order_id order by updated_epoch) as lag_event_type, 
        lag(updated_epoch) over (partition by order_id order by updated_epoch) as lag_updated_epoch, 
        row_number() over (partition by order_id order by updated_epoch desc) as Rank_1, 
        row_number() over (partition by order_id, captain_id order by updated_epoch desc) as Rank_2 
        from orders.order_logs_immutable 
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d') 
        ) 
        group by 1,2,3,4 ) 
        order by 1), 
        y as ( SELECT yyyymmdd, city_name, order_type, order_id, captain_id, customer_id, cancel_fee, cancel_reason, customer_feedback_rating, order_status, pickup_cluster, captain_obj_mobile 
        from orders.order_logs_snapshot 
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d') 
        ), 
        z as ( 
        SELECT * from datasets.g2n_classify_immutable 
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d') 
        ) 
        SELECT a.yyyymmdd as yyyymmdd, a.city_name as city_name, a.order_type as order_type, a.order_id as order_id, order_status, cancel_time, arrived_time, ETA_Shown, 
        b.captain_id as captain_id, captain_obj_mobile, b.customer_id as customer_id, cancel_fee, cancel_reason, stage_name, epoch, issue_cause_actor_primary, pickup_cluster,
        strategy_to_classify 
        from x as a left join y as b on a.yyyymmdd = b.yyyymmdd and a.order_id = b.order_id and a.city_name = b.city_name and a.order_type = b.order_type 
        left join z as c on a.yyyymmdd = c.yyyymmdd and a.order_id = c.order_id 
        order by 1,2

      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()-timedelta(days=1)"
        - var_name: end_date
          var_type: DATE
          expression: "current_date()-timedelta(days=1)"


    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_cancel_charged_orders_wrt_eta_shown_v2"
      partition_columns: ['yyyymmdd','city_name','order_type']

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_cancel_charged_orders_wrt_eta_shown_v2"
      table_schema_name: "reports_internal"
      view_name: "cancel_charged_orders_wrt_eta_shown_v2"
      base_path: "metrics/sql_ingest_cancel_charged_orders_wrt_eta_shown_v2"
      view_schema_name: "reports"

  - run_config:
      name: CUSTOMER_RETENTION_WOW_V1
      start_date: '2021-08-29T00:00:00'
      schedule_interval: 0 0 * * MON
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-customer-retention-v1
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 4
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"
    flow_config:
      sql:
        select date_format(date_trunc('week', date_parse(yyyymmdd,'%Y%m%d')),'%Y%m%d') as week_start_date, date_trunc('week', date_parse(yyyymmdd,'%Y%m%d')) as week_name, customer_id, city_name, order_status, cancel_fee, order_type 
        from orders.order_logs_snapshot
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d')
        and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        group by 1,2,3,4,5,6,7
        order by 2,1

      args:
        - var_name: start_date
          var_type: DATE
          expression: 'current_date()'
        - var_name: end_date
          var_type: DATE
          expression: 'next_execution_date()-timedelta(days=1)'


    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_customer_retention_wow_v1"
      partition_columns: ['week_start_date']

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_customer_retention_wow_v1"
      table_schema_name: "reports_internal"
      view_name: "customer_retention_wow_v1"
      base_path: "metrics/sql_ingest_customer_retention_wow_v1"
      view_schema_name: "reports"


  - run_config:
      name: 'CAPTAIN_LEVEL_REFERRAL_CAMPAIGNS'
      start_date: '2022-03-31T18:30:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-captain-level-referral-campaigns
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 6
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"


    flow_config:
      sql:
        with cap_ref_dump as
        (
        select
        *
        from
        (
        select
        yyyymmdd, riderid, city, cast(amount as double) as amount, incentiveid,
        json_extract_scalar(data, '$.campaignId') as campaign_id,
        row_number() over (partition by _id order by updated_epoch desc) as row
        from
        raw.kafka_captain_transactions_immutable
        where
        yyyymmdd >= date_format({{start_date}},'%Y%m%d')
        and yyyymmdd <= date_format({{end_date}},'%Y%m%d')
        and status = 'success'
        and transactiontype = 'referral'
        )
        where
        row = 1
        )

        ,campaign as (
        select
        distinct _id as camp_id
        from
        raw.mongodb_rapidoreferralcampaigns_referral_campaigns_immutable
        where
        yyyymmdd >= date_format(current_date - interval '5' month, '%Y%m%d')
        and yyyymmdd <= date_format(current_date - interval '1' day, '%Y%m%d')
        and json_extract_scalar(data, '$.mode.mode') = 'Auto'
        )

        ,refer_incen as
        (
        select
        distinct _id as incen_id, referreruserid, referralrule_campaignid, progress_referreduserid
        from
        raw.mongodb_rapidoreferralcampaigns_referral_incentive_immutable
        where
        yyyymmdd >= date_format(current_date - interval '135' day,'%Y%m%d')
        and yyyymmdd <= date_format(current_date - interval '1' day,'%Y%m%d')
        )

        ,fin_rid_dump as
        (
        select
        yyyymmdd, city, riderid, incentiveid, amount, referreruserid, progress_referreduserid
        from
        cap_ref_dump join campaign on cap_ref_dump.campaign_id = campaign.camp_id
        join refer_incen on cap_ref_dump.incentiveid = refer_incen.incen_id
        )

        ,riders as
        (
        select
        _id, mobile, status_updates_activated_on, yyyymmdd as reg_date
        from
        entity.riders_snapshot
        where
        yyyymmdd >= '20150101'
        )

        ,orders as
        (
        select
        rider,
        count(distinct order_id) as referred_net_orders,
        min(ride_day_1) as referred_first_ridedate,
        min(ride_day_5) as referred_fifth_ridedate,
        min(ride_day_10) as referred_tenth_ridedate,
        min(ride_day_20) as referred_twentyth_ridedate,
        min(ride_day_30) as referred_thirtyth_ridedate,
        min(ride_day_50) as referred_fiftyth_ridedate,
        min(ride_day_75) as referred_seventyfifth_ridedate,
        min(ride_day_100) as referred_hundredth_ridedate
        from
        (
        select
        captain_id as rider, orderdate, order_id,
        (case when rn=1 then orderdate end) as ride_day_1,
        (case when rn=5 then orderdate end) as ride_day_5,
        (case when rn=10 then orderdate end) as ride_day_10,
        (case when rn=20 then orderdate end) as ride_day_20,
        (case when rn=30 then orderdate end) as ride_day_30,
        (case when rn=50 then orderdate end) as ride_day_50,
        (case when rn=75 then orderdate end) as ride_day_75,
        (case when rn=100 then orderdate end) as ride_day_100
        from
        (
        select
        captain_id, order_id,
        date_format(date_parse(yyyymmdd,'%Y%m%d'), '%Y-%m-%d') as orderdate,
        row_number() over (partition by captain_id order by yyyymmdd asc) rn
        from
        orders.order_logs_snapshot
        where
        yyyymmdd >= date_format(current_date - interval '135' day,'%Y%m%d')
        and yyyymmdd <= date_format(current_date - interval '1' day,'%Y%m%d')
        and service_obj_service_name IN ('Delivery','Zomato','Auto')
        and order_status = 'dropped'
        and (spd_fraud_flag = false or spd_fraud_flag is null)

        )
        )
        group by
        1
        )


        select
        yyyymmdd, city, incentiveid, referred_id, referred_mobile, referred_reg_date,
        date_format(from_unixtime((referred_act_date + 19800000)/1000),'%Y-%m-%d') as referred_act_date, referred_amount,
        referred_net_orders, referred_first_ridedate, referred_fifth_ridedate, referred_tenth_ridedate, referred_twentyth_ridedate, referred_thirtyth_ridedate,
        referred_fiftyth_ridedate, referred_seventyfifth_ridedate, referred_hundredth_ridedate,
        referrer_id, mobile as referrer_mobile,
        date_format(from_unixtime((status_updates_activated_on + 19800000)/1000),'%Y-%m-%d') as referrer_act_date, referrer_amount
        from
        (
        select
        pre_tab.*,  mobile as referred_mobile,
        date_format(date_parse(reg_date,'%Y%m%d'), '%Y-%m-%d') as referred_reg_date, status_updates_activated_on as referred_act_date
        from
        (
        select
        coalesce(refrdd.yyyymmdd, refrrr.yyyymmdd) as yyyymmdd, coalesce(refrdd.city, refrrr.city) as city,
        coalesce(refrdd.incentiveid, refrrr.incentiveid) as incentiveid,
        referred_id, referred_amount, referrer_id, referrer_amount
        from
        (
        select
        yyyymmdd, city, riderid as referred_id, incentiveid, sum(amount) as referred_amount
        from
        fin_rid_dump
        where
        riderid = progress_referreduserid
        group by
        1, 2, 3, 4
        ) refrdd
        full outer join
        (
        select
        yyyymmdd, city, riderid as referrer_id, incentiveid, sum(amount) as referrer_amount
        from
        fin_rid_dump
        where
        riderid = referreruserid
        group by
        1, 2, 3, 4
        ) refrrr
        on
        refrdd.yyyymmdd = refrrr.yyyymmdd and refrdd.city = refrrr.city and refrdd.incentiveid = refrrr.incentiveid
        ) as pre_tab left join riders
        on pre_tab.referred_id = riders._id
        ) as post_tab left join riders
        on post_tab.referrer_id = riders._id
        left join orders
        on post_tab.referred_id = orders.rider
      args:
        - var_name: start_date
          var_type: DATE
          expression: 'current_date()-timedelta(days = 90)'
        - var_name: end_date
          var_type: DATE
          expression: 'current_date()'


    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_captain_level_referral_campaigns_v1"
      partition_columns: [ "yyyymmdd" ]


    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_captain_level_referral_campaigns_v1"
      table_schema_name: "reports_internal"
      view_name: "sql_ingest_captain_level_referral_campaigns_v1"
      base_path: "metrics/sql_ingest_captain_level_referral_campaigns_v1"
      view_schema_name: "reports"

  - run_config:
      name: CUSTOMER_SERVICE_AFFINITY_V0
      start_date: '2022-04-05T00:00:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-customer-service-affinity-v0
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 3600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.8
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"

    flow_config:
      sql:
       WITH city_service AS (
        SELECT
        distinct service_detail_id service_details_id,service_level, city_display_name, city_id
        FROM
        datasets.service_mapping
        WHERE
        service_level in ('Link', 'Auto')
        AND service_category in ('app', 'auto')
        ),
        rr_tbl AS (
        SELECT
        date_format(from_unixtime(epoch / 1000, 'Asia/Kolkata'), '%Y-%m-%d') AS day,
        city_display_name AS city,
        city_id,
        service_level AS service_level,
        user_id AS customer_id,
        ct_session_id,
        epoch,
        b.service_details_id,
        cast(cast(ct_session_id AS decimal) AS varchar) || ' - ' || user_id AS unique_id,
        row_number() over (partition BY city_display_name, cast(cast(ct_session_id AS decimal) as varchar) || ' - ' || user_id ORDER BY epoch DESC) AS updated_seq,
        row_number() over (partition BY city_display_name, user_id ORDER BY epoch DESC) AS event_seq
        FROM
        canonical.clevertap_customer_request_rapido rr INNER JOIN city_service b
        on rr.service_details_id = b.service_details_id
        WHERE rr.user_id is NOT NULL
        AND rr.ct_session_id is NOT NULL
        AND yyyymmdd >= date_format({{start_date}}, '%Y%m%d')
        AND yyyymmdd <= date_format({{end_date}}, '%Y%m%d')
        ),
        rr_with_cityservice_seq as (
        SELECT
        *,
        row_number() over(partition by city,customer_id order by city,customer_id,epoch desc) session_sequence
        FROM
        rr_tbl
        WHERE updated_seq = 1
        ),
        rr_session_agg as (
        SELECT
        date_format({{end_date}}, '%Y-%m-%d') run_date,
        city_id,
        city,
        customer_id,
        min(day) last_rr_active_day,
        max(case when session_sequence = 1 then service_level end) last_rr_service_name,
        cast(count(case when service_level ='Auto' then ct_session_id end) as double) auto_rr_sessions,
        cast(count(case when service_level ='Link' then ct_session_id end) as double) link_rr_sessions,
        cast(count(ct_session_id) as double) taxi_rr_sessions,
        cast((count(case when service_level ='Link' then ct_session_id end)*1.00/count(ct_session_id)) as double) link_rr_contributions,
        cast((count(case when service_level ='Auto' then ct_session_id end)*1.00/count(ct_session_id)) as double) auto_rr_contributions,
        'v0' version
        FROM
        rr_with_cityservice_seq
        WHERE
        session_sequence <= 10
        GROUP BY 1,2,3,4
        )

        SELECT
        *,
        CASE
            WHEN auto_rr_contributions <.35 THEN 'ONLY_LINK'
            WHEN auto_rr_contributions >= .35 AND auto_rr_contributions <= .65 THEN 'BOTH'
            WHEN auto_rr_contributions > .65 THEN 'ONLY_AUTO'
            ELSE 'UNKNOWN' END service_affinity
        FROM rr_session_agg

      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()-timedelta(days=89)"
        - var_name: end_date
          var_type: DATE
          expression: "current_date()"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_customer_service_affinity_v0"
      partition_columns: ["run_date","city"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_customer_service_affinity_v0"
      table_schema_name: "reports_internal"
      view_name: "customer_service_affinity_v0"
      base_path: "metrics/sql_ingest_customer_service_affinity_v0"
      view_schema_name: "reports"


  - run_config:
      name: CUSTOMER_REFUND_V1
      start_date: '2022-05-08T00:00:00'
      schedule_interval: 0 2 * * *
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-customer-refund-v1
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 3600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.8
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"

    flow_config:
      sql:
        With dasboard_coins_credit as (
        select
        data.yyyymmdd, entity_id as order_id, a.mobile as customer_mobile_number, meta_data_ticket_id as ticket_id,  remarks as reason,
        cast(json_extract(data.wallets,'$.0.name') as varchar(15)) as wallets_name,
        cast(json_extract(data.wallets,'$.0.amount') as int) as amount,
        meta_data_adjusted_by as adjusted_by,
        coin_wallet_changes,
        wallets,
        data.epoch,
        owner_type,
        owner_id,
        transaction_status,
        transaction_type,
        subtype,
        subsub_type,
        data.updated_at,
        actor_id,
        actor_type,
        id,
        a.city as customer_city,
        a.email as customer_email,
        a.roles as customer_roles,
        a.payment_method as customer_payment_method,
        a.date_of_birth as customer_date_of_birth,
        a.epoch as customer_epoch
        from payments.transactions_snapshot as data
        left join entity.users_snapshot a
        on data.owner_id = a._id
        where
        data.yyyymmdd between date_format({{start_date}},'%Y%m%d') and date_format({{end_date}},'%Y%m%d')
        and owner_type = 'customer'
        and transaction_status = 'done'
        and transaction_type = 'credit'
        and coin_wallet_changes like '%dashboardCoinsCredit%'
        ),
        wallet_refund as (
        select
        data.yyyymmdd, entity_id as order_id, a.mobile as customer_mobile_number, meta_data_ticket_id as ticket_id,  remarks as reason,
        cast(json_extract(data.wallets,'$.0.name') as varchar(15)) as wallets_name,
        cast(json_extract(data.wallets,'$.0.amount') as int) as amount,
        meta_data_adjusted_by as adjusted_by,
        coin_wallet_changes,
        wallets,
        data.epoch,
        owner_type,
        owner_id,
        transaction_status,
        transaction_type,
        subtype,
        subsub_type,
        data.updated_at,
        actor_id,
        actor_type,
        id,
        a.city as customer_city,
        a.email as customer_email,
        a.roles as customer_roles,
        a.payment_method as customer_payment_method,
        a.date_of_birth as customer_date_of_birth,
        a.epoch as customer_epoch
        from payments.transactions_snapshot as data
        left join  entity.users_snapshot a
        on data.owner_id = a._id
        where
        data.yyyymmdd between date_format({{start_date}},'%Y%m%d') and date_format({{end_date}},'%Y%m%d')
        and owner_type = 'customer'
        and transaction_status = 'done'
        and transaction_type = 'credit'
        and subtype = 'customerRefund'
        )
        select
        a.*
        from
        dasboard_coins_credit a
        union all
        select
        b.*
        from
        wallet_refund b
        order by 1

      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()-timedelta(days=7)"
        - var_name: end_date
          var_type: DATE
          expression: "current_date()"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"

    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_customer_refund_v1"
      partition_columns: ["yyyymmdd"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_customer_refund_v1"
      table_schema_name: "reports_internal"
      view_name: "customer_refund_v1"
      base_path: "metrics/sql_ingest_customer_refund_v1"
      view_schema_name: "reports"

  - run_config:
      name: AUTO_CAPTAIN_DETAIL_V1
      start_date: '2022-05-18T18:30:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-auto-captain-detail-v1
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 3
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"

    flow_config:
      sql:

        with redeem_date as
        (
        select 
        owner_id as userid, 
        count(distinct id) as lt_redeem_count,
        min(yyyymmdd) as min_redeem_date,
        max(yyyymmdd) as max_redeem_date
        from 
        raw.kafka_payments_transaction_immutable
        where
        sub_type = 'redeem'
        and transaction_type = 'debit'
        and owner_type = 'captain'
        group by
        1
        )

        select
        city, captain_id, captain_mobile, referral_code, source, activated_services, active, activationdate,
        device_model, device_device_id, first_ride_date, last_ride_date, wallet_balance, lifetimerides, cash_rides_perc, wallet_rides_perc,
        (case when accounts_len >= 1 or upi_len >= 1 then 'Yes' else 'No' end) as account_upi_added,
        lt_redeem_count, first_redeem_date, last_redeem_date
        from
        (
        select
        citys.cityname as city, l_rids._id as captain_id, l_rids.mobile as captain_mobile, referral_code,
        (case
        when exp_ref.source = 'Vendor' then 'Vendor'
        when exp_ref.source = 'Central FOS' then 'Central FOS'
        when exp_ref.source = 'Intern' then 'Intern'
        when exp_ref.source = 'RFP FOS' then 'RFP FOS'
        when (substr(referral_code,1,1) = 'C' or substr(referral_code,1,1) = 'R') and length(referral_code) = 7 then 'Referral' else
        'Organic'
        end) as source,
        service_name as activated_services, l_rids.active,
        concat(l_rids.device_manufacturer, ' ', l_rids.device_model) as device_model, l_rids.device_device_id,
        date_format(csv.firstridedate,'%Y-%m-%d') as first_ride_date, date_format(csv.lastridedate,'%Y-%m-%d') as last_ride_date,
        date_format(csv.activationdate,'%Y-%m-%d') as activationdate,
        balance as wallet_balance, coalesce(csv.lifetimerides,0) as lifetimerides, cash_rides_perc, wallet_rides_perc,
        lt_redeem_count, date_format(date_parse(min_redeem_date, '%Y%m%d'),'%Y-%m-%d') as first_redeem_date,
        date_format(date_parse(max_redeem_date,'%Y%m%d'),'%Y-%m-%d') as last_redeem_date,
        cardinality(rid_wallet.accounts) as accounts_len , cardinality(cast(rid_wallet.upiaccounts as array<json>)) as upi_len
        from
        entity.riders_snapshot l_rids
        join (select distinct _id as city_id, displayname as cityname
        from hive.raw.mongodb_rapidoprod_cities_immutable) citys on l_rids.city = citys.city_id
        join (select * from datasets_internal.captain_acquisition where service_name like '%Auto%') acq on l_rids._id = acq.captainid
        join (select * from datasets.captain_single_view
        where ActivationDate >= {{start_date}} and ActivationDate <= {{end_date}}) csv on l_rids._id = csv.captainid
        left join raw.mongodb_rapidopayments_riderwalletaccounts_snapshot rid_wallet on l_rids._id = rid_wallet.riderid
        left join  experiments.pm_referral_codes_auto exp_ref on l_rids.referral_code = exp_ref.hub_code
        left join (
        select
        captain_id,
        cast(count(distinct case when collected_cash > 0 then order_id end) as double) / count(distinct order_id) as cash_rides_perc,
        cast(count(distinct case when (collected_cash is null or collected_cash <= 0) then order_id end) as double) / count(distinct order_id) as wallet_rides_perc
        from orders.order_logs_snapshot
        where
        service_obj_service_name IN ('Auto','Delivery', 'Zomato')
        and order_status = 'dropped'
        and (spd_fraud_flag is null or spd_fraud_flag = false)
        and yyyymmdd >= '20200701'
        and yyyymmdd <= date_format(current_date,'%Y%m%d')
        group by 1
        ) orders on l_rids._id = orders.captain_id
        left join redeem_date on l_rids._id = redeem_date.userid
        )

      args:
        - var_name: start_date
          var_type: DATE
          value: "DATE('2018-01-01')"
        - var_name: end_date
          var_type: DATE
          expression: 'current_date()'

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"

    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_auto_captain_detail_v1"
      partition_columns: ["activationdate"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_auto_captain_detail_v1"
      table_schema_name: "reports_internal"
      view_name: "auto_captain_detail_v1"
      base_path: "metrics/sql_ingest_auto_captain_detail_v1"
      view_schema_name: "reports"

  - run_config:
      name: CITY_WEEKLY_KM_WISE_PRICE_PARITY_METRICS_V2
      start_date: '2022-05-25T00:00:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      cluster_config:
        name: rapido-sql-ingest-city-pp-wow-v2
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 3
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"

    flow_config:
      sql:
        with orders as (
        select
        service_obj_city_display_name,
        week(date_parse(order_date, '%Y-%m-%d')) as week_,
        date_trunc('week', cast(order_date as date)) as startdate,
        customer_id,
        service_obj_service_name,
        order_id,
        distance_final_distance,
        sub_total,
        amount,
        discount
        from
        orders.order_logs_snapshot
        WHERE
        service_obj_service_name in ('Link', 'Auto')
        AND order_status = 'dropped'
        AND (
        (spd_fraud_flag = false)
        or (spd_fraud_flag is null)
        )
        and yyyymmdd >= date_format({{start_date}}, '%Y%m%d')
        AND yyyymmdd <= date_format({{end_date}}, '%Y%m%d')
        and service_obj_city_display_name in (
        SELECT
        distinct city_display_name
        from
        datasets_internal.service_mapping
        where
        service_level = 'Auto'
        )
        ),
        fin_tab as (
        select
        service_obj_city_display_name,
        week_,
        date_format(startdate, '%Y-%m-%d') as wk_start,
        case
        when distance_final_distance <= 1 then 'A.00to01'
        when distance_final_distance > 1
        and distance_final_distance <= 2 then 'B.01to02'
        when distance_final_distance > 2
        and distance_final_distance <= 3 then 'C.02to03'
        when distance_final_distance > 3
        and distance_final_distance <= 4 then 'D.03to04'
        when distance_final_distance > 4
        and distance_final_distance <= 5 then 'E.04to05'
        when distance_final_distance > 5
        and distance_final_distance <= 6 then 'F.05to06'
        when distance_final_distance > 6
        and distance_final_distance <= 7 then 'G.06to07'
        when distance_final_distance > 7
        and distance_final_distance <= 8 then 'H.07to08'
        when distance_final_distance > 8
        and distance_final_distance <= 9 then 'I.08to09'
        when distance_final_distance > 9
        and distance_final_distance <= 10 then 'J.09to10'
        when distance_final_distance > 10
        and distance_final_distance <= 11 then 'K.10to11'
        when distance_final_distance > 11
        and distance_final_distance <= 12 then 'L.11to12'
        when distance_final_distance > 12
        and distance_final_distance <= 13 then 'M.12to13'
        when distance_final_distance > 13
        and distance_final_distance <= 14 then 'N.13to14'
        when distance_final_distance > 14
        and distance_final_distance <= 15 then 'O.14to15'
        else 'P.15more'
        end as Distance,
        avg(
        case
        when service_obj_service_name = 'Link' then Amount
        end
        ) as Avg_Link_Post_discount_Amount,
        avg(
        case
        when service_obj_service_name = 'Auto' then Amount
        end
        ) as Avg_Auto_Post_discount_Amount,
        (
        avg(
        case
        when service_obj_service_name = 'Auto' then Amount
        end
        ) - avg(
        case
        when service_obj_service_name = 'Link' then Amount
        end
        )
        ) as Price_diff_Auto_Link,
        avg(
        (
        case
        when (
        service_obj_service_name = 'Auto'
        and discount != 0
        ) then discount
        end
        )
        ) as Auto_Discount_per_discounted_ride_AutoDPDR,
        avg(
        (
        case
        when (
        service_obj_service_name = 'Link'
        and discount != 0
        ) then discount
        end
        )
        ) as Link_Discount_per_discounted_ride_LinkDPDR,
        count(
        distinct(
        case
        when service_obj_service_name = 'Auto' then order_id
        end
        )
        ) as Net_Auto_rides,
        count(
        distinct(
        case
        when service_obj_service_name = 'Link' then order_id
        end
        )
        ) as Net_Link_rides,
        count(
        distinct(
        case
        when service_obj_service_name = 'Auto'
        and discount != 0 then order_id
        end
        )
        ) as Net_Auto_Discounted_rides,
        count(
        distinct(
        case
        when service_obj_service_name = 'Link'
        and discount != 0 then order_id
        end
        )
        ) as Net_Link_Discounted_rides
        from
        orders
        group by
        1,
        2,
        3,
        4
        ),
        ferr_table as (
        select
        fe.fe_date,
        fe.city,
        fe_ct_sess,
        rr_ct_sess,
        fe_id,
        fe_rr_id,
        est_distance,
        (
        case
        when est_distance <= 1 then 'A.00to01'
        when est_distance > 1
        and est_distance <= 2 then 'B.01to 02'
        when est_distance > 2
        and est_distance <= 3 then 'C.02to03'
        when est_distance > 3
        and est_distance <= 4 then 'D.03to04'
        when est_distance > 4
        and est_distance <= 5 then 'E.04to05'
        when est_distance > 5
        and est_distance <= 6 then 'F.05to06'
        when est_distance > 6
        and est_distance <= 7 then 'G.06to07'
        when est_distance > 7
        and est_distance <= 8 then 'H.07to08'
        when est_distance > 8
        and est_distance <= 9 then 'I.08to09'
        when est_distance > 9
        and est_distance <= 10 then 'J.09to10'
        when est_distance > 10
        and est_distance <= 11 then 'K.10to11'
        when est_distance > 11
        and est_distance <= 12 then 'L.11to12'
        when est_distance > 12
        and est_distance <= 13 then 'M.12to13'
        when est_distance > 13
        and est_distance <= 14 then 'N.13to14'
        when est_distance > 14
        and est_distance <= 15 then 'O.14to15'
        else 'P.15more'
        end
        ) as distTag,
        fe_service,
        rr_service,
        fe.customer as customer_id,
        date_format(date_trunc('week', date(fe.fe_date)), '%Y-%m-%d') AS Week_Start_Date,
        date_trunc('week', date(fe.fe_date)) as fe_week_start
        from
        (
        select
        date_parse(yyyymmdd, '%Y%m%d') as fe_date,
        current_city as city,
        service_name as fe_service,
        fare_estimate_id as fe_id,
        user_id as customer,
        cast(cast(ct_session_id as decimal) as varchar) || ' - ' || user_id as fe_ct_sess,
        (cast(hf_distance as double) / 1000) as est_distance
        from
        canonical.clevertap_customer_fare_estimate
        where
        yyyymmdd >= date_format({{start_date}}, '%Y%m%d')
        AND yyyymmdd <= date_format({{end_date}}, '%Y%m%d')
        and service_name in ('Link', 'Auto')
        and current_city IN (
        select
        service_obj_city_display_name
        from
        orders
        )
        ) as fe
        left join (
        select
        date_parse(yyyymmdd, '%Y%m%d') as rr_date,
        current_city as city,
        service_name as rr_service,
        fare_estimate_id as fe_rr_id,
        cast(cast(ct_session_id as decimal) as varchar) || ' - ' || user_id as rr_ct_sess
        from
        canonical.clevertap_customer_request_rapido
        where
        yyyymmdd >= date_format({{start_date}}, '%Y%m%d')
        AND yyyymmdd <= date_format({{end_date}}, '%Y%m%d')
        and service_name in ('Link', 'Auto')
        and current_city IN (
        select
        service_obj_city_display_name
        from
        orders
        )
        ) as rr on fe.fe_ct_sess = rr.rr_ct_sess
        ),
        fe2rr_fin as (
        select
        city,
        week,
        week_start,
        distTag,
        cast(Comm_RR as double) / Comm_FE as Commute_FE2RR,
        cast(Link_RR as double) / Link_FE as Link_FE2RR,
        cast(Auto_RR as double) / Auto_FE as Auto_FE2RR
        from
        (
        select
        ferr_table.city,
        week(fe_week_start) as week,
        date_format(fe_week_start, '%Y-%m-%d') as week_start,
        distTag,
        count(distinct fe_ct_sess) as Comm_FE,
        count(distinct rr_ct_sess) as Comm_RR,
        count(
        distinct case
        when fe_service = 'Link' then fe_ct_sess
        end
        ) as Link_FE,
        count(
        distinct case
        when rr_service = 'Link' then rr_ct_sess
        end
        ) as Link_RR,
        count(
        distinct case
        when fe_service = 'Auto' then fe_ct_sess
        end
        ) as Auto_FE,
        count(
        distinct case
        when rr_service = 'Auto' then rr_ct_sess
        end
        ) as Auto_RR
        from
        ferr_table
        group by
        1,
        2,
        3,
        4
        )
        )
        select
        coalesce(
        fe2rr_fin.city,
        fin_tab.service_obj_city_display_name
        ) as City,
        coalesce(fe2rr_fin.week, fin_tab.week_) as Week,
        coalesce(fe2rr_fin.week_start, fin_tab.wk_start) as week_start,
        coalesce(fe2rr_fin.distTag, fin_tab.Distance) as Distance,
        Commute_FE2RR,
        Link_FE2RR,
        Auto_FE2RR,
        Avg_Link_Post_discount_Amount,
        Avg_Auto_Post_discount_Amount,
        Price_diff_Auto_Link,
        Auto_Discount_per_discounted_ride_AutoDPDR,
        Link_Discount_per_discounted_ride_LinkDPDR,
        Net_Auto_rides,
        Net_Link_rides,
        Net_Auto_Discounted_rides,
        Net_Link_Discounted_rides
        from
        fe2rr_fin full
        outer join fin_tab on fe2rr_fin.city = fin_tab.service_obj_city_display_name
        and fe2rr_fin.week_start = fin_tab.wk_start
        and fe2rr_fin.distTag = fin_tab.Distance
        order by
        1,
        2,
        3,
        4
      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()-timedelta(days=14)"
        - var_name: end_date
          var_type: DATE
          expression: "current_date()"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"

    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_city_pp_wow_v2"
      partition_columns: ["week_start"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_city_pp_wow_v2"
      table_schema_name: "reports_internal"
      view_name: "city_pp_wow_v2"
      base_path: "metrics/sql_ingest_city_pp_wow_v2"
      view_schema_name: "reports"


  - run_config:
      name: DIAGNOSTICS_AO_FE_V1
      start_date: '2022-05-01T00:00:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-diagnostics-ao-fe-v1
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 3600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.8
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"

    flow_config:
      sql:
        with v5 as(
        select
        t1.date,
        t1.city,
        channel,
        case when ride is null then 'no_rides_booked' else ride end as ride,
        morning_ao_users,afternoon_ao_users,evening_ao_users,midnight_ao_users,
        morning_fe_users,afternoon_fe_users,evening_fe_users,midnight_fe_users,
        unserviceable_ao,
        sum(ao_sessions_unique_daily) as ao_users,
        sum(fe_sessions_unique_daily) as fe_users,
        try((sum(fe_sessions_unique_daily)*100.00)/(sum(ao_sessions_unique_daily))) as ao2fe
        from
        (
        select
        customerid,
        date_parse(day,'%Y-%m-%d') as date,
        ao_sessions_unique_daily,
        fe_sessions_unique_daily,
        rr_sessions_unique_daily,
        lower(city) as city
        from
        datasets.customer_rf_daily_kpi
        where
        (service_name = 'Link'
        or service_name is null)
        and day >= date_format({{start_date}}, '%Y-%m-%d')
        and day <= date_format({{end_date}}, '%Y-%m-%d')
        )as t1
        left join (
        select
        customerid,
        ride,
        channel
        from
        (
        select
        customerid,
        ride,
        channel,
        orderdate,
        campaign,
        ROW_NUMBER() OVER (PARTITION BY customerid ORDER BY orderdate desc) as row_number
        from
        datasets.customer_platform_ride_acquisition
        where
        orderdate >= date_format({{start_date}}, '%Y-%m-%d')
        and orderdate <= date_format({{end_date}}, '%Y-%m-%d')
        )
        where
        row_number = 1
        ) as t2 on t1.customerid = t2.customerid
        inner join
        (
        select
        date,
        city,
        sum(case when time_level='morning' then ao_users end)  as morning_ao_users,
        sum(case when time_level='afternoon' then ao_users end)  as afternoon_ao_users,
        sum(case when time_level='evening' then ao_users end)  as evening_ao_users,
        sum(case when time_level='midnight' then ao_users end)  as midnight_ao_users,
        sum(case when time_level='morning' then fe_users end)  as morning_fe_users,
        sum(case when time_level='afternoon' then fe_users end)  as afternoon_fe_users,
        sum(case when time_level='evening' then fe_users end)  as evening_fe_users,
        sum(case when time_level='midnight' then fe_users end)  as midnight_fe_users
        from(
        select
        date_parse(substr(time_value,1,10),'%Y-%m-%d') as date,
        lower(city) as city,time_level,
        sum(ao_users) as ao_users,
        sum(fe_users) as fe_users
        from
        datasets.funnel_servicelevel_kpi
        where
        time_level in ('afternoon','morning','midnight','evening')
        and geo_level='city'
        and lower(service_name) in ('link')
        AND city != 'na' AND city IS NOT NULL AND city !=''
        and substr(time_value,1,10) >=  date_format({{start_date}}, '%Y-%m-%d')
        and substr(time_value,1,10) <= date_format({{end_date}}, '%Y-%m-%d')
        group by 1,2,3
        )
        group by 1,2
        ) as t3 on (t1.date=t3.date) and (t1.city=t3.city)
        inner join
        (
        select
        lower(city) as city,
        date_format(date_parse(substr(yyyymmdd,1,8),'%Y%m%d'),'%Y-%m-%d') as date,
        COUNT(distinct(uniqueid)) as unserviceable_ao
        FROM(
        SELECT
        eventprops_currentcity as city,
        eventprops_userid,
        cast(date_format(from_unixtime(cast(eventprops_epoch as double)/1000 + 19800), '%H') as real) as hour,
        yyyymmdd,eventprops_currentcluster as cluster,
        cast(cast(eventprops_ctsessionid as decimal) as varchar) || ' - ' || profile_phone as uniqueid
        FROM
        raw.clevertap_customer_orderactivity
        WHERE
        1=1
        and yyyymmdd>= date_format({{start_date}}, '%Y%m%d')
        and yyyymmdd<= date_format({{end_date}}, '%Y%m%d')
        and eventprops_serviceable= 'false'
        )
        group by 1,2) as t4 on (t1.date=CAST(t4.date AS timestamp(3))) and (t1.city=t4.city)
        group by 1,2,3,4,5,6,7,8,9,10,11,12,13
        )

        select date,city,channel,ride,
        morning_ao_users,afternoon_ao_users,evening_ao_users,midnight_ao_users,
        morning_fe_users,afternoon_fe_users,evening_fe_users,midnight_fe_users,
        unserviceable_ao,
        ao_users,fe_users,ao2fe
        from v5
      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()"
        - var_name: end_date
          var_type: DATE
          expression: "current_date()"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"

    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_diagnostics_ao_fe_v1"
      partition_columns: ["date"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_diagnostics_ao_fe_v1"
      table_schema_name: "reports_internal"
      view_name: "diagnostics_ao_fe_v1"
      base_path: "metrics/sql_ingest_diagnostics_ao_fe_v1"
      view_schema_name: "reports"

  - run_config:
      name: GP_B2B_LOSS_V1
      start_date: '2022-05-07T00:00:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-gp-b2b-loss-v1
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"

    flow_config:
      sql:
        with Composite as (
        Select
        composite_hex_id,city_name, source_hex , time_of_day , day_of_week , refresh_date
        from datasets.composite_hex_config
        where
        enabled=True
        ),
        cluster as (
        select
        hex_id,cluster,lower(city) as city
        from
        datasets.city_cluster_hex
        where
        resolution = 8
        )
        , one as(
        select composite_hex_id,city_name, source_hex as source_hex5 , time_of_day , day_of_week , refresh_date,hex_id,cluster,city
        from Composite left join cluster on Composite.source_hex = cluster.hex_id
        )
        ,
        citys as (
        select distinct _id as city_id, displayname as cityname
        from hive.raw.mongodb_rapidoprod_cities_immutable
        ) ,
        Orders as (
        Select
        order_id, city_name,updated_quarter_hour, yyyymmdd,pickup_location_hex_8,pickup_cluster,updated_epoch,order_date,spd_fraud_flag,event_type,service_obj_service_name,captain_id
        from
        orders.order_logs_immutable
        where
        yyyymmdd >= date_format({{startdate}}, '%Y%m%d')
        and yyyymmdd <= date_format({{enddate}}, '%Y%m%d')
        and lower(city_name) IN  (select city from one)
        and service_obj_service_name IN ('Link','Delivery','Zomato')
        ),
        Pings_Hex as (
        select
        id,yyyymmdd, epoch, quarter_hour, pick_cluster,client_other_data_city,
        from_unixtime(round(cast(epoch as double) / 1000) + 19800) requested_ds,
        pickup_location_latitude,pickup_location_longitude,client_parent_name,client_order_id,pickup_location_hex_8,
        (case when substr(quarter_hour, 1, 2) >= '08' and substr(quarter_hour,1,2) <= '11' then 'morning_peak' else
        case when substr(quarter_hour, 1, 2) >= '17' and substr(quarter_hour,1,2) <= '21' then 'evening_peak' else
        case when substr(quarter_hour, 1, 2) > '11' and substr(quarter_hour,1,2) < '17' then 'afternoon' else
        case when substr(quarter_hour, 1, 2) >= '00' and substr(quarter_hour,1,2) < '08' then 'rest_morning' else
        'rest_evening'
        end
        end
        end
        end) as window_name,
        date_format(date_parse(yyyymmdd,'%Y%m%d'), '%W') as weekday_name
        from
        hive.raw.serviceability_requests
        where
        yyyymmdd >= date_format({{startdate}}, '%Y%m%d')
        and yyyymmdd <= date_format({{enddate}}, '%Y%m%d')
        and client_parent_name in('Swiggy','Zomato')
        and client_other_data_city In (select city_id from citys)
        ),
        GP_Serviceable as (
        Select *
        from
        (select
        _id,client_otherdata_city,
        json_extract_scalar(data, '$.GPResponse.serviceable') as GP_Serviceable
        from
        hive.raw.mongodb_pricingprod_serviceabilityrequests_immutable
        where
        yyyymmdd >= date_format({{startdate}}, '%Y%m%d')
        and yyyymmdd <= date_format({{enddate}}, '%Y%m%d')
        and client_parentName in('Swiggy','Zomato')
        and client_otherdata_city In (select city_id from citys)
        )
        where
        GP_Serviceable = 'false'
        )
        , two as(
        select *
        from Pings_Hex left join GP_Serviceable on Pings_Hex.id = GP_Serviceable._id
        left join citys on Pings_Hex.client_other_data_city = citys.city_id
        where GP_Serviceable = 'false'
        )
        , three as (
        select id,yyyymmdd, epoch, quarter_hour, pick_cluster,client_other_data_city,requested_ds,pickup_location_latitude,pickup_location_longitude,
        client_parent_name,client_order_id,pickup_location_hex_8,window_name,weekday_name,
        composite_hex_id,city_name, source_hex5 as source_hex3, time_of_day , day_of_week , refresh_date,hex_id,cluster,city
        from two inner join one
        on lower(two.cityname) = one.city_name and
        two.pick_cluster = one.cluster and
        two.window_name = one.time_of_day and
        two.weekday_name = one.day_of_week and
        two.pickup_location_hex_8 = one.source_hex5
        )
        , Accepted_Link as (
        select
        *,from_unixtime(round(cast(Accepted_epoch as double) / 1000) + 19800) Accepted_ds ,
        (case when substr(updated_quarter_hour, 1, 2) >= '08' and substr(updated_quarter_hour,1,2) <= '11' then 'morning_peak' else
        case when substr(updated_quarter_hour, 1, 2) >= '17' and substr(updated_quarter_hour,1,2) <= '21' then 'evening_peak' else
        case when substr(updated_quarter_hour, 1, 2) > '11' and substr(updated_quarter_hour,1,2) < '17' then 'afternoon' else
        case when substr(updated_quarter_hour, 1, 2) >= '00' and substr(updated_quarter_hour,1,2) < '08' then 'rest_morning' else
        'rest_evening'
        end
        end
        end
        end) as window_name,
        date_format(date_parse(DateYYYMMDD,'%Y%m%d'), '%W') as weekday_name
        from
        (
        Select
        distinct order_id, city_name as city1,updated_quarter_hour, yyyymmdd as DateYYYMMDD,pickup_location_hex_8,pickup_cluster, max(updated_epoch) as Accepted_epoch
        from
        Orders
        where
        service_obj_service_name ='Link'
        and (spd_fraud_flag = false OR spd_fraud_flag IS NULL)
        and event_type = 'accepted'
        group by 1,2,3,4,5,6
        )
        ),
        five as (
        select
        order_id, city1,updated_quarter_hour, DateYYYMMDD,pickup_location_hex_8 as Pickhex5,pickup_cluster,window_name as window_name5,weekday_name as weekday_name5 ,Accepted_epoch,Accepted_ds,
        composite_hex_id as composite_hex_id5 ,source_hex5 , time_of_day , day_of_week , refresh_date,hex_id,cluster,city
        from Accepted_Link left join one
        on lower(Accepted_Link.city1) = one.city and
        Accepted_Link.pickup_location_hex_8 = one.source_hex5 and
        Accepted_Link.pickup_cluster = one.cluster and
        Accepted_Link.weekday_name = one.day_of_week and
        Accepted_Link.window_name = one.time_of_day
        where composite_hex_id != ''
        )
        ,six as (
        select city1 as City, "Date",pickup_cluster as PickUpCluster, count(distinct order_id) as Link_orders_Accepted_in_next5min ,
        count(distinct id) as B2B_pings_refused
        from
        (
        select *,date_format(date_parse(DateYYYMMDD, '%Y%m%d'), '%Y-%m-%d') as "Date", (Accepted_epoch - epoch)/60000 as time_diff
        from
        (
        select distinct
        id,yyyymmdd, epoch, quarter_hour, pick_cluster,client_other_data_city,requested_ds,pickup_location_latitude,pickup_location_longitude,
        client_parent_name,client_order_id,pickup_location_hex_8,window_name,weekday_name,
        composite_hex_id,city_name, source_hex3 ,
        order_id, city1,updated_quarter_hour, DateYYYMMDD,Pickhex5,pickup_cluster,window_name5,weekday_name5,Accepted_epoch,Accepted_ds,
        composite_hex_id5, source_hex5
        from three left join five on
        three.city_name = lower(five.city1) and
        three.yyyymmdd = five.DateYYYMMDD and
        three.composite_hex_id = five.composite_hex_id5 and
        three.window_name = five.time_of_day and
        three.pick_cluster = five.pickup_cluster
        )
        )
        where time_diff <= 5
        group by 1,2,3
        )
        , Link_GN as
        (
        select
        geo_city as cityL,geo_value as cluster, substr(time_value,1,10) as DateL,
        round((dropped_orders - fraud_orders)/cast(gross_orders_requests as real),2) as "G2N Req"
        from
        datasets.marketplace_kpi_servicelevel
        where
        date_parse(substr(time_value,1,10),'%Y-%m-%d') >= {{startdate}}
        and date_parse(substr(time_value,1,10),'%Y-%m-%d') <= {{enddate}}
        and order_type = 'app'
        and geo_city IN (select cityname from citys)
        and time_level = 'daily'
        and geo_value != ''
        and geo_level ='cluster'
        )
        ,Link_orders_added as (
        select *, ROUND("G2N Req" * Link_orders_Accepted_in_next5min) as Link_Net_orders_added
        from
        (
        select City,"Date" as DateLA,PickUpCluster,Link_orders_Accepted_in_next5min,B2B_pings_refused,cluster,DateL as Date1,"G2N Req"
        from six left join Link_GN on
        six.City = Link_GN.cityL and
        six."Date" = Link_GN.DateL and
        six.PickUpCluster = Link_GN.cluster
        )
        )
        , pings_group as (
        select
        client_other_data_city,date_format(date_parse(yyyymmdd, '%Y%m%d'), '%Y-%m-%d') as "Date", pick_cluster,
        count(distinct(id)) as pings
        from
        Pings_Hex
        group by 1,2,3
        )
        , pings_group_city as (
        select client_other_data_city,"Date", pick_cluster,cityname,pings
        from pings_group left join citys
        on pings_group.client_other_data_city = citys.city_id
        )
        , B2B_Net as (
        select order_date,city_name,pickup_cluster,
        count(distinct order_id) as Gross_Orders,
        count(distinct case when event_type IN ('dropped') then order_id end) as Net_Orders,
        count(distinct captain_id) as Gross_Captains,
        count(distinct case when event_type IN ('dropped') then captain_id end) as Net_Captains
        from
        Orders
        where
        service_obj_service_name IN ('Delivery','Zomato')
        group by
        1, 2,3
        )
        , B2B_P_N As (
        select *, (Net_Orders / cast(pings as double))  as "B2B_P-N%"
        from
        (
        select "Date", pick_cluster,cityname,pings,Gross_Orders,Net_Orders
        from pings_group_city left join B2B_Net
        on pings_group_city.cityname = B2B_Net.city_name and
        pings_group_city."Date" = B2B_Net.order_date and
        pings_group_city.pick_cluster = B2B_Net.pickup_cluster
        )
        )
        select City,Date,PickUpCluster,B2B_pings_refused,Link_orders_Accepted_in_next5min,Link_Net_orders_added,"B2B_P-N%",ROUND("B2B_P-N%" * B2B_pings_refused) as B2B_loss
        from (
        select City,DateLA as Date,PickUpCluster,Link_orders_Accepted_in_next5min,B2B_pings_refused,cluster,"G2N Req",Link_Net_orders_added,pick_cluster,
        cityname,pings,Gross_Orders,Net_Orders,"B2B_P-N%"
        from Link_orders_added inner join B2B_P_N on
        Link_orders_added.City = B2B_P_N.cityname and
        Link_orders_added.DateLA = B2B_P_N."Date" and
        Link_orders_added.PickUpCluster = B2B_P_N.pick_cluster
        )

      args:
        - var_name: startdate
          var_type: DATE
          expression: "current_date()-timedelta(days=31)"
        - var_name: enddate
          var_type: DATE
          expression: "current_date()"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"

    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_gp_b2b_loss_v1"
      partition_columns: [ "Date" ]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_gp_b2b_loss_v1"
      table_schema_name: "reports_internal"
      view_name: "gp_b2b_loss_v1"
      base_path: "metrics/sql_ingest_gp_b2b_loss_v1"
      view_schema_name: "reports"


  - run_config:
      name: LM_FM_DISTANCE_RATIO
      start_date: '2022-05-09T00:00:00'
      schedule_interval: 0 0 * * MON
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-lm-fm-distance-ratio
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 3600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.8
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"

    flow_config:
      sql:
        SELECT * from (
        select time, week_start_date, city_name, order_type, "ratio", 
        count(distinct case when event_type in ('accepted', 'rider_busy', 'rider_reject') then uid_1 end)/
        cast(sum(count(distinct case when event_type in ('accepted', 'rider_busy', 'rider_reject') then uid_1 end)) 
        over (partition by time,city_name,order_type) as real) as "per_pings", 
        sum(case when event_type in ('accepted') then 1 else 0 end)
        /cast(sum(case when event_type in ('accepted', 'rider_busy', 'rider_reject') then 1 else 0 end) as real) as APR,
        sum(case when event_type in ('dropped') then 1 else 0 end)
        /cast(sum(case when event_type in ('accepted') then 1 else 0 end) as real) as DAPR,
        sum(case when event_type in ('dropped') then 1 else 0 end)
        /cast(sum(case when event_type in ('accepted', 'rider_busy', 'rider_reject') then 1 else 0 end) as real) as DPR
        from(
        select  concat('WK ~ ', date_format(date_parse(yyyymmdd,'%Y%m%d'),'%v')) as time,
        date_format(date_trunc('week',date_parse(yyyymmdd, '%Y%m%d')),'%Y%m%d') as week_start_date,
        yyyymmdd, city_name, order_type, order_id, captain_id, event_type, order_status,
        LastMile, fm_distance,
        (case when LastMile/cast(fm_distance as real) >= 0 and LastMile/cast(fm_distance as real) <= 1 then '<=1'
        when LastMile/cast(fm_distance as real) > 1 and LastMile/cast(fm_distance as real) <= 2 then '1-2'
        when LastMile/cast(fm_distance as real) > 2 and LastMile/cast(fm_distance as real) <= 3 then '2-3'
        when LastMile/cast(fm_distance as real) > 3 and LastMile/cast(fm_distance as real) <= 4 then '3-4'
        when LastMile/cast(fm_distance as real) > 4 and LastMile/cast(fm_distance as real) <= 5 then '4-5'
        when LastMile/cast(fm_distance as real) > 5 and LastMile/cast(fm_distance as real) <= 6 then '5-6'
        when LastMile/cast(fm_distance as real) > 6 and LastMile/cast(fm_distance as real) <= 7 then '6-7'
        when LastMile/cast(fm_distance as real) > 7 and LastMile/cast(fm_distance as real) <= 8 then '7-8'
        when LastMile/cast(fm_distance as real) > 8 and LastMile/cast(fm_distance as real) <= 9 then '8-9'
        when LastMile/cast(fm_distance as real) > 9 and LastMile/cast(fm_distance as real) <= 10 then '9-10'
        when LastMile/cast(fm_distance as real) > 10 then '>10' end) as "ratio", uid_1
        from ( 
        select  yyyymmdd, city_name, order_type,
        order_id, captain_id, event_type, order_status, accept_to_pickup_distance as fm, 
        cast(estimated_accept_to_pickup_distance as double)/1000 as fm_distance,
        distance_final_distance as LastMile, updated_epoch,
        cast(order_id as varchar)||'-'||cast(captain_id as varchar)||'-'||cast(yyyymmdd as varchar)||'-'||
        cast(event_type as varchar)||'-'||cast(estimated_accept_to_pickup_distance as varchar) as uid_1
        from 
        orders.order_logs_immutable
        where 
        yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d') 
        and captain_id != ''
        and event_type in ('accepted', 'rider_busy', 'rider_reject','customer_cancelled', 'dropped')
        order by order_id, updated_epoch
        )
        ) where "ratio" is not null
        group by 1,2,3,4,5
        )     
        UNION 
        SELECT * from (
        select time, week_start_date, city_name, order_type, "ratio", 
        count(distinct case when event_type in ('accepted', 'rider_busy', 'rider_reject') then uid_1 end)/
        cast(sum(count(distinct case when event_type in ('accepted', 'rider_busy', 'rider_reject') then uid_1 end)) 
        over (partition by time,city_name,order_type) as real) as "per_pings", 
        sum(case when event_type in ('accepted') then 1 else 0 end)
        /cast(sum(case when event_type in ('accepted', 'rider_busy', 'rider_reject') then 1 else 0 end) as real) as APR,
        sum(case when event_type in ('dropped') then 1 else 0 end)
        /cast(sum(case when event_type in ('accepted') then 1 else 0 end) as real) as DAPR,
        sum(case when event_type in ('dropped') then 1 else 0 end)
        /cast(sum(case when event_type in ('accepted', 'rider_busy', 'rider_reject') then 1 else 0 end) as real) as DPR
        from(
        select  concat('WK ~ ', date_format(date_parse(yyyymmdd,'%Y%m%d'),'%v')) as time,
        date_format(date_trunc('week',date_parse(yyyymmdd, '%Y%m%d')),'%Y%m%d') as week_start_date,
        yyyymmdd, city_name, order_type, order_id, captain_id, event_type, order_status,
        LastMile, fm_distance,
        (case when LastMile/cast(fm_distance as real) >= 0 and LastMile/cast(fm_distance as real) <= 1 then '<=1'
        when LastMile/cast(fm_distance as real) > 1 and LastMile/cast(fm_distance as real) <= 2 then '1-2'
        when LastMile/cast(fm_distance as real) > 2 and LastMile/cast(fm_distance as real) <= 3 then '2-3'
        when LastMile/cast(fm_distance as real) > 3 and LastMile/cast(fm_distance as real) <= 4 then '3-4'
        when LastMile/cast(fm_distance as real) > 4 and LastMile/cast(fm_distance as real) <= 5 then '4-5'
        when LastMile/cast(fm_distance as real) > 5 and LastMile/cast(fm_distance as real) <= 6 then '5-6'
        when LastMile/cast(fm_distance as real) > 6 and LastMile/cast(fm_distance as real) <= 7 then '6-7'
        when LastMile/cast(fm_distance as real) > 7 and LastMile/cast(fm_distance as real) <= 8 then '7-8'
        when LastMile/cast(fm_distance as real) > 8 and LastMile/cast(fm_distance as real) <= 9 then '8-9'
        when LastMile/cast(fm_distance as real) > 9 and LastMile/cast(fm_distance as real) <= 10 then '9-10'
        when LastMile/cast(fm_distance as real) > 10 then '>10' end) as "ratio", uid_1
        from ( 
        select  yyyymmdd, 'pan-india' as city_name, order_type,
        order_id, captain_id, event_type, order_status, accept_to_pickup_distance as fm, 
        cast(estimated_accept_to_pickup_distance as double)/1000 as fm_distance,
        distance_final_distance as LastMile, updated_epoch,
        cast(order_id as varchar)||'-'||cast(captain_id as varchar)||'-'||cast(yyyymmdd as varchar)||'-'||
        cast(event_type as varchar)||'-'||cast(estimated_accept_to_pickup_distance as varchar) as uid_1
        from 
        orders.order_logs_immutable
        where 
        yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        and captain_id != ''
        and event_type in ('accepted', 'rider_busy', 'rider_reject','customer_cancelled', 'dropped')
        order by order_id, updated_epoch
        )
        ) where "ratio" is not null
        group by 1,2,3,4,5
        )order by week_start_date, (case when city_name in ('pan-india') then '1.pan-india' else city_name end),
        (case when "ratio" = '<=1' then 1
        when "ratio" = '1-2' then 2
        when "ratio" = '2-3' then 3
        when "ratio" = '3-4' then 4
        when "ratio" = '4-5' then 5
        when "ratio" = '5-6' then 6
        when "ratio" = '6-7' then 7
        when "ratio" = '7-8' then 8
        when "ratio" = '8-9' then 9
        when "ratio" = '9-10' then 10 
        when "ratio" = '>10' then 11 end)


      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()"
        - var_name: end_date
          var_type: DATE
          expression: "next_execution_date()-timedelta(days=1)"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_lm_fm_distance_ratio"
      partition_columns: ["week_start_date","city_name","order_type"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_lm_fm_distance_ratio"
      table_schema_name: "reports_internal"
      view_name: "ride_lm_fm_distance_ratio"
      base_path: "metrics/sql_ingest_lm_fm_distance_ratio"
      view_schema_name: "reports"


  - run_config:
      name: LM_DISTANCE_BUCKET_RATIO_V0
      start_date: '2022-05-09T00:00:00'
      schedule_interval: 0 0 * * MON
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-lm-distance-bucket-ratio-v0
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 4
        ttl: 7200
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.8
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"

    flow_config:
      sql:
        SELECT * from (
        select 
        city_name, Week, week_startdate, order_type, Ride_Distance, Avg_Ride_Distance, Gross_Order_Requests, Gross_Orders_Mapped, 
        sum(per_Contribution_of_GrossReq) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_GrossReq,
        sum(per_Contribution_of_GrossMapped) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_GrossMapped,
        sum(per_Contribution_of_Dropped) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_Dropped,
        sum(per_Contribution_of_OCARA_CC) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_OCARA,
        per_G2N_Req, per_G2N_Mapped, per_OCARA_CC_per_GrossReq, per_OCARA_CC_per_GrossMapped, per_OCARA_CC_per_Dropped, APR, DPR
        from 
        (select 
        city_name, Week, week_startdate, order_type, Ride_Distance, Avg_Ride_Distance, Gross_Order_Requests, Gross_Orders_Mapped, 
        Gross_Order_Requests/cast(sum(Gross_Order_Requests) over (partition by city_name, Week) as double) as per_Contribution_of_GrossReq,
        Gross_Orders_Mapped/cast(sum(Gross_Orders_Mapped) over (partition by city_name, Week) as double) as per_Contribution_of_GrossMapped,
        Dropped_Orders/cast(sum(Dropped_Orders) over (partition by city_name, Week) as double) as per_Contribution_of_Dropped,
        OCARA_Orders/cast(sum(OCARA_Orders) over (partition by city_name, Week) as double) as per_Contribution_of_OCARA_CC,
        OCARA_Orders/cast(Dropped_Orders as double) as per_OCARA_CC_per_Dropped, 
        Dropped_Orders/cast(Gross_Orders_Mapped as double) as per_G2N_Mapped,
        Dropped_Orders/cast(Gross_Order_Requests as double) as per_G2N_Req,
        OCARA_Orders/cast(Gross_Order_Requests as double) as per_OCARA_CC_per_GrossReq,
        OCARA_Orders/cast(Gross_Orders_Mapped as double) as per_OCARA_CC_per_GrossMapped, APR, DPR
        from 
        (select 
        city_name, order_type, 
        weekofyear(date_parse(order_date, '%Y-%m-%d')) as Week, date_format(date_trunc('week', date_parse(order_date, '%Y-%m-%d')), '%Y%m%d') as week_startdate,
        (CASE WHEN (distance_final_distance < 0 or cast(distance_final_distance as varchar) = '' or distance_final_distance is null) THEN '< 0 KM'
        WHEN distance_final_distance >= 0 AND distance_final_distance <= 1 THEN '0 to 1 KM'
        WHEN distance_final_distance > 1 AND distance_final_distance <= 2 THEN '1 to 2 KM'
        WHEN distance_final_distance > 2 AND distance_final_distance <= 3 THEN '2 to 3 KM'
        WHEN distance_final_distance > 3 AND distance_final_distance <= 4 THEN '3 to 4 KM'
        WHEN distance_final_distance > 4 AND distance_final_distance <= 5 THEN '4 to 5 KM'
        WHEN distance_final_distance > 5 AND distance_final_distance <= 6 THEN '5 to 6 KM'
        WHEN distance_final_distance > 6 AND distance_final_distance <= 7 THEN '6 to 7 KM'
        WHEN distance_final_distance > 7 AND distance_final_distance <= 8 THEN '7 to 8 KM'
        WHEN distance_final_distance > 8 AND distance_final_distance <= 9 THEN '8 to 9 KM'
        WHEN distance_final_distance > 9 AND distance_final_distance <= 10 THEN '9 to 10 KM'
        WHEN distance_final_distance > 10 THEN 'Above 10 KM' END) as Ride_Distance,
        avg(distance_final_distance) as Avg_Ride_Distance,
        count(distinct order_id) as Gross_Order_Requests,
        count(distinct case when length(map_riders) >= 28  and Rank_1 = 1 then order_id end) as Gross_Orders_Mapped,
        count(distinct case when order_status in ('customerCancelled') and Rank_1 = 1
        and cancel_reason not in ('order cancelled before rider accepted', 'Order cancelled before rider was mapped', '') then order_id end) as OCARA_Orders,
        count(distinct case when order_status in ('dropped') and spd_fraud_flag != True then order_id end) as Dropped_Orders,
        sum(case when event_type in ('accepted') then 1 else 0 end)
        /cast((sum(case when event_type in ('accepted') then 1 else 0 end)
        + sum(case when event_type in ('rider_busy') then 1 else 0 end)
        + sum(case when event_type in ('rider_reject') then 1 else 0 end)) as double) as APR,
        count(distinct(case when event_type = 'dropped' and spd_fraud_flag != True then order_id end))
        /cast((sum(case when event_type in ('accepted') then 1 else 0 end)
        + sum(case when event_type in ('rider_busy') then 1 else 0 end)
        + sum(case when event_type in ('rider_reject') then 1 else 0 end)) as double) as DPR
        from (         
        select *,
        row_number() over (partition by order_id order by updated_epoch desc) as Rank_1
        from
        orders.order_logs_immutable
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        and cast(distance_final_distance as varchar) != ''
        )
        group by 1,2,3,4,5
        )))
        UNION 
        SELECT * from (
        select 
        city_name, Week, week_startdate, order_type, Ride_Distance, Avg_Ride_Distance, Gross_Order_Requests, Gross_Orders_Mapped, 
        sum(per_Contribution_of_GrossReq) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_GrossReq,
        sum(per_Contribution_of_GrossMapped) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_GrossMapped,
        sum(per_Contribution_of_Dropped) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_Dropped,
        sum(per_Contribution_of_OCARA_CC) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_OCARA,
        per_G2N_Req, per_G2N_Mapped, per_OCARA_CC_per_GrossReq, per_OCARA_CC_per_GrossMapped, per_OCARA_CC_per_Dropped, APR, DPR
        from 
        (select 
        city_name, Week, week_startdate, order_type, Ride_Distance, Avg_Ride_Distance, Gross_Order_Requests, Gross_Orders_Mapped,
        Gross_Order_Requests/cast(sum(Gross_Order_Requests) over (partition by city_name, Week) as double) as per_Contribution_of_GrossReq,
        Gross_Orders_Mapped/cast(sum(Gross_Orders_Mapped) over (partition by city_name, Week) as double) as per_Contribution_of_GrossMapped,
        Dropped_Orders/cast(sum(Dropped_Orders) over (partition by city_name, Week) as double) as per_Contribution_of_Dropped,
        OCARA_Orders/cast(sum(OCARA_Orders) over (partition by city_name, Week) as double) as per_Contribution_of_OCARA_CC,
        OCARA_Orders/cast(Dropped_Orders as double) as per_OCARA_CC_per_Dropped, 
        Dropped_Orders/cast(Gross_Orders_Mapped as double) as per_G2N_Mapped,
        Dropped_Orders/cast(Gross_Order_Requests as double) as per_G2N_Req,
        OCARA_Orders/cast(Gross_Order_Requests as double) as per_OCARA_CC_per_GrossReq,
        OCARA_Orders/cast(Gross_Orders_Mapped as double) as per_OCARA_CC_per_GrossMapped, APR, DPR
        from 
        (select 
        city_name, 'overall_bike_taxi' as order_type, 
        weekofyear(date_parse(order_date, '%Y-%m-%d')) as Week, date_format(date_trunc('week', date_parse(order_date, '%Y-%m-%d')), '%Y%m%d') as week_startdate,
        (CASE WHEN (distance_final_distance < 0 or cast(distance_final_distance as varchar) = '' or distance_final_distance is null) THEN '< 0 KM'
        WHEN distance_final_distance >= 0 AND distance_final_distance <= 1 THEN '0 to 1 KM'
        WHEN distance_final_distance > 1 AND distance_final_distance <= 2 THEN '1 to 2 KM'
        WHEN distance_final_distance > 2 AND distance_final_distance <= 3 THEN '2 to 3 KM'
        WHEN distance_final_distance > 3 AND distance_final_distance <= 4 THEN '3 to 4 KM'
        WHEN distance_final_distance > 4 AND distance_final_distance <= 5 THEN '4 to 5 KM'
        WHEN distance_final_distance > 5 AND distance_final_distance <= 6 THEN '5 to 6 KM'
        WHEN distance_final_distance > 6 AND distance_final_distance <= 7 THEN '6 to 7 KM'
        WHEN distance_final_distance > 7 AND distance_final_distance <= 8 THEN '7 to 8 KM'
        WHEN distance_final_distance > 8 AND distance_final_distance <= 9 THEN '8 to 9 KM'
        WHEN distance_final_distance > 9 AND distance_final_distance <= 10 THEN '9 to 10 KM'
        WHEN distance_final_distance > 10 THEN 'Above 10 KM' END) as Ride_Distance,
        avg(distance_final_distance) as Avg_Ride_Distance,
        count(distinct order_id) as Gross_Order_Requests,
        count(distinct case when length(map_riders) >= 28  and Rank_1 = 1 then order_id end) as Gross_Orders_Mapped,
        count(distinct case when order_status in ('customerCancelled') and Rank_1 = 1
        and cancel_reason not in ('order cancelled before rider accepted', 'Order cancelled before rider was mapped', '') then order_id end) as OCARA_Orders,
        count(distinct case when order_status in ('dropped') and spd_fraud_flag != True then order_id end) as Dropped_Orders,
        sum(case when event_type in ('accepted') then 1 else 0 end)
        /cast((sum(case when event_type in ('accepted') then 1 else 0 end)
        + sum(case when event_type in ('rider_busy') then 1 else 0 end)
        + sum(case when event_type in ('rider_reject') then 1 else 0 end)) as double) as APR,
        count(distinct(case when event_type = 'dropped' and spd_fraud_flag != True then order_id end))
        /cast((sum(case when event_type in ('accepted') then 1 else 0 end)
        + sum(case when event_type in ('rider_busy') then 1 else 0 end)
        + sum(case when event_type in ('rider_reject') then 1 else 0 end)) as double) as DPR
        from (         
        select *,
        row_number() over (partition by order_id order by updated_epoch desc) as Rank_1
        from
        orders.order_logs_immutable
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        and order_type not in ('auto')
        and cast(distance_final_distance as varchar) != ''
        )
        group by 1,2,3,4,5
        )))
        UNION 
        SELECT * from (
        select 
        city_name, Week, week_startdate, order_type, Ride_Distance, Avg_Ride_Distance, Gross_Order_Requests, Gross_Orders_Mapped, 
        sum(per_Contribution_of_GrossReq) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_GrossReq,
        sum(per_Contribution_of_GrossMapped) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_GrossMapped,
        sum(per_Contribution_of_Dropped) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_Dropped,
        sum(per_Contribution_of_OCARA_CC) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_OCARA,
        per_G2N_Req, per_G2N_Mapped, per_OCARA_CC_per_GrossReq, per_OCARA_CC_per_GrossMapped, per_OCARA_CC_per_Dropped, APR, DPR
        from 
        (select 
        city_name, Week, week_startdate, order_type, Ride_Distance, Avg_Ride_Distance, Gross_Order_Requests, Gross_Orders_Mapped,
        Gross_Order_Requests/cast(sum(Gross_Order_Requests) over (partition by city_name, Week) as double) as per_Contribution_of_GrossReq,
        Gross_Orders_Mapped/cast(sum(Gross_Orders_Mapped) over (partition by city_name, Week) as double) as per_Contribution_of_GrossMapped,
        Dropped_Orders/cast(sum(Dropped_Orders) over (partition by city_name, Week) as double) as per_Contribution_of_Dropped,
        OCARA_Orders/cast(sum(OCARA_Orders) over (partition by city_name, Week) as double) as per_Contribution_of_OCARA_CC,
        OCARA_Orders/cast(Dropped_Orders as double) as per_OCARA_CC_per_Dropped, 
        Dropped_Orders/cast(Gross_Orders_Mapped as double) as per_G2N_Mapped,
        Dropped_Orders/cast(Gross_Order_Requests as double) as per_G2N_Req,
        OCARA_Orders/cast(Gross_Order_Requests as double) as per_OCARA_CC_per_GrossReq,
        OCARA_Orders/cast(Gross_Orders_Mapped as double) as per_OCARA_CC_per_GrossMapped, APR, DPR
        from 
        (select 
        'pan_india' as city_name, order_type, 
        weekofyear(date_parse(order_date, '%Y-%m-%d')) as Week, date_format(date_trunc('week', date_parse(order_date, '%Y-%m-%d')), '%Y%m%d') as week_startdate,
        (CASE WHEN (distance_final_distance < 0 or cast(distance_final_distance as varchar) = '' or distance_final_distance is null) THEN '< 0 KM'
        WHEN distance_final_distance >= 0 AND distance_final_distance <= 1 THEN '0 to 1 KM'
        WHEN distance_final_distance > 1 AND distance_final_distance <= 2 THEN '1 to 2 KM'
        WHEN distance_final_distance > 2 AND distance_final_distance <= 3 THEN '2 to 3 KM'
        WHEN distance_final_distance > 3 AND distance_final_distance <= 4 THEN '3 to 4 KM'
        WHEN distance_final_distance > 4 AND distance_final_distance <= 5 THEN '4 to 5 KM'
        WHEN distance_final_distance > 5 AND distance_final_distance <= 6 THEN '5 to 6 KM'
        WHEN distance_final_distance > 6 AND distance_final_distance <= 7 THEN '6 to 7 KM'
        WHEN distance_final_distance > 7 AND distance_final_distance <= 8 THEN '7 to 8 KM'
        WHEN distance_final_distance > 8 AND distance_final_distance <= 9 THEN '8 to 9 KM'
        WHEN distance_final_distance > 9 AND distance_final_distance <= 10 THEN '9 to 10 KM'
        WHEN distance_final_distance > 10 THEN 'Above 10 KM' END) as Ride_Distance,
        avg(distance_final_distance) as Avg_Ride_Distance,
        count(distinct order_id) as Gross_Order_Requests,
        count(distinct case when length(map_riders) >= 28  and Rank_1 = 1 then order_id end) as Gross_Orders_Mapped,
        count(distinct case when order_status in ('customerCancelled') and Rank_1 = 1
        and cancel_reason not in ('order cancelled before rider accepted', 'Order cancelled before rider was mapped', '') then order_id end) as OCARA_Orders,
        count(distinct case when order_status in ('dropped') and spd_fraud_flag != True then order_id end) as Dropped_Orders,
        sum(case when event_type in ('accepted') then 1 else 0 end)
        /cast((sum(case when event_type in ('accepted') then 1 else 0 end)
        + sum(case when event_type in ('rider_busy') then 1 else 0 end)
        + sum(case when event_type in ('rider_reject') then 1 else 0 end)) as double) as APR, 
        count(distinct(case when event_type = 'dropped' and spd_fraud_flag != True then order_id end))
        /cast((sum(case when event_type in ('accepted') then 1 else 0 end)
        + sum(case when event_type in ('rider_busy') then 1 else 0 end)
        + sum(case when event_type in ('rider_reject') then 1 else 0 end)) as double) as DPR
        from (         
        select *,
        row_number() over (partition by order_id order by updated_epoch desc) as Rank_1
        from
        orders.order_logs_immutable
        where   yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        and cast(distance_final_distance as varchar) != ''
        )
        group by 1,2,3,4,5
        )))
        UNION 
        SELECT * from (
        select 
        city_name, Week, week_startdate, order_type, Ride_Distance, Avg_Ride_Distance, Gross_Order_Requests, Gross_Orders_Mapped, 
        sum(per_Contribution_of_GrossReq) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_GrossReq,
        sum(per_Contribution_of_GrossMapped) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_GrossMapped,
        sum(per_Contribution_of_Dropped) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_Dropped,
        sum(per_Contribution_of_OCARA_CC) over (partition by city_name, Week order by Avg_Ride_Distance) as Cumulative_percent_of_OCARA,
        per_G2N_Req, per_G2N_Mapped, per_OCARA_CC_per_GrossReq, per_OCARA_CC_per_GrossMapped, per_OCARA_CC_per_Dropped, APR, DPR
        from 
        (select 
        city_name, Week, week_startdate, order_type, Ride_Distance, Avg_Ride_Distance, Gross_Order_Requests, Gross_Orders_Mapped, 
        Gross_Order_Requests/cast(sum(Gross_Order_Requests) over (partition by city_name, Week) as double) as per_Contribution_of_GrossReq,
        Gross_Orders_Mapped/cast(sum(Gross_Orders_Mapped) over (partition by city_name, Week) as double) as per_Contribution_of_GrossMapped,
        Dropped_Orders/cast(sum(Dropped_Orders) over (partition by city_name, Week) as double) as per_Contribution_of_Dropped,
        OCARA_Orders/cast(sum(OCARA_Orders) over (partition by city_name, Week) as double) as per_Contribution_of_OCARA_CC,
        OCARA_Orders/cast(Dropped_Orders as double) as per_OCARA_CC_per_Dropped, 
        Dropped_Orders/cast(Gross_Orders_Mapped as double) as per_G2N_Mapped,
        Dropped_Orders/cast(Gross_Order_Requests as double) as per_G2N_Req,
        OCARA_Orders/cast(Gross_Order_Requests as double) as per_OCARA_CC_per_GrossReq,
        OCARA_Orders/cast(Gross_Orders_Mapped as double) as per_OCARA_CC_per_GrossMapped, APR, DPR
        from 
        (select 
        'pan_india' as city_name, 'overall_bike_taxi' as order_type, 
        weekofyear(date_parse(order_date, '%Y-%m-%d')) as Week, date_format(date_trunc('week', date_parse(order_date, '%Y-%m-%d')), '%Y%m%d') as week_startdate,
        (CASE WHEN (distance_final_distance < 0 or cast(distance_final_distance as varchar) = '' or distance_final_distance is null) THEN '< 0 KM'
        WHEN distance_final_distance >= 0 AND distance_final_distance <= 1 THEN '0 to 1 KM'
        WHEN distance_final_distance > 1 AND distance_final_distance <= 2 THEN '1 to 2 KM'
        WHEN distance_final_distance > 2 AND distance_final_distance <= 3 THEN '2 to 3 KM'
        WHEN distance_final_distance > 3 AND distance_final_distance <= 4 THEN '3 to 4 KM'
        WHEN distance_final_distance > 4 AND distance_final_distance <= 5 THEN '4 to 5 KM'
        WHEN distance_final_distance > 5 AND distance_final_distance <= 6 THEN '5 to 6 KM'
        WHEN distance_final_distance > 6 AND distance_final_distance <= 7 THEN '6 to 7 KM'
        WHEN distance_final_distance > 7 AND distance_final_distance <= 8 THEN '7 to 8 KM'
        WHEN distance_final_distance > 8 AND distance_final_distance <= 9 THEN '8 to 9 KM'
        WHEN distance_final_distance > 9 AND distance_final_distance <= 10 THEN '9 to 10 KM'
        WHEN distance_final_distance > 10 THEN 'Above 10 KM' END) as Ride_Distance,
        avg(distance_final_distance) as Avg_Ride_Distance,
        count(distinct order_id) as Gross_Order_Requests, 
        count(distinct case when length(map_riders) >= 28  and Rank_1 = 1 then order_id end) as Gross_Orders_Mapped,         
        count(distinct case when order_status in ('customerCancelled') and Rank_1 = 1
        and cancel_reason not in ('order cancelled before rider accepted', 'Order cancelled before rider was mapped', '') then order_id end) as OCARA_Orders,        
        count(distinct case when order_status in ('dropped') and spd_fraud_flag != True then order_id end) as Dropped_Orders,     
        sum(case when event_type in ('accepted') then 1 else 0 end)
        /cast((sum(case when event_type in ('accepted') then 1 else 0 end)
        + sum(case when event_type in ('rider_busy') then 1 else 0 end)
        + sum(case when event_type in ('rider_reject') then 1 else 0 end)) as double) as APR,
        count(distinct(case when event_type = 'dropped' and spd_fraud_flag != True then order_id end))
        /cast((sum(case when event_type in ('accepted') then 1 else 0 end)
        + sum(case when event_type in ('rider_busy') then 1 else 0 end)
        + sum(case when event_type in ('rider_reject') then 1 else 0 end)) as double) as DPR
        from (         
        select *,
        row_number() over (partition by order_id order by updated_epoch desc) as Rank_1
        from
        orders.order_logs_immutable
        where   yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        and order_type not in ('auto')
        and cast(distance_final_distance as varchar) != ''
        )
        group by 1,2,3,4,5
        )))
        order by (case when order_type in ('overall_bike_taxi') then '1.overall_bike_taxi' else order_type end),
        (case when city_name in ('pan_india') then '1.Pan-India' else city_name end),3,5

      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()"
        - var_name: end_date
          var_type: DATE
          expression: "next_execution_date()-timedelta(days=1)"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_lm_distance_bucket_ratio_v1"
      partition_columns: ["week_startdate","city_name","order_type"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_lm_distance_bucket_ratio_v1"
      table_schema_name: "reports_internal"
      view_name: "lm_distance_bucket_ratio"
      base_path: "metrics/sql_ingest_lm_distance_bucket_ratio_v1"
      view_schema_name: "reports"

  - run_config:
      name: CHAT_LOGS_TRANSCRIPTS_V0
      start_date: '2022-07-11T01:00:00'
      schedule_interval: 0/30 * * * *
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-chat-logs-transcripts
        master_machine_type: "e2-highmem-16"
        worker_machine_type: "e2-highmem-16"
        worker_count: 8
        ttl: 3600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.8
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"
          "spark:spark.driver.memoryOverhead": "2g"
          "spark:spark.executor.memoryOverhead": "2g"
          "spark:spark.driver.memory": "64g"

    flow_config:
      sql:
        select yyyymmdd, orderid as order_id, epoch, from_unixtime(epoch/1000) as epoch_time, state_1, respective_id as id_captain_customer, messages_1 as msg_id,
        text_1_1 as text_msg, userType_1 as user_type, chat
        from (
        select yyyymmdd, orderid, from_unixtime(epoch/1000) as epoch_time, epoch, state_1, (case when userType_1 = 'Captain' then captainId_1
        when userType_1 = 'Customer' then customerId_1 end) as respective_id, messages_1, text_1_1, userType_1, concat(userType_1,'-', text_1_1) as chat
        from ( 
        select DISTINCT  yyyymmdd, orderid, epoch,
        regexp_extract_all(snapshot, '(?<=customerId":").*?(?=",)')  as customerId,
        regexp_extract_all(snapshot, '(?<=captainId":").*?(?=",)')  as captainId,
        regexp_extract_all(snapshot, '(?<=text":").*?(?=",)')  as text_1,
        regexp_extract_all(snapshot, '(?<=userType":").*?(?=")')  as userType,
        regexp_extract_all(snapshot, '(?<="-).*?(?=")')  as messages,
        regexp_extract_all(snapshot, '(?="state":).*?(?=,")')  as state 
        from 
        raw.firebase_chat_logs_immutable
        where yyyymmdd >= date_format(date({{start_date}}), '%Y%m%d') and yyyymmdd <= date_format(date({{end_date}}), '%Y%m%d')
        ) cross join unnest (customerId,captainId,text_1,userType,messages,state) as t(customerId_1,captainId_1,text_1_1,userType_1,messages_1,state_1)
        ) where respective_id is not null and state_1 = '"state":1'
        group by 1,2,3,4,5,6,7,8,9,10
        order by order_id, epoch_time


      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()"
        - var_name: end_date
          var_type: DATE
          expression: "current_date()"


    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_chat_logs_transcripts_v0"
      partition_columns: ["yyyymmdd"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_chat_logs_transcripts_v0"
      table_schema_name: "reports_internal"
      view_name: "ride_chat_logs_transcripts"
      base_path: "metrics/sql_ingest_chat_logs_transcripts_v0"
      view_schema_name: "reports"

  - run_config:
      name: 'CAPTAIN_LEVEL_AUTO_B2B'
      start_date: '2022-06-14T18:30:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-captain-level-auto-b2b
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"


    flow_config:
      sql:
        with caps_main_dump as
        (
        select
        logs_1.*, csv.mobilenumber as captain_mobile, csv.shift
        from
        (
        select
        yyyymmdd, order_id, order_status, event_type, updated_epoch, ride_distance, ride_time, spd_fraud_flag,
        accept_to_pickup_distance, distance_final_distance, captain_id, service_obj_city_display_name as city_name
        from
        orders.order_logs_immutable
        where
        yyyymmdd >= date_format({{start_date}},'%Y%m%d')
        and yyyymmdd <= date_format({{end_date}},'%Y%m%d')
        and service_obj_service_name IN ('Delivery', 'Zomato')
        ) as logs_1
        join
        (select distinct captainid, shift, mobilenumber
        from datasets.captain_single_view
        where lower(shift) like '%auto%' and length(mobilenumber) > 0) csv
        on logs_1.captain_id = csv.captainid
        )

        ,event_tab as
        (
        select
        yyyymmdd, city_name, captain_id, captain_mobile, shift,
        count(distinct case when event_type IN ('rider_busy','rider_reject','accepted') then order_id end) as gross_orders,
        count(case when event_type IN ('rider_busy','rider_reject','accepted') then order_id end) as total_pings,
        count(case when event_type IN ('accepted') then order_id end) as accepted_pings,
        count(distinct case when event_type IN ('accepted') then order_id end) as accepted_orders,
        count(case when event_type IN ('rider_busy') then order_id end) as rider_busy_pings,
        count(distinct case when event_type IN ('rider_busy') then order_id end) as rider_busy_orders,
        count(case when event_type IN ('rider_reject') then order_id end) as rider_reject_pings,
        count(distinct case when event_type = 'rider_reject' then order_id end) as rejected_orders,
        count(distinct case when event_type IN ('switch_rider') then order_id end) as rider_switch_orders,
        count(distinct case when event_type = 'dropped' then order_id end) as net_orders,
        count(distinct case when event_type = 'aborted' then order_id end) as aborted_orders,
        count(distinct case when event_type = 'customer_cancelled' then order_id end) as cc_orders
        from
        caps_main_dump
        where
        event_type IN ('rider_busy','rider_reject','accepted','switch_rider','dropped','aborted','customer_cancelled')
        group by
        1, 2, 3, 4, 5
        )

        ,gross_day_tab as
        (
        select
        yyyymmdd, city_name, captain_id, shift,
        count(distinct order_id) as gross_orders_day
        from
        (
        select
        *,
        row_number() over(partition by order_id order by updated_epoch) as row_captain
        from
        caps_main_dump
        where
        event_type IN ('rider_busy','rider_reject','accepted')
        )
        where
        row_captain = 1
        group by
        1, 2, 3, 4
        )

        ,fm_lm_tab as
        (
        select
        yyyymmdd, city_name, captain_id, shift,
        sum(accept_to_pickup_distance) as sum_fm_kms,
        sum(distance_final_distance) as sum_lm_kms
        from
        (
        select
        distinct yyyymmdd, city_name, captain_id, shift,
        order_id, accept_to_pickup_distance, distance_final_distance
        from
        caps_main_dump
        where
        event_type = 'dropped'
        )
        group by
        1, 2, 3, 4
        )

        ,svo_tab as
        (
        select
        yyyymmdd, city, lh_tab.captainid, csv_a.shift,
        total_login_hr, idle_hours
        from
        (
        select
        yyyymmdd, city, captainid,
        sum(total_login_hr) as total_login_hr,
        sum(idle_hours) as idle_hours
        from
        (
        select
        distinct yyyymmdd, city, captainid, total_login_hr, idle_hours
        from
        datasets.captain_svo_daily_kpi
        where
        yyyymmdd >= date_format({{start_date}},'%Y%m%d')
        and yyyymmdd <= date_format({{end_date}},'%Y%m%d')
        and service_name IN ('Delivery','Zomato')
        )
        group by
        1, 2, 3
        ) as lh_tab
        join
        (select distinct captainid, shift, mobilenumber
        from datasets.captain_single_view
        where lower(shift) like '%auto%' and length(mobilenumber) > 0) csv_a
        on lh_tab.captainid = csv_a.captainid
        )

        ,cap_trns as
        (
        select
        pre_trns.*, csv_b.shift
        from
        (
        select
        order_date, city, payment_date, rider_id, CAST(amount AS DOUBLE) AS amount, service, yyyymmdd, CAST(captain_earnings AS DOUBLE) as captain_earnings,
        incentive_details_order_count, incentive_details_service, transaction_type, transaction_category, hh
        from
        captain.captain_transactions
        where
        yyyymmdd >= date_format({{start_date}},'%Y%m%d')
        and yyyymmdd <= date_format({{end_date}} + interval '15' day,'%Y%m%d')
        and status = 'success'
        ) pre_trns
        join
        (select distinct captainid, shift, mobilenumber
        from datasets.captain_single_view
        where lower(shift) like '%auto%' and length(mobilenumber) > 0) csv_b
        on pre_trns.rider_id = csv_b.captainid
        )

        ,order_earns as
        (
        select
        date_format(date_parse(order_date,'%Y-%m-%d'), '%Y%m%d') as yyyymmdd, city, rider_id, shift,
        sum(case when transaction_type IN ('orders','ordersAdjustment') then captain_earnings end) as orders_1,
        sum(case when transaction_category = 'cancellationIncentive' then amount end) as orders_2,
        sum(case when transaction_type IN ('ExtraKmFare','ExtraKmFareAdjustment','adjustment','pickupExtraKmFare') then amount end) as part_incentive
        from
        cap_trns
        where
        service IN ('Delivery','Zomato')
        and order_date >= DATE_FORMAT({{start_date}}, '%Y-%m-%d')
        and order_date <= DATE_FORMAT({{end_date}}, '%Y-%m-%d')
        group by
        1, 2, 3, 4
        )

        ,spl_incents as
        (
        select
        date_format(date_parse(order_date,'%Y-%m-%d'), '%Y%m%d') as yyyymmdd, rider_id, shift,
        sum(SpecialIncentive1) as special_incentive1
        from
        (
        select
        order_date, city, service, rider_id, shift,
        ROUND(SUM(TRY(order_count/total_order * 1.00) * amount)) AS SpecialIncentive1
        from
        (
        select
        order_date, city, payment_date, rider_id, CAST(amount AS DOUBLE) AS amount, hh, shift,
        TRANSFORM(incentive_details_order_count, x -> cast(x as double)) AS service_order_count,
        REDUCE(TRANSFORM(incentive_details_order_count, x -> cast(x as double)),
        CAST(0 AS DOUBLE), (x1, x2) -> x1 + x2, x1 -> x1) AS total_order,
        incentive_details_service AS service_array
        from
        cap_trns
        where
        transaction_category = 'specialIncentive'
        )
        CROSS JOIN UNNEST(service_array, service_order_count) AS tbl1 (service, order_count)
        where
        order_date >= DATE_FORMAT({{start_date}}, '%Y-%m-%d')
        AND order_date <= DATE_FORMAT({{end_date}}, '%Y-%m-%d')
        AND Service IN ('Delivery','Zomato')
        GROUP BY
        1, 2, 3, 4, 5
        )
        group by
        1, 2, 3
        )

        select
        event_tab.*, gross_orders_day, sum_fm_kms, sum_lm_kms, total_login_hr, idle_hours,
        round(coalesce(orders_1,0) + coalesce(orders_2,0)) as order_earnings,
        round(coalesce(part_incentive,0) + coalesce(special_incentive1,0)) as incentives
        from
        event_tab left join gross_day_tab
        on event_tab.yyyymmdd = gross_day_tab.yyyymmdd and event_tab.city_name = gross_day_tab.city_name
        and event_tab.captain_id = gross_day_tab.captain_id and event_tab.shift = gross_day_tab.shift

        left join fm_lm_tab
        on event_tab.yyyymmdd = fm_lm_tab.yyyymmdd and event_tab.city_name = fm_lm_tab.city_name
        and event_tab.captain_id = fm_lm_tab.captain_id and event_tab.shift = fm_lm_tab.shift

        left join svo_tab
        on event_tab.yyyymmdd = svo_tab.yyyymmdd and event_tab.city_name = svo_tab.city
        and event_tab.captain_id = svo_tab.captainid and event_tab.shift = svo_tab.shift

        left join order_earns
        on event_tab.yyyymmdd = order_earns.yyyymmdd and event_tab.city_name = order_earns.city
        and event_tab.captain_id = order_earns.rider_id and event_tab.shift = order_earns.shift

        left join spl_incents
        on event_tab.yyyymmdd = spl_incents.yyyymmdd
        and event_tab.captain_id = spl_incents.rider_id and event_tab.shift = spl_incents.shift

        order by
        yyyymmdd, city_name

      args:
        - var_name: start_date
          var_type: DATE
          expression: 'current_date()-timedelta(days = 180)'
        - var_name: end_date
          var_type: DATE
          expression: 'current_date()'


    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"
      trino_db_url: "{{ var.value.get('REPORTS_PRESTO_JDBC_STRING') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_captain_level_auto_b2b"
      partition_columns: [ "yyyymmdd","city_name"]


    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_captain_level_auto_b2b"
      table_schema_name: "reports_internal"
      view_name: "sql_ingest_captain_level_auto_b2b"
      base_path: "metrics/sql_ingest_captain_level_auto_b2b"
      view_schema_name: "reports"

  - run_config:
      name: CAPTAIN_PLAYBOOK_DATA_V0
      start_date: '2022-06-24T00:00:00'
      schedule_interval:  0 4 * * *
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all-tag.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-captain-playbook-data
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 4
        ttl: 3600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.8
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"

    flow_config:
      sql:
        with x as (select DISTINCT date_format(date_parse(stats_resolved_at,'%Y-%m-%d'),'%Y%m%d') as resolved_date,
        custom_fields_cf_rd_order_id, custom_fields_cf_mobile, custom_fields_cf_reason, custom_fields_cf_sub_reason918254,
        (case when custom_fields_cf_sub_reason918254 in ('Captain Denied Duty','Captain Denied Duty - Bot Resolved','Captain Denied Duty - Bot Dropoff') then 'Captain Denied Duty'
        when custom_fields_cf_sub_reason918254 in ('Rude Behaviour - Bot Resolved','Rude Behaviour - Bot Dropoff') then 'Rude Behaviour'
        when custom_fields_cf_sub_reason918254 in ('Rash Driving - Bot Resolved', 'Rash Driving - Bot Dropoff','Rash Driving/Driving Skills') then 'Rash Driving'
        when custom_fields_cf_sub_reason918254 in ('Helmet/HairCap not offered', 'Helmet/HairCap') then 'Helmet/HairCap not offered'
        else custom_fields_cf_sub_reason918254 end) as sub_reasons, custom_fields_cf_playbook_chips, custom_fields_cf_playbook_priority
        from freshdesk.tickets_snapshot
        where date_format(date_parse(stats_resolved_at,'%Y-%m-%d'),'%Y%m%d') >= date_format(date({{start_date}}), '%Y%m%d') and 
        date_format(date_parse(stats_resolved_at,'%Y-%m-%d'),'%Y%m%d') <= date_format(date({{end_date}}), '%Y%m%d')
        and custom_fields_cf_ticketing_disposition = 'Customer Support'
        and custom_fields_cf_reason in ('Quality Issue (Captain Side)','Emergency Cases P1') 
        and custom_fields_cf_sub_reason918254 is not null
        and custom_fields_cf_sub_reason918254 not like '%Bot Dropoff%'
        and status in ('4','5')
        and stats_resolved_at is not null
        ),
        y as (select DISTINCT yyyymmdd, captain_id, order_id, unique_id, city_name, order_type, captain_obj_mobile, order_status
        from orders.order_logs_snapshot
        where yyyymmdd between date_format({{start_date}} - interval '1' month, '%Y%m%d') 
        and date_format({{end_date}}, '%Y%m%d') and order_type = 'app'
        and cast(captain_id as varchar)!= ''
        ) SELECT DISTINCT resolved_date, city_name, order_type, captain_id, unique_id, captain_obj_mobile, order_status, custom_fields_cf_rd_order_id, 
        sub_reasons, custom_fields_cf_playbook_chips, custom_fields_cf_playbook_priority
        from x inner join y on custom_fields_cf_rd_order_id = unique_id
        order by 4,1,2


      args:
        - var_name: start_date
          var_type: DATE
          expression: "current_date()"
        - var_name: end_date
          var_type: DATE
          expression: "current_date()"

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_captain_playbook_data_v0"
      partition_columns: ["resolved_date","city_name","order_type"]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_captain_playbook_data_v0"
      table_schema_name: "reports_internal"
      view_name: "captain_playbook_data"
      base_path: "metrics/sql_ingest_captain_playbook_data_v0"
      view_schema_name: "reports"


  - run_config:
      name: CUSTOMER_FE_RR_DISTANCE_TIME_BASED
      start_date: '2022-07-04T01:30:00'
      schedule_interval: DAILY
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-customer-ferr-distance
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 8
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"


    flow_config:
      sql:
        with
        LS_Data as
        (select distinct week,customer_id,auto_lifetime_stage,link_lifetime_stage,city from (
        select week(date_parse(run_date,'%Y-%m-%d'))+1 as week,
        customer_id,auto_lifetime_stage,link_lifetime_stage,taxi_lifetime_last_ride_city as city,row_number() over(partition by week(date_parse(run_date,'%Y-%m-%d'))+1,customer_id order by run_date DESC) as cnt
        from
        datasets.iallocator_customer_segments
        where run_date >=date_format({{start_date}}-interval '7' day,'%Y-%m-%d')
        and run_date<=date_format({{end_date}},'%Y-%m-%d')
        and day_of_week(date_parse(run_date,'%Y-%m-%d')) in (5,6,7)
        group by 1,2,3,4,run_date, taxi_lifetime_last_ride_city)
        where cnt=1
        )
        ,
        FE as
        (
        SELECT DISTINCT
        case when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 1 then 'Monday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 2 then 'Tuesday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 3 then 'Wednesday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 4 then 'Thursday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 5 then 'Friday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 6 then 'Saturday'
        else 'Sunday' end as day,
        week(cast(date_parse(yyyymmdd,'%Y%m%d') as date)) as week,yyyymmdd,
        eventprops_currentcity AS city,
        eventprops_userid AS fe_userid,
        eventprops_ctsessionid AS fe_sessionid,
        (CAST(eventprops_hfdistance as double))/1000 AS hfdistance,
        case when (CAST(eventprops_hfdistance as double))/1000 <= 1 then '01'
        when (CAST(eventprops_hfdistance as double))/1000 > 1 and (CAST(eventprops_hfdistance as double))/1000 <= 2 then '02'
        when (CAST(eventprops_hfdistance as double))/1000 > 2 and (CAST(eventprops_hfdistance as double))/1000 <= 3 then '03'
        when (CAST(eventprops_hfdistance as double))/1000 > 3 and (CAST(eventprops_hfdistance as double))/1000 <= 4 then '04'
        when (CAST(eventprops_hfdistance as double))/1000 > 4 and (CAST(eventprops_hfdistance as double))/1000 <= 5 then '05'
        when (CAST(eventprops_hfdistance as double))/1000 > 5 and (CAST(eventprops_hfdistance as double))/1000 <= 6 then '06'
        when (CAST(eventprops_hfdistance as double))/1000 > 6 and (CAST(eventprops_hfdistance as double))/1000 <= 7 then '07'
        when (CAST(eventprops_hfdistance as double))/1000 > 7 and (CAST(eventprops_hfdistance as double))/1000 <= 8 then '08'
        when (CAST(eventprops_hfdistance as double))/1000 > 8 and (CAST(eventprops_hfdistance as double))/1000 <= 9 then '09'
        when (CAST(eventprops_hfdistance as double))/1000 > 9 and (CAST(eventprops_hfdistance as double))/1000 <= 10 then '10'
        when (CAST(eventprops_hfdistance as double))/1000 > 10 and (CAST(eventprops_hfdistance as double))/1000 <= 11 then '11'
        when (CAST(eventprops_hfdistance as double))/1000 > 11 and (CAST(eventprops_hfdistance as double))/1000 <= 12 then '12'
        when (CAST(eventprops_hfdistance as double))/1000 > 12 and (CAST(eventprops_hfdistance as double))/1000 <= 13 then '13'
        when (CAST(eventprops_hfdistance as double))/1000 > 13 and (CAST(eventprops_hfdistance as double))/1000 <= 14 then '14'
        when (CAST(eventprops_hfdistance as double))/1000 > 14 and (CAST(eventprops_hfdistance as double))/1000 <= 15 then '15'
        else '15+' end as distance,
        hour(from_unixtime(floor(cast(epoch AS DOUBLE)/1000))+interval '330' MINUTE) as hour2,eventprops_servicename
        FROM raw.clevertap_customer_fareestimate
        WHERE
        yyyymmdd>=date_format({{start_date}},'%Y%m%d')  and yyyymmdd<=date_format({{end_date}},'%Y%m%d')
        AND
        eventprops_servicename in ('Link','Auto')
        )
        ,

        RR as (
        SELECT DISTINCT
        eventprops_currentcity AS city,
        eventprops_userid AS rr_userid,
        eventprops_ctsessionid AS rr_sessionid,
        eventprops_servicename
        FROM raw.clevertap_customer_request_rapido
        WHERE
        yyyymmdd>=date_format({{start_date}},'%Y%m%d')  and yyyymmdd<=date_format({{end_date}},'%Y%m%d')

        AND
        eventprops_servicename in ('Auto','Link')
        )
        ,

        FE_RR as(
        select FE.*,FE.eventprops_servicename as fe_service_name,RR.eventprops_servicename as rr_service_name,
        case when FE.eventprops_servicename ='Link' then b.link_lifetime_stage else auto_lifetime_stage end as lifetime_stage,
        if(length(cast(hour2 as varchar))=2,concat('hour_',cast(hour2 as varchar)),concat('hour_0',cast(hour2 as varchar))) as hour
        from
        FE
        left join
        RR
        ON FE.city = RR.city and FE.fe_userid = RR.rr_userid and FE.fe_sessionid = RR.rr_sessionid
        and FE.eventprops_servicename=RR.eventprops_servicename
        join
        LS_Data b
        on FE.fe_userid=b.customer_id
        and FE.week=b.week
        and FE.city=b.city

        ),

        fe_calc as(
        select week,
        lifetime_stage,
        date_format(date_parse(yyyymmdd,'%Y%m%d'),'%Y-%m-%d') as date,
        day,
        hour,
        city,distance,'Link' as service_name,
        count(distinct concat(fe_userid,fe_sessionid)) as fe
        from
        FE_RR
        where fe_service_name='Link'
        group by 1,2,3,4,5,6,7,8

        union all

        select week,
        lifetime_stage,
        date_format(date_parse(yyyymmdd,'%Y%m%d'),'%Y-%m-%d') as date,
        day,
        hour,
        city,distance,'Auto' as service_name,
        count(distinct concat(fe_userid,fe_sessionid)) as fe
        from
        FE_RR
        where fe_service_name='Link'
        group by 1,2,3,4,5,6,7,8
        ),
        rr_calc as(
        select week,
        lifetime_stage,
        date_format(date_parse(yyyymmdd,'%Y%m%d'),'%Y-%m-%d') as date,
        day,
        hour,
        city,distance,
        fe_service_name as service_name,
        coalesce(count(distinct case when rr_service_name is not null then concat(fe_userid,fe_sessionid) end ),0) as rr
        from
        FE_RR
        group by 1,2,3,4,5,6,7,8
        )
        select a.week,
        a.lifetime_stage,
        a.date,
        a.day,
        a.hour,
        a.city,a.distance,b.service_name,a.fe,coalesce(b.rr,0) as rr
        from fe_calc a
        join
        rr_calc b
        on a.week=b.week
        and a.lifetime_stage=b.lifetime_stage
        and a.date=b.date
        and a.day=b.day
        and a.hour=b.hour
        and a.city=b.city
        and a.distance=b.distance
        and a.service_name=b.service_name
        order by 1,2,3,4,5,6,7,8

      args:
        - var_name: start_date
          var_type: DATE
          expression: 'current_date()'

        - var_name: end_date
          var_type: DATE
          expression: 'current_date()'



    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_customer_distance_time_fe_info"
      partition_columns: [ "date" ]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_customer_distance_time_fe_info"
      table_schema_name: "reports_internal"
      view_name: "sql_ingest_customer_distance_time_fe_info"
      base_path: "metrics/sql_ingest_customer_distance_time_fe_info"
      view_schema_name: "reports"


  - run_config:
      name: CUSTOMER_G2N_DISTANCE_TIME_BASED
      start_date: '2022-07-04T01:30:00'
      schedule_interval: 0 2 * * *
      jar: gs://{{ var.value.get('environment', 'staging' ) }}-data-airflow/jars/ingestion-data-fw-jars/ingestion-data-driver/ingestion-data-driver/ingestion-data-driver-2.4.5-1.1.0-sql-fix-all.jar
      main_class: bike.rapido.data.SQLFlowDriver
      eternal: false
      auto_recover: false
      cluster_config:
        name: rapido-sql-ingest-customer-g2n-distance
        master_machine_type: "e2-standard-8"
        worker_machine_type: "e2-standard-8"
        worker_count: 2
        ttl: 21600
        idle_ttl: 3600
        image: "1.4-debian10"
        preembtible_worker_percent: 0.9
        properties:
          "dataproc:dataproc.conscrypt.provider.enable": "false"
          "spark:spark.executor.cores": "8"
          "spark:spark.executor.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.driver.extraJavaOptions": "-Duser.timezone=Asia/Calcutta"
          "spark:spark.sql.session.timeZone": "Asia/Calcutta"


    flow_config:
      sql:
        with
        LS_Data as
        (select distinct week,customer_id,auto_lifetime_stage,link_lifetime_stage,city from (
        select week(date_parse(run_date,'%Y-%m-%d'))+1 as week,
        customer_id,auto_lifetime_stage,link_lifetime_stage,taxi_lifetime_last_ride_city as city,row_number() over(partition by week(date_parse(run_date,'%Y-%m-%d'))+1,customer_id order by run_date DESC) as cnt
        from
        datasets.iallocator_customer_segments
        where run_date >=date_format({{start_date}}-interval '7' day,'%Y-%m-%d')
        and run_date<=date_format({{end_date}},'%Y-%m-%d')
        and day_of_week(date_parse(run_date,'%Y-%m-%d')) in (5,6,7)
        group by 1,2,3,4,run_date, taxi_lifetime_last_ride_city)
        where cnt=1
        )
        ,
        offer_details as (
        select
        yyyymmdd, startdate, endDate, userselectors,
        id,
        lower(offertext) as offertext,
        offercode,
        expressions as offer_expressions,
        selector_type,
        peruserlimit,
        json_extract(expressions, '$.0.maxLimit') as discountLimit,
        json_extract(expressions, '$.0.expression') as expression,
        cast(userselectors as ARRAY<VARCHAR>) as selectors_list,
        NAME offer_name,
        type as offer_type,
        NAME recommendation_date,
        cast(json_extract(services,'$.0') as varchar) services,
        cast(json_extract(city,'$.0') as varchar) city,
        description
        
        from
        raw.kafka_offers_immutable
        where
        yyyymmdd>=date_format({{start_date}}-interval '3' day,'%Y%m%d')  and yyyymmdd<=date_format({{end_date}},'%Y%m%d')
        
        ),
        order2 as(
        select week(date_parse(yyyymmdd,'%Y%m%d')) as week,
        case when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 1 then 'Monday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 2 then 'Tuesday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 3 then 'Wednesday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 4 then 'Thursday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 5 then 'Friday'
        when day_of_week(date_parse(yyyymmdd,'%Y%m%d'))= 6 then 'Saturday'
        else '07) Sunday' end as day,
        yyyymmdd,a.customer_id,
        case when (CAST(distance_final_distance as double)) <= 1 then '01'
        when (CAST(distance_final_distance as double)) > 1 and (CAST(distance_final_distance as double)) <= 2 then '02'
        when (CAST(distance_final_distance as double)) > 2 and (CAST(distance_final_distance as double)) <= 3 then '03'
        when (CAST(distance_final_distance as double)) > 3 and (CAST(distance_final_distance as double)) <= 4 then '04'
        when (CAST(distance_final_distance as double)) > 4 and (CAST(distance_final_distance as double)) <= 5 then '05'
        when (CAST(distance_final_distance as double)) > 5 and (CAST(distance_final_distance as double)) <= 6 then '06'
        when (CAST(distance_final_distance as double)) > 6 and (CAST(distance_final_distance as double)) <= 7 then '07'
        when (CAST(distance_final_distance as double)) > 7 and (CAST(distance_final_distance as double)) <= 8 then '08'
        when (CAST(distance_final_distance as double)) > 8 and (CAST(distance_final_distance as double)) <= 9 then '09'
        when (CAST(distance_final_distance as double)) > 9 and (CAST(distance_final_distance as double)) <= 10 then '10'
        when (CAST(distance_final_distance as double)) > 10 and (CAST(distance_final_distance as double)) <= 11 then '11'
        when (CAST(distance_final_distance as double)) > 11 and (CAST(distance_final_distance as double)) <= 12 then '12'
        when (CAST(distance_final_distance as double)) > 12 and (CAST(distance_final_distance as double)) <= 13 then '13'
        when (CAST(distance_final_distance as double)) > 13 and (CAST(distance_final_distance as double)) <= 14 then '14'
        when (CAST(distance_final_distance as double)) > 14 and (CAST(distance_final_distance as double)) <= 15 then '15'
        else '15+' end as distance,
        hour(from_unixtime(floor(cast(epoch AS DOUBLE)/1000))+interval '330' MINUTE) as hour2,
        order_id,
        unique_id,
        case when service_obj_service_name ='Link' then b.link_lifetime_stage else b.auto_lifetime_stage end as ls,
        sub_total,
        discount,
        order_type,
        order_status,
        city_name as city,
        service_obj_service_name as service_name,
        collected_coin , payment_type,
        offer_details_offer_applied,
        offer_details_offer_type,
        offer_details_offer_id
        from
        orders.order_logs_snapshot a
        join
        LS_Data b
        on a.customer_id=b.customer_id
        and week(date_parse(a.yyyymmdd,'%Y%m%d'))=b.week
        and a.city_name=b.city
        and yyyymmdd>=date_format({{start_date}},'%Y%m%d')  and yyyymmdd<=date_format({{end_date}},'%Y%m%d')
        and service_obj_service_name in ('Link','Auto')
        ),
        order1 as (
        select
        a.*,
        b.description,
        case when b.description like '%IALLOCATOR%' then 'iallocator'
        when offer_details_offer_type like '%coupon%' then 'coupon' else offer_details_offer_type
        end offer_source,
        b.offertext
        from order2 a
        left join offer_details b
        on a.offer_details_offer_id = b.id
        )
        ,
        orders as(
        select *,'Overall' as lifetime_stage,'combined_24' as hour
        from
        order1
        union all
        select *,ls as lifetime_stage,'combined_24' as hour
        from
        order1
        union all
        select *,'Overall' as lifetime_stage,if(length(cast(hour2 as varchar))=2,concat('hour_',cast(hour2 as varchar)),concat('hour_0',cast(hour2 as varchar))) as hour
        from
        order1
        union all
        select *,ls as lifetime_stage,if(length(cast(hour2 as varchar))=2,concat('hour_',cast(hour2 as varchar)),concat('hour_0',cast(hour2 as varchar))) as hour
        from
        order1
        )
        select
        week,
        lifetime_stage,
        date_format(date_parse(yyyymmdd,'%Y%m%d'),'%Y-%m-%d') as date,
        day,
        hour,
        city,distance,service_name,
        count(distinct case when  lower(order_status)='dropped' then order_id end) as net_rides,
        count(distinct order_id ) as gross_rides,
        sum(case when  lower(order_status)='dropped' then sub_total end) as sub_total,
        sum(case when  lower(order_status)='dropped' then discount end) as discount,
        count(distinct case when  lower(order_status)='dropped' and discount>0 then order_id end) as discounted_rides,
        count(distinct case when  lower(order_status)='dropped' and payment_type like '%cash%' then order_id end) as cash_rides,
        count(distinct case when  lower(order_status)='dropped' and payment_type like '%rapido%' then order_id end) as wallet_rides,
        count(distinct case when  lower(order_status)='dropped' and lower(cast(offer_details_offer_applied as varchar))= 'true' then order_id end) as offer_used_rides,
        count(distinct case when  lower(order_status)='dropped' and lower(cast(offer_details_offer_type as varchar)) like '%retention%' then order_id end) as retention_offer_rides,
        count(distinct case when  lower(order_status)='dropped' and lower(cast(offer_details_offer_type as varchar)) like '%location%' then order_id end) as location_offer_rides,
        count(distinct case when  lower(order_status)='dropped' and lower(cast(offer_details_offer_type as varchar)) like '%subscription%' then order_id end) as subscription_offer_rides,
        count(distinct case when  lower(order_status)='dropped' and lower(offer_source) = 'iallocator' then order_id end) as allocator_rides
        from
        orders
        group by 1,2,3,4,5,6,7,8

      args:
        - var_name: start_date
          var_type: DATE
          expression: 'current_date()'

        - var_name: end_date
          var_type: DATE
          expression: 'current_date()'

    sql_read_store:
      atlas_base_url: "{{ var.value.get('CATALOG_URL') }}"
      atlas_user_name: "{{ var.value.get('CATALOG_USER') }}"
      atlas_password: "{{ var.value.get('CATALOG_PASSWORD') }}"
      trino_db_username: "{{ var.value.get('TRINO_DB_USERNAME') }}"


    write_store:
      bucket_path: "gs://production-data-reports"
      base_path: "metrics/sql_ingest_customer_distance_time_order_info"
      partition_columns: [ "date" ]

    catalog: "hive"
    db: "reports_internal"
    table_view_config:
      bucket_path: "gs://production-data-reports"
      table_name: "sql_ingest_customer_distance_time_order_info"
      table_schema_name: "reports_internal"
      view_name: "sql_ingest_customer_distance_time_order_info"
      base_path: "metrics/sql_ingest_customer_distance_time_order_info"
      view_schema_name: "reports"